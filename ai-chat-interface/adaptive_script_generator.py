#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì ì‘í˜• ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì—”ì§„
ìš”êµ¬ì‚¬í•­ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì í™”ëœ CrewAI ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë™ì ìœ¼ë¡œ ìƒì„±
"""

import os
import json
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path

from intelligent_requirement_analyzer import IntelligentRequirementAnalyzer, RequirementAnalysis
from dynamic_agent_matcher import DynamicAgentMatcher, AgentSelection
from smart_model_allocator import SmartModelAllocator, ModelAllocation
from quality_assurance_framework import QualityAssuranceFramework
from minimal_documentation_generator import MinimalDocumentationGenerator

@dataclass
class ScriptGenerationResult:
    """ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ê²°ê³¼"""
    script_content: str
    requirements_path: str
    readme_path: str
    quality_score: float
    generation_metadata: Dict
    is_production_ready: bool

class AdaptiveScriptGenerator:
    """ì ì‘í˜• ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì—”ì§„"""

    def __init__(self, model_config_path: str = "model_config.json"):
        self.analyzer = IntelligentRequirementAnalyzer()
        self.matcher = DynamicAgentMatcher()
        self.allocator = SmartModelAllocator(model_config_path)
        self.qa_framework = QualityAssuranceFramework()
        self.doc_generator = MinimalDocumentationGenerator()

    def generate_optimal_script(self,
                              requirement: str,
                              project_path: str,
                              execution_id: str,
                              budget: str = "medium",
                              strategy: str = "balanced",
                              max_quality_iterations: int = 2) -> ScriptGenerationResult:
        """ìµœì í™”ëœ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""

        print(f"ğŸš€ ì ì‘í˜• ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì‹œì‘ - {execution_id}")

        # 1. ìš”êµ¬ì‚¬í•­ ë¶„ì„
        print("ğŸ“‹ ìš”êµ¬ì‚¬í•­ ë¶„ì„ ì¤‘...")
        analysis = self.analyzer.analyze_requirement(requirement)
        print(f"   ë„ë©”ì¸: {analysis.domain}, ë³µì¡ë„: {analysis.complexity.value}, ì—ì´ì „íŠ¸ ìˆ˜: {analysis.agent_count}")

        # 2. ì—ì´ì „íŠ¸ ë§¤ì¹­
        print("ğŸ­ ìµœì  ì—ì´ì „íŠ¸ ì¡°í•© ì„ íƒ ì¤‘...")
        agent_selection = self.matcher.select_optimal_agents(analysis)
        print(f"   ì„ íƒëœ ì—ì´ì „íŠ¸: {[agent.name for agent in agent_selection.agents]}")

        # 3. ëª¨ë¸ í• ë‹¹
        print("ğŸ§  LLM ëª¨ë¸ í• ë‹¹ ì¤‘...")
        model_allocation = self.allocator.allocate_models(agent_selection, analysis, budget, strategy)
        print(f"   í• ë‹¹ ì „ëµ: {strategy}, ì˜ˆìƒ ë¹„ìš©: {model_allocation.total_estimated_cost:.1f}")

        # 4. ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
        print("âš™ï¸  CrewAI ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì¤‘...")
        script_content = self._generate_script_content(
            requirement, analysis, agent_selection, model_allocation, project_path, execution_id
        )

        # 5. í’ˆì§ˆ ê²€ì¦ ë° ê°œì„ 
        print("ğŸ” í’ˆì§ˆ ê²€ì¦ ë° ê°œì„  ì¤‘...")
        script_content, quality_report = self._improve_script_quality(
            script_content, requirement, project_path, max_quality_iterations
        )

        # 6. í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„±
        print("ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„± ì¤‘...")
        project_structure = self._create_project_structure(
            project_path, script_content, analysis.required_libraries
        )

        # 7. ë¬¸ì„œí™”
        print("ğŸ“ ë¬¸ì„œ ìƒì„± ì¤‘...")
        readme_path = self._generate_documentation(
            requirement, analysis, agent_selection, model_allocation, project_path
        )

        # 8. ë©”íƒ€ë°ì´í„° ìƒì„±
        generation_metadata = self._create_generation_metadata(
            requirement, analysis, agent_selection, model_allocation, quality_report, execution_id
        )

        print(f"âœ… ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì™„ë£Œ! í’ˆì§ˆ ì ìˆ˜: {quality_report.overall_score:.1f}/100")

        return ScriptGenerationResult(
            script_content=script_content,
            requirements_path=project_structure['requirements'],
            readme_path=readme_path,
            quality_score=quality_report.overall_score,
            generation_metadata=generation_metadata,
            is_production_ready=quality_report.is_production_ready
        )

    def _generate_script_content(self,
                               requirement: str,
                               analysis: RequirementAnalysis,
                               agent_selection: AgentSelection,
                               model_allocation: ModelAllocation,
                               project_path: str,
                               execution_id: str) -> str:
        """ì ì‘í˜• ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš© ìƒì„±"""

        # ê¸°ë³¸ í…œí”Œë¦¿ ë¡œë“œ
        template = self._get_base_template()

        # ë™ì  êµ¬ì„± ìš”ì†Œ ìƒì„±
        imports_section = self._generate_imports_section(analysis)
        models_section = self._generate_models_section(model_allocation)
        agents_section = self._generate_agents_section(agent_selection, model_allocation)
        tasks_section = self._generate_tasks_section(agent_selection, requirement, analysis, project_path)
        crew_section = self._generate_crew_section(agent_selection)
        main_section = self._generate_main_section(requirement, project_path, execution_id, analysis)

        # í…œí”Œë¦¿ ì¡°ë¦½
        script_content = template.format(
            execution_id=execution_id,
            requirement=requirement,
            imports=imports_section,
            models=models_section,
            agents=agents_section,
            tasks=tasks_section,
            crew=crew_section,
            main=main_section
        )

        return script_content

    def _get_base_template(self) -> str:
        """ê¸°ë³¸ ìŠ¤í¬ë¦½íŠ¸ í…œí”Œë¦¿"""
        return '''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ê³ í’ˆì§ˆ CrewAI ìŠ¤í¬ë¦½íŠ¸ (ì ì‘í˜• ìƒì„±)
ì‹¤í–‰ ID: {execution_id}
ìš”êµ¬ì‚¬í•­: {requirement}
"""

{imports}

{models}

{agents}

{tasks}

{crew}

{main}

if __name__ == "__main__":
    main()
'''

    def _generate_imports_section(self, analysis: RequirementAnalysis) -> str:
        """import ì„¹ì…˜ ìƒì„±"""
        imports = [
            "import os",
            "import sys",
            "import json",
            "from datetime import datetime",
            "from pathlib import Path",
            "from dotenv import load_dotenv",
            "from crewai import Agent, Task, Crew, Process",
            "from langchain_litellm import ChatLiteLLM",
            "",
            "# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ .env íŒŒì¼ì˜ ê²½ë¡œë¥¼ ì§€ì •",
            "# ì´ë ‡ê²Œ í•˜ë©´ ì–´ë–¤ ìœ„ì¹˜ì—ì„œ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ë”ë¼ë„ .env íŒŒì¼ì„ ì˜¬ë°”ë¥´ê²Œ ì°¾ì„ ìˆ˜ ìˆìŒ",
            "dotenv_path = os.path.join(os.path.dirname(__file__), '.env')",
            "load_dotenv(dotenv_path=dotenv_path)",
            "",
            "# API í‚¤ í™•ì¸",
            "missing_keys = []",
            "if not os.getenv('GOOGLE_API_KEY'):",
            "    missing_keys.append('GOOGLE_API_KEY')",
            "if not os.getenv('OPENAI_API_KEY'):",
            "    missing_keys.append('OPENAI_API_KEY')",
            "",
            "if missing_keys:",
            "    print(f'âš ï¸  ê²½ê³ : ë‹¤ìŒ í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {\", \".join(missing_keys)}', file=sys.stderr)",
            "    print('   .env íŒŒì¼ì— í•´ë‹¹ í‚¤ë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ ì‹œìŠ¤í…œ í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.', file=sys.stderr)",
            "    print('   ì¼ë¶€ ì—ì´ì „íŠ¸ê°€ ì‘ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.', file=sys.stderr)"
        ]

        # ë„ë©”ì¸ë³„ ì¶”ê°€ import
        domain_imports = {
            'data_analysis': ['import pandas as pd', 'import numpy as np'],
            'web_development': ['import requests'],
            'document_processing': ['import re'],
            'automation': ['import schedule', 'import time'],
            'content_creation': ['import re']
        }

        if analysis.domain in domain_imports:
            imports.extend(domain_imports[analysis.domain])

        # ì„œë¸Œ ë„ë©”ì¸ import
        for sub_domain in analysis.sub_domains:
            if sub_domain in domain_imports:
                imports.extend(domain_imports[sub_domain])

        return '\n'.join(imports)

    def _generate_models_section(self, model_allocation: ModelAllocation) -> str:
        """ëª¨ë¸ ì„¤ì • ì„¹ì…˜ ìƒì„± (ChatLiteLLM ê°ì²´ ë°©ì‹)"""
        model_mapping = model_allocation.agent_model_mapping

        # ëª¨ë¸ë³„ API í‚¤ ë§¤í•‘
        api_key_mapping = {
            'gemini': 'GOOGLE_API_KEY',
            'openai': 'OPENAI_API_KEY',
            'anthropic': 'ANTHROPIC_API_KEY',
            'deepseek': 'DEEPSEEK_API_KEY'
        }

        models_code = ["# LLM ëª¨ë¸ ì„¤ì • (ChatLiteLLM ê°ì²´ ìƒì„±)", ""]
        models_code.append("# ê° ëª¨ë¸ì— ëŒ€í•œ LLM ê°ì²´ ìƒì„±")
        models_code.append("MODELS = {}")
        models_code.append("")

        for agent_name, model_name in model_mapping.items():
            # ëª¨ë¸ëª…ì—ì„œ ì œê³µì ì¶”ì¶œ (ì˜ˆ: gemini/gemini-2.5-flash -> gemini)
            provider = model_name.split('/')[0] if '/' in model_name else 'gemini'
            api_key_env = api_key_mapping.get(provider, 'GOOGLE_API_KEY')

            model_code = f'''# {agent_name} ëª¨ë¸
MODELS['{agent_name}'] = ChatLiteLLM(
    model="{model_name}",
    api_key=os.getenv("{api_key_env}")
)'''
            models_code.append(model_code)

        return '\n'.join(models_code)

    def _generate_agents_section(self, agent_selection: AgentSelection,
                                model_allocation: ModelAllocation) -> str:
        """ì—ì´ì „íŠ¸ ì„¹ì…˜ ìƒì„±"""
        agents_code = []
        agents_code.append("# ì „ë¬¸ ì—ì´ì „íŠ¸ ì •ì˜")

        for agent in agent_selection.agents:
            agent_name = agent.name

            agent_code = f'''
{agent_name} = Agent(
    role="{agent.role}",
    goal="{agent.goal}",
    backstory="""{agent.backstory}""",
    verbose=True,
    llm=MODELS['{agent_name}'],  # ChatLiteLLM ê°ì²´ ì§ì ‘ ì „ë‹¬
    allow_delegation=False
)'''
            agents_code.append(agent_code)

        return '\n'.join(agents_code)

    def _generate_tasks_section(self, agent_selection: AgentSelection,
                              requirement: str, analysis: RequirementAnalysis,
                              project_path: str) -> str:
        """íƒœìŠ¤í¬ ì„¹ì…˜ ìƒì„±"""
        tasks_code = []
        tasks_code.append("# ì „ë¬¸ íƒœìŠ¤í¬ ì •ì˜")

        for i, agent in enumerate(agent_selection.agents, 1):
            task_description = self._generate_task_description(agent, requirement, analysis, project_path)
            expected_output = self._generate_expected_output(agent, analysis)

            task_code = f'''
task{i}_{agent.name} = Task(
    description="""{task_description}""",
    expected_output="{expected_output}",
    agent={agent.name}
)'''
            tasks_code.append(task_code)

        return '\n'.join(tasks_code)

    def _generate_task_description(self, agent, requirement: str,
                                 analysis: RequirementAnalysis, project_path: str) -> str:
        """ì—ì´ì „íŠ¸ë³„ íƒœìŠ¤í¬ ì„¤ëª… ìƒì„±"""

        base_descriptions = {
            'requirements_analyst': f"""ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ì„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”: {requirement}

**ë¶„ì„ í•­ëª©:**
1. **í•µì‹¬ ê¸°ëŠ¥**: ì£¼ìš” ìš”êµ¬ì‚¬í•­ê³¼ ê¸°ëŠ¥ ë¶„ì„
2. **ê¸°ìˆ ì  ì œì•½**: ì„±ëŠ¥, ë³´ì•ˆ, í˜¸í™˜ì„± ìš”êµ¬ì‚¬í•­
3. **ì„±ê³µ ê¸°ì¤€**: ì¸¡ì • ê°€ëŠ¥í•œ ê²°ê³¼ë¬¼ê³¼ í’ˆì§ˆ ê¸°ì¤€
4. **ìœ„í—˜ ìš”ì†Œ**: ì ì¬ì  ë¬¸ì œì ê³¼ ëŒ€ì‘ ë°©ì•ˆ

**ê²°ê³¼ë¬¼**: êµ¬ì¡°í™”ëœ ìš”êµ¬ì‚¬í•­ ë¶„ì„ ë³´ê³ ì„œ""",

            'technology_researcher': f"""ìš”êµ¬ì‚¬í•­ì— ìµœì í™”ëœ ê¸°ìˆ  ìŠ¤íƒì„ ì—°êµ¬í•˜ê³  ì¶”ì²œí•˜ì„¸ìš”:

**ì—°êµ¬ ì˜ì—­:**
1. **í”„ë¡œê·¸ë˜ë° ì–¸ì–´**: Python, JavaScript ë“± ìµœì  ì–¸ì–´ ì„ íƒ
2. **í”„ë ˆì„ì›Œí¬**: {', '.join(analysis.tech_stack[:3])} ë“± ì í•©í•œ í”„ë ˆì„ì›Œí¬
3. **ë¼ì´ë¸ŒëŸ¬ë¦¬**: {', '.join(analysis.required_libraries[:5])} ë“± í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬
4. **ì•„í‚¤í…ì²˜**: í™•ì¥ ê°€ëŠ¥í•˜ê³  ìœ ì§€ë³´ìˆ˜ ê°€ëŠ¥í•œ ì„¤ê³„ íŒ¨í„´

**ê²°ê³¼ë¬¼**: ê¸°ìˆ  ìŠ¤íƒ ì¶”ì²œì„œì™€ êµ¬í˜„ ê°€ì´ë“œë¼ì¸""",

            'solution_architect': f"""í¬ê´„ì ì¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ë¥¼ ì„¤ê³„í•˜ì„¸ìš”:

**ì„¤ê³„ ìš”ì†Œ:**
1. **ì‹œìŠ¤í…œ êµ¬ì¡°**: ì»´í¬ë„ŒíŠ¸ ê°„ ìƒí˜¸ì‘ìš©ê³¼ ë°ì´í„° í”Œë¡œìš°
2. **API ì„¤ê³„**: ì¸í„°í˜ì´ìŠ¤ ëª…ì„¸ì™€ ë°ì´í„° ìŠ¤í‚¤ë§ˆ
3. **ë°ì´í„°ë² ì´ìŠ¤**: íš¨ìœ¨ì ì¸ ë°ì´í„° ì €ì¥ ë° ì¡°íšŒ êµ¬ì¡°
4. **ë³´ì•ˆ ì„¤ê³„**: ë°ì´í„° ë³´í˜¸ì™€ ì ‘ê·¼ ì œì–´ ë°©ì•ˆ

**ê²°ê³¼ë¬¼**: ìƒì„¸í•œ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ì„¤ê³„ì„œ""",

            'implementation_engineer': f"""ìƒì‚° ì¤€ë¹„ëœ ì™„ì „í•œ êµ¬í˜„ì„ ê°œë°œí•˜ì„¸ìš”:

**êµ¬í˜„ ìš”ì†Œ:**
1. **í•µì‹¬ ì½”ë“œ**: ìš”êµ¬ì‚¬í•­ì„ ì™„ì „íˆ êµ¬í˜„í•˜ëŠ” í”„ë¡œë•ì…˜ ì½”ë“œ
2. **ì„¤ì • ê´€ë¦¬**: í™˜ê²½ ì„¤ì •ê³¼ ì˜ì¡´ì„± ê´€ë¦¬
3. **í…ŒìŠ¤íŠ¸ ì½”ë“œ**: ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ì™€ í†µí•© í…ŒìŠ¤íŠ¸ êµ¬í˜„
4. **ë¬¸ì„œí™”**: ì½”ë“œ ë¬¸ì„œì™€ ì‚¬ìš©ì ê°€ì´ë“œ

ì €ì¥ ìœ„ì¹˜: {project_path}/output/
**ê²°ê³¼ë¬¼**: ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì™„ì „í•œ ì• í”Œë¦¬ì¼€ì´ì…˜""",

            'content_creator': f"""ê³ í’ˆì§ˆ ì½˜í…ì¸ ë¥¼ ê¸°íší•˜ê³  ì œì‘í•˜ì„¸ìš”:

**ì œì‘ ìš”ì†Œ:**
1. **ì½˜í…ì¸  ê¸°íš**: íƒ€ê²Ÿ ë…ìì™€ ëª©ì ì— ë§ëŠ” ì½˜í…ì¸  ì „ëµ
2. **ê¸€ ì‘ì„±**: SEO ìµœì í™”ëœ ê³ í’ˆì§ˆ í…ìŠ¤íŠ¸ ì½˜í…ì¸ 
3. **êµ¬ì¡°í™”**: ì½ê¸° ì‰¬ìš´ í˜•ì‹ê³¼ ë…¼ë¦¬ì  êµ¬ì„±
4. **ìµœì í™”**: ê²€ìƒ‰ ì—”ì§„ê³¼ ì‚¬ìš©ì ê²½í—˜ ìµœì í™”

**ê²°ê³¼ë¬¼**: ì™„ì„±ëœ ê³ í’ˆì§ˆ ì½˜í…ì¸ ì™€ ê²Œì‹œ ê°€ì´ë“œ""",

            'data_scientist': f"""ë°ì´í„° ë¶„ì„ê³¼ ì¸ì‚¬ì´íŠ¸ ë„ì¶œì„ ìˆ˜í–‰í•˜ì„¸ìš”:

**ë¶„ì„ í•­ëª©:**
1. **ë°ì´í„° ìˆ˜ì§‘**: ê´€ë ¨ ë°ì´í„° ì†ŒìŠ¤ ì‹ë³„ ë° ìˆ˜ì§‘
2. **ë°ì´í„° ì²˜ë¦¬**: ì •ì œ, ë³€í™˜, í†µí•© ê³¼ì •
3. **ë¶„ì„ ìˆ˜í–‰**: í†µê³„ ë¶„ì„ê³¼ íŒ¨í„´ íƒì§€
4. **ì‹œê°í™”**: ì¸ì‚¬ì´íŠ¸ë¥¼ ëª…í™•íˆ ì „ë‹¬í•˜ëŠ” ì°¨íŠ¸ì™€ ê·¸ë˜í”„

**ê²°ê³¼ë¬¼**: ë°ì´í„° ë¶„ì„ ë¦¬í¬íŠ¸ì™€ ì‹œê°í™” ìë£Œ""",

            'automation_specialist': f"""íš¨ìœ¨ì ì¸ ìë™í™” ì†”ë£¨ì…˜ì„ êµ¬í˜„í•˜ì„¸ìš”:

**ìë™í™” ìš”ì†Œ:**
1. **í”„ë¡œì„¸ìŠ¤ ë¶„ì„**: ìë™í™” ê°€ëŠ¥í•œ ì‘ì—… íë¦„ ì‹ë³„
2. **ìŠ¤í¬ë¦½íŠ¸ ê°œë°œ**: ë°˜ë³µ ì‘ì—…ì„ ìë™í™”í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
3. **ìŠ¤ì¼€ì¤„ë§**: ì •ê¸°ì  ì‹¤í–‰ì„ ìœ„í•œ ìŠ¤ì¼€ì¤„ ì„¤ì •
4. **ëª¨ë‹ˆí„°ë§**: ìë™í™” í”„ë¡œì„¸ìŠ¤ ìƒíƒœ ì¶”ì 

**ê²°ê³¼ë¬¼**: ì™„ì „ ìë™í™”ëœ ì›Œí¬í”Œë¡œìš° ì‹œìŠ¤í…œ"""
        }

        return base_descriptions.get(agent.name, f"ì „ë¬¸ ë¶„ì•¼ì—ì„œ ìµœê³  í’ˆì§ˆì˜ ê²°ê³¼ë¬¼ì„ ìƒì„±í•˜ì„¸ìš”: {requirement}")

    def _generate_expected_output(self, agent, analysis: RequirementAnalysis) -> str:
        """ì˜ˆìƒ ì¶œë ¥ ìƒì„±"""
        outputs = {
            'requirements_analyst': 'ì²´ê³„ì ì¸ ìš”êµ¬ì‚¬í•­ ë¶„ì„ ë³´ê³ ì„œì™€ ì„±ê³µ ê¸°ì¤€',
            'technology_researcher': 'ìµœì í™”ëœ ê¸°ìˆ  ìŠ¤íƒ ì¶”ì²œì„œì™€ êµ¬í˜„ ë¡œë“œë§µ',
            'solution_architect': 'ìƒì„¸í•œ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ì™€ ì„¤ê³„ ëª…ì„¸ì„œ',
            'implementation_engineer': 'ì™„ì „íˆ êµ¬í˜„ëœ í”„ë¡œë•ì…˜ ì½”ë“œì™€ í…ŒìŠ¤íŠ¸',
            'content_creator': 'ê³ í’ˆì§ˆ ì½˜í…ì¸ ì™€ SEO ìµœì í™” ê°€ì´ë“œ',
            'data_scientist': 'ë°ì´í„° ë¶„ì„ ê²°ê³¼ì™€ ì¸ì‚¬ì´íŠ¸ ë¦¬í¬íŠ¸',
            'automation_specialist': 'ìë™í™” ìŠ¤í¬ë¦½íŠ¸ì™€ ì‹¤í–‰ ê°€ì´ë“œ'
        }

        return outputs.get(agent.name, 'ì „ë¬¸ ë¶„ì•¼ì˜ ê³ í’ˆì§ˆ ê²°ê³¼ë¬¼')

    def _generate_crew_section(self, agent_selection: AgentSelection) -> str:
        """í¬ë£¨ ì„¹ì…˜ ìƒì„±"""
        agent_names = [agent.name for agent in agent_selection.agents]
        task_names = [f"task{i+1}_{agent.name}" for i, agent in enumerate(agent_selection.agents)]

        return f'''# ì „ë¬¸ í¬ë£¨ êµ¬ì„±
crew = Crew(
    agents=[{', '.join(agent_names)}],
    tasks=[{', '.join(task_names)}],
    process=Process.sequential,
    verbose=True
)'''

    def _generate_main_section(self, requirement: str, project_path: str,
                             execution_id: str, analysis: RequirementAnalysis) -> str:
        """ë©”ì¸ í•¨ìˆ˜ ì„¹ì…˜ ìƒì„±"""
        return f'''def main():
    """ê³ í’ˆì§ˆ CrewAI ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 80)
    print("ğŸš€ ê³ í’ˆì§ˆ CrewAI ì‹œìŠ¤í…œ ì‹¤í–‰ ì‹œì‘")
    print(f"ì‹¤í–‰ ID: {execution_id}")
    print(f"í”„ë¡œì íŠ¸ ê²½ë¡œ: {project_path}")
    print(f"ìš”êµ¬ì‚¬í•­: {requirement}")
    print(f"ë³µì¡ë„: {analysis.complexity.value}")
    print(f"ì—ì´ì „íŠ¸ ìˆ˜: {analysis.agent_count}")
    print("=" * 80)

    try:
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        output_dir = Path("{project_path}") / "output"
        output_dir.mkdir(parents=True, exist_ok=True)

        logs_dir = output_dir / "logs"
        logs_dir.mkdir(exist_ok=True)

        deliverables_dir = output_dir / "deliverables"
        deliverables_dir.mkdir(exist_ok=True)

        # ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
        start_time = datetime.now()
        print(f"\\nğŸš€ CrewAI ì‹¤í–‰ ì‹œì‘: {{start_time.strftime('%Y-%m-%d %H:%M:%S')}}")

        # CrewAI ì‹¤í–‰
        result = crew.kickoff()

        end_time = datetime.now()
        execution_time = (end_time - start_time).total_seconds()

        print("\\n" + "=" * 80)
        print("âœ… ì‹¤í–‰ ì™„ë£Œ!")
        print(f"â±ï¸  ì‹¤í–‰ ì‹œê°„: {{execution_time:.2f}}ì´ˆ")
        print(f"ğŸ‘¥ ì—ì´ì „íŠ¸: {analysis.agent_count}ê°œ ì „ë¬¸ ì—ì´ì „íŠ¸")
        print(f"ğŸ“‹ íƒœìŠ¤í¬: {analysis.agent_count}ê°œ ì „ë¬¸ íƒœìŠ¤í¬")
        print("=" * 80)
        print("\\nğŸ“„ ì‹¤í–‰ ê²°ê³¼:")
        print(result)

        # ê²°ê³¼ ì €ì¥
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

        # ë©”ì¸ ê²°ê³¼ íŒŒì¼
        result_file = output_dir / f"crew_result_{{timestamp}}.txt"
        with open(result_file, 'w', encoding='utf-8') as f:
            f.write(f"CrewAI ì‹¤í–‰ ê²°ê³¼\\n")
            f.write(f"================\\n")
            f.write(f"ì‹¤í–‰ ID: {execution_id}\\n")
            f.write(f"ìš”êµ¬ì‚¬í•­: {requirement}\\n")
            f.write(f"ì‹œì‘ ì‹œê°„: {{start_time}}\\n")
            f.write(f"ì¢…ë£Œ ì‹œê°„: {{end_time}}\\n")
            f.write(f"ì‹¤í–‰ ì‹œê°„: {{execution_time:.2f}}ì´ˆ\\n")
            f.write(f"ì—ì´ì „íŠ¸ ìˆ˜: {analysis.agent_count}\\n\\n")
            f.write(f"ê²°ê³¼:\\n")
            f.write(f"======\\n")
            f.write(str(result))

        # ì‹¤í–‰ ë©”íƒ€ë°ì´í„°
        metadata_file = output_dir / f"execution_metadata_{{timestamp}}.json"
        metadata = {{
            "execution_id": "{execution_id}",
            "requirement": "{requirement}",
            "start_time": start_time.isoformat(),
            "end_time": end_time.isoformat(),
            "duration_seconds": execution_time,
            "agent_count": {analysis.agent_count},
            "complexity": "{analysis.complexity.value}",
            "domain": "{analysis.domain}",
            "status": "completed",
            "output_files": [str(result_file), str(metadata_file)]
        }}

        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)

        print(f"\\nğŸ“ ê²°ê³¼ íŒŒì¼:")
        print(f"   ğŸ“„ ë©”ì¸ ê²°ê³¼: {{result_file}}")
        print(f"   ğŸ“Š ë©”íƒ€ë°ì´í„°: {{metadata_file}}")
        print(f"   ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {{output_dir}}")

        return result

    except Exception as e:
        error_time = datetime.now()
        print(f"\\nâŒ ì˜¤ë¥˜ ë°œìƒ: {{e}}")

        # ì˜¤ë¥˜ ë¡œê¹…
        error_file = Path("{project_path}") / "output" / f"error_log_{{error_time.strftime('%Y%m%d_%H%M%S')}}.txt"
        error_file.parent.mkdir(parents=True, exist_ok=True)

        with open(error_file, 'w', encoding='utf-8') as f:
            f.write(f"CrewAI ì‹¤í–‰ ì˜¤ë¥˜ ë³´ê³ ì„œ\\n")
            f.write(f"=====================\\n")
            f.write(f"ì‹œê°„: {{error_time}}\\n")
            f.write(f"ì‹¤í–‰ ID: {execution_id}\\n")
            f.write(f"ì˜¤ë¥˜: {{str(e)}}\\n\\n")

            import traceback
            f.write("ìƒì„¸ ì˜¤ë¥˜ ì •ë³´:\\n")
            f.write(traceback.format_exc())

        print(f"ğŸ“„ ì˜¤ë¥˜ ë¡œê·¸: {{error_file}}")
        raise'''

    def _improve_script_quality(self, script_content: str, requirement: str,
                               project_path: str, max_iterations: int):
        """ìŠ¤í¬ë¦½íŠ¸ í’ˆì§ˆ ê°œì„ """

        current_script = script_content
        best_score = 0.0

        for iteration in range(max_iterations):
            print(f"   í’ˆì§ˆ ê²€ì¦ {iteration + 1}/{max_iterations}...")

            # í’ˆì§ˆ í‰ê°€
            quality_report = self.qa_framework.assess_quality(current_script, requirement, project_path)

            print(f"   í’ˆì§ˆ ì ìˆ˜: {quality_report.overall_score:.1f}/100")

            # ì ìˆ˜ê°€ ê°œì„ ë˜ì—ˆìœ¼ë©´ ì—…ë°ì´íŠ¸
            if quality_report.overall_score > best_score:
                best_score = quality_report.overall_score
                best_script = current_script
                best_report = quality_report

            # ë§Œì¡±í• ë§Œí•œ í’ˆì§ˆì´ë©´ ì¤‘ë‹¨
            if quality_report.overall_score >= 85.0:
                print("   âœ… ê³ í’ˆì§ˆ ë‹¬ì„±!")
                break

            # ê°œì„ ì´ í•„ìš”í•œ ê²½ìš° ìë™ ìˆ˜ì •
            if iteration < max_iterations - 1:
                current_script = self._apply_automatic_fixes(current_script, quality_report)

        return best_script if 'best_script' in locals() else current_script, \
               best_report if 'best_report' in locals() else quality_report

    def _apply_automatic_fixes(self, script_content: str, quality_report) -> str:
        """ìë™ ìˆ˜ì • ì ìš©"""
        improved_script = script_content

        # ì¹˜ëª…ì  ì´ìŠˆ ìë™ ìˆ˜ì •
        for issue in quality_report.issues:
            if issue.severity == "critical":
                if "import" in issue.description.lower():
                    # import ë¬¸ ìˆ˜ì •
                    if "crewai" in issue.description.lower():
                        improved_script = "from crewai import Agent, Task, Crew, Process\n" + improved_script

                if "utf-8" in issue.description.lower():
                    # UTF-8 ì¸ì½”ë”© ì¶”ê°€
                    if "# -*- coding: utf-8 -*-" not in improved_script:
                        lines = improved_script.split('\n')
                        lines.insert(1, "# -*- coding: utf-8 -*-")
                        improved_script = '\n'.join(lines)

        return improved_script

    def _create_project_structure(self, project_path: str, script_content: str,
                                required_libraries: List[str]) -> Dict[str, str]:
        """í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„±"""

        # ë””ë ‰í† ë¦¬ ìƒì„±
        Path(project_path).mkdir(parents=True, exist_ok=True)
        Path(project_path, "output").mkdir(exist_ok=True)
        Path(project_path, "output", "logs").mkdir(exist_ok=True)
        Path(project_path, "output", "deliverables").mkdir(exist_ok=True)

        # ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸ ì €ì¥
        script_path = os.path.join(project_path, "crewai_script.py")
        with open(script_path, 'w', encoding='utf-8') as f:
            f.write(script_content)

        # requirements.txt ìƒì„±
        requirements_path = os.path.join(project_path, "requirements.txt")
        with open(requirements_path, 'w', encoding='utf-8') as f:
            for lib in required_libraries:
                f.write(f"{lib}\n")

        # .env.example ìƒì„±
        env_example_path = os.path.join(project_path, ".env.example")
        with open(env_example_path, 'w', encoding='utf-8') as f:
            f.write("# LLM API í‚¤ ì„¤ì •\n")
            f.write("OPENAI_API_KEY=your_openai_key_here\n")
            f.write("GOOGLE_API_KEY=your_google_key_here\n")
            f.write("ANTHROPIC_API_KEY=your_anthropic_key_here\n")
            f.write("\n# ê¸°íƒ€ ì„¤ì •\n")
            f.write("# LOG_LEVEL=INFO\n")

        # ì‹¤ì œ .env íŒŒì¼ ìƒì„± (ì‹œìŠ¤í…œ í™˜ê²½ë³€ìˆ˜ì—ì„œ ë³µì‚¬)
        env_path = os.path.join(project_path, ".env")
        with open(env_path, 'w', encoding='utf-8') as f:
            f.write("# LLM API í‚¤ ì„¤ì • (ìë™ ìƒì„±)\n")

            # ì‹œìŠ¤í…œ í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
            api_keys = {
                'OPENAI_API_KEY': os.getenv('OPENAI_API_KEY', ''),
                'GOOGLE_API_KEY': os.getenv('GOOGLE_API_KEY', ''),
                'ANTHROPIC_API_KEY': os.getenv('ANTHROPIC_API_KEY', ''),
                'DEEPSEEK_API_KEY': os.getenv('DEEPSEEK_API_KEY', '')
            }

            for key, value in api_keys.items():
                if value:
                    f.write(f"{key}={value}\n")
                    print(f"âœ… {key} í™˜ê²½ë³€ìˆ˜ ë³µì‚¬ë¨")
                else:
                    f.write(f"# {key}=your_key_here\n")
                    print(f"âš ï¸  {key} í™˜ê²½ë³€ìˆ˜ ì—†ìŒ (.env íŒŒì¼ì— ìˆ˜ë™ ì„¤ì • í•„ìš”)")

            f.write("\n# ê¸°íƒ€ ì„¤ì •\n")
            f.write("LOG_LEVEL=INFO\n")

        return {
            'script': script_path,
            'requirements': requirements_path,
            'env_example': env_example_path,
            'env': env_path
        }

    def _generate_documentation(self, requirement: str, analysis: RequirementAnalysis,
                              agent_selection: AgentSelection, model_allocation: ModelAllocation,
                              project_path: str) -> str:
        """ë¬¸ì„œ ìƒì„±"""

        readme_content = self.doc_generator.generate_documentation(
            requirement, analysis, agent_selection, model_allocation, project_path
        )

        return os.path.join(project_path, "README.md")

    def _create_generation_metadata(self, requirement: str, analysis: RequirementAnalysis,
                                   agent_selection: AgentSelection, model_allocation: ModelAllocation,
                                   quality_report, execution_id: str) -> Dict:
        """ìƒì„± ë©”íƒ€ë°ì´í„° ìƒì„±"""

        return {
            "generation_info": {
                "execution_id": execution_id,
                "timestamp": datetime.now().isoformat(),
                "generator_version": "1.0.0"
            },
            "requirement_analysis": {
                "original_requirement": requirement,
                "domain": analysis.domain,
                "complexity": analysis.complexity.value,
                "confidence_score": analysis.confidence_score,
                "keywords": analysis.keywords
            },
            "agent_selection": {
                "agent_count": len(agent_selection.agents),
                "selected_agents": [agent.name for agent in agent_selection.agents],
                "selection_reasoning": agent_selection.selection_reasoning,
                "confidence_score": agent_selection.confidence_score
            },
            "model_allocation": {
                "allocation_strategy": model_allocation.allocation_reasoning,
                "total_cost": model_allocation.total_estimated_cost,
                "model_mapping": model_allocation.agent_model_mapping,
                "confidence_score": model_allocation.confidence_score
            },
            "quality_assessment": {
                "overall_score": quality_report.overall_score,
                "quality_level": quality_report.quality_level.value,
                "is_production_ready": quality_report.is_production_ready,
                "stage_scores": quality_report.stage_scores
            }
        }

    def generate_optimal_script_with_manual_models(self,
                                                   requirement: str,
                                                   selected_models: dict,
                                                   project_path: str,
                                                   execution_id: str,
                                                   budget: str = "medium",
                                                   strategy: str = "balanced",
                                                   max_quality_iterations: int = 2) -> ScriptGenerationResult:
        """ìˆ˜ë™ ëª¨ë¸ ì„ íƒì„ ì‚¬ìš©í•œ ìµœì í™”ëœ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""

        print(f"ğŸš€ ìˆ˜ë™ ëª¨ë¸ ì„ íƒ ì ì‘í˜• ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì‹œì‘ - {execution_id}")
        print(f"   ì„ íƒëœ ëª¨ë¸: {selected_models}")

        # 1. ìš”êµ¬ì‚¬í•­ ë¶„ì„
        print("ğŸ“‹ ìš”êµ¬ì‚¬í•­ ë¶„ì„ ì¤‘...")
        analysis = self.analyzer.analyze_requirement(requirement)
        print(f"   ë„ë©”ì¸: {analysis.domain}, ë³µì¡ë„: {analysis.complexity.value}, ì—ì´ì „íŠ¸ ìˆ˜: {analysis.agent_count}")

        # 2. ì—ì´ì „íŠ¸ ë§¤ì¹­ (ê³ í’ˆì§ˆ ì—ì´ì „íŠ¸ ê°•ì œ ì‚¬ìš©)
        print("ğŸ­ ê³ í’ˆì§ˆ ì—ì´ì „íŠ¸ ì¡°í•© ì„ íƒ ì¤‘...")
        agent_selection = self.matcher.select_optimal_agents(analysis)
        print(f"   ì„ íƒëœ ì—ì´ì „íŠ¸: {[agent.name for agent in agent_selection.agents]}")

        # 3. ìˆ˜ë™ ëª¨ë¸ í• ë‹¹ ìƒì„±
        print("ğŸ§  ìˆ˜ë™ ì„ íƒ ëª¨ë¸ í• ë‹¹ ì¤‘...")
        model_allocation = self._create_manual_model_allocation(selected_models, agent_selection)
        print(f"   ìˆ˜ë™ í• ë‹¹ ì™„ë£Œ, ì—ì´ì „íŠ¸-ëª¨ë¸ ë§¤í•‘: {model_allocation.agent_model_mapping}")

        # 4. ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
        print("âš™ï¸  CrewAI ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì¤‘...")
        script_content = self._generate_script_content(
            requirement, analysis, agent_selection, model_allocation, project_path, execution_id
        )

        # 5. í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„±
        print("ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„± ì¤‘...")
        project_structure = self.doc_generator.create_project_structure(project_path)

        # 6. README ìƒì„±
        print("ğŸ“„ README.md ìƒì„± ì¤‘...")
        readme_path = self.doc_generator.generate_readme(
            project_path, requirement, agent_selection, model_allocation, analysis
        )

        # 7. í’ˆì§ˆ í‰ê°€
        print("ğŸ” í’ˆì§ˆ í‰ê°€ ì¤‘...")
        quality_report = self.quality_framework.evaluate_script(script_content, analysis)

        # 8. ë©”íƒ€ë°ì´í„° ìƒì„±
        generation_metadata = {
            "generation_mode": "manual_models",
            "selected_models": selected_models,
            "agent_count": len(agent_selection.agents),
            "domain": analysis.domain,
            "complexity": analysis.complexity.value,
            "budget": budget,
            "strategy": strategy,
            "quality_score": quality_report.overall_score,
            "generation_timestamp": datetime.now().isoformat(),
            "execution_id": execution_id
        }

        print(f"âœ… ìˆ˜ë™ ëª¨ë¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì™„ë£Œ! í’ˆì§ˆ ì ìˆ˜: {quality_report.overall_score:.1f}/100")

        return ScriptGenerationResult(
            script_content=script_content,
            requirements_path=project_structure['requirements'],
            readme_path=readme_path,
            quality_score=quality_report.overall_score,
            generation_metadata=generation_metadata,
            is_production_ready=quality_report.is_production_ready
        )

    def _create_manual_model_allocation(self, selected_models: dict, agent_selection: AgentSelection):
        """ìˆ˜ë™ ì„ íƒëœ ëª¨ë¸ì„ ModelAllocation ê°ì²´ë¡œ ë³€í™˜"""
        from smart_model_allocator import ModelAllocation

        # ìˆ˜ë™ ëª¨ë¸ì„ ì—ì´ì „íŠ¸ì— ë§¤í•‘
        agent_model_mapping = {}
        model_role_mapping = {
            'planner': ['Planner', 'Project Manager', 'Product Manager'],
            'researcher': ['Researcher', 'Data Scientist', 'Research Specialist'],
            'writer': ['Writer', 'Documentation Specialist', 'Content Creator']
        }

        for agent in agent_selection.agents:
            assigned_model = None
            # ì—ì´ì „íŠ¸ ì´ë¦„ì„ ê¸°ë°˜ìœ¼ë¡œ ì ì ˆí•œ ìˆ˜ë™ ì„ íƒ ëª¨ë¸ í• ë‹¹
            for role_key, role_names in model_role_mapping.items():
                if any(role_name.lower() in agent.name.lower() for role_name in role_names):
                    assigned_model = selected_models.get(role_key, 'gemini-flash')
                    break

            if not assigned_model:
                # ê¸°ë³¸ê°’ í• ë‹¹
                assigned_model = list(selected_models.values())[0] if selected_models.values() else 'gemini-flash'

            agent_model_mapping[agent.name] = assigned_model

        return ModelAllocation(
            agent_model_mapping=agent_model_mapping,
            total_estimated_cost=1.0,  # ìˆ˜ë™ ì„ íƒì´ë¯€ë¡œ ë¹„ìš© ê³„ì‚° ìƒëµ
            strategy="manual",
            budget_utilization=0.5
        )

def main():
    """í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    generator = AdaptiveScriptGenerator()

    # í…ŒìŠ¤íŠ¸ ìš”êµ¬ì‚¬í•­
    test_requirement = "ë§¤ì¼ êµ­ë‚´ íŒŒì›Œë¶ˆë¡œê±° ìƒìœ„ 10ê°œë¥¼ ì¡°ì‚¬í•˜ê³ , ì¡°ì‚¬ ë‹¹ì¼ ì£¼ì œë¥¼ í™•ì¸í•´ì„œ ê°€ì¥ ë§ì´ ì‚¬ìš©ëœ ì£¼ì œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¦¬ì„œì¹˜ë¥¼ í•œí›„ ë¸”ë¡œê·¸ë¥¼ ì‘ì„±í•´ì¤˜"
    test_project_path = "test_generated_project"
    test_execution_id = "test_" + datetime.now().strftime("%Y%m%d_%H%M%S")

    print("=== ì ì‘í˜• ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì—”ì§„ í…ŒìŠ¤íŠ¸ ===")

    # ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
    result = generator.generate_optimal_script(
        requirement=test_requirement,
        project_path=test_project_path,
        execution_id=test_execution_id,
        budget="medium",
        strategy="balanced"
    )

    print(f"\nğŸ“Š ìƒì„± ê²°ê³¼:")
    print(f"í’ˆì§ˆ ì ìˆ˜: {result.quality_score:.1f}/100")
    print(f"í”„ë¡œë•ì…˜ ì¤€ë¹„: {'âœ…' if result.is_production_ready else 'âŒ'}")
    print(f"README ê²½ë¡œ: {result.readme_path}")
    print(f"Requirements ê²½ë¡œ: {result.requirements_path}")

    print(f"\nğŸ“ ìƒì„±ëœ íŒŒì¼ë“¤:")
    if os.path.exists(test_project_path):
        for file_path in Path(test_project_path).rglob("*"):
            if file_path.is_file():
                print(f"  {file_path}")

if __name__ == "__main__":
    main()