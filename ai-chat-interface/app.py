# -*- coding: utf-8 -*-
"""
AI Chat Interface - Flask Integration Server
Single Python server integrating CrewAI and MetaGPT
"""

from flask import Flask, render_template, request, jsonify, send_from_directory
from flask_cors import CORS
# Real-time monitoring removed
import os
import sys
import json
import subprocess
import threading
import time
import psutil
from datetime import datetime
import requests
from functools import wraps
from dotenv import load_dotenv
import uuid
import gevent
from supabase import create_client, Client

# Load environment variables
load_dotenv()

# UTF-8 ì¸ì½”ë”© ì „ì—­ ì„¤ì • (ê°€ì¥ ë¨¼ì € ì‹¤í–‰)
def setup_global_utf8_environment():
    """ì „ì—­ UTF-8 ì¸ì½”ë”© í™˜ê²½ ì„¤ì • (ê°•í™”ë²„ì „)"""
    import locale
    import io
    import unicodedata

    # 1ë‹¨ê³„: í™˜ê²½ ë³€ìˆ˜ ê°•ì œ ì„¤ì •
    utf8_env_vars = {
        'PYTHONIOENCODING': 'utf-8',
        'PYTHONLEGACYWINDOWSSTDIO': '0',
        'PYTHONUTF8': '1',
        'LC_ALL': 'ko_KR.UTF-8',
        'LANG': 'ko_KR.UTF-8'
    }

    for key, value in utf8_env_vars.items():
        os.environ[key] = value

    # 2ë‹¨ê³„: Windows íŠ¹ë³„ ì²˜ë¦¬ (ê°•í™”)
    if sys.platform.startswith('win'):
        try:
            # Windows ì½˜ì†” UTF-8 ëª¨ë“œ í™œì„±í™”
            os.system('chcp 65001 > nul 2>&1')

            # Windows ë ˆì§€ìŠ¤íŠ¸ë¦¬ ê¸°ë°˜ UTF-8 ì„¤ì • (ê°€ëŠ¥í•œ ê²½ìš°)
            try:
                import winreg
                key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, r"Console")
                winreg.SetValueEx(key, "CodePage", 0, winreg.REG_DWORD, 65001)
                winreg.CloseKey(key)
            except:
                pass  # ê¶Œí•œ ì—†ëŠ” ê²½ìš° ë¬´ì‹œ

            # stdout/stderr UTF-8 ì¬êµ¬ì„± (ê°•í™”)
            if hasattr(sys.stdout, 'reconfigure'):
                try:
                    sys.stdout.reconfigure(encoding='utf-8', errors='replace')
                    sys.stderr.reconfigure(encoding='utf-8', errors='replace')
                except Exception:
                    # í´ë°±: TextIOWrapper ì‚¬ìš©
                    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
                    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
            else:
                # ì´ì „ Python ë²„ì „
                sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
                sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

        except Exception as e:
            print(f"Windows UTF-8 ì„¤ì • ê²½ê³ : {e}")

    # ë¡œì¼€ì¼ ì„¤ì • ì‹œë„
    try:
        locale.setlocale(locale.LC_ALL, 'ko_KR.UTF-8')
    except:
        try:
            locale.setlocale(locale.LC_ALL, 'Korean_Korea.65001')
        except:
            try:
                locale.setlocale(locale.LC_ALL, 'C.UTF-8')
            except:
                pass  # ë¡œì¼€ì¼ ì„¤ì • ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰

    print("âœ… UTF-8 ì¸ì½”ë”© í™˜ê²½ ì„¤ì • ì™„ë£Œ")

# UTF-8 í™˜ê²½ ì¦‰ì‹œ ì„¤ì •
setup_global_utf8_environment()

# Import database module
from database import db
from security_utils import validate_request_data, check_request_security
from template_api import template_bp
from ollama_client import ollama_client
# WebSocket manager removed
# Progress tracking simplified
from admin_auth import admin_auth
from crewai_logger import crewai_logger, ExecutionPhase
from generate_crewai_script_new import generate_crewai_execution_script_with_approval

# ìƒˆë¡œìš´ ëª¨ë“ˆ import
from pre_analysis_service import pre_analysis_service
from approval_workflow import approval_workflow_manager

# Add current directory to Python path
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)

# Add CrewAI and MetaGPT paths - í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ì§ì ‘ ì°¸ì¡°
crewai_path = os.path.join(os.path.dirname(current_dir), 'CrewAi')
metagpt_path = os.path.join(os.path.dirname(current_dir), 'MetaGPT')
sys.path.append(crewai_path)
sys.path.append(metagpt_path)

# ê²½ë¡œ í™•ì¸ ì™„ë£Œ
# CrewAI: D:\GenProjects\CrewAi
# MetaGPT: D:\GenProjects\MetaGPT

app = Flask(__name__, static_folder='.', static_url_path='')

# UTF-8 ì²˜ë¦¬ ê°•í™”
app.config['JSON_AS_ASCII'] = False
app.config['JSONIFY_MIMETYPE'] = 'application/json; charset=utf-8'

# UTF-8 ì²˜ë¦¬ë¥¼ ìœ„í•œ í—¬í¼ í•¨ìˆ˜
def get_json_safely():
    """ì•ˆì „í•œ JSON íŒŒì‹±"""
    try:
        if request.is_json:
            return request.get_json(force=True)
        else:
            # ê°•ì œë¡œ JSONìœ¼ë¡œ íŒŒì‹± ì‹œë„
            raw_data = request.get_data(as_text=True)
            if raw_data.startswith('\ufeff'):  # BOM ì œê±°
                raw_data = raw_data[1:]
            return json.loads(raw_data)
    except (UnicodeDecodeError, json.JSONDecodeError, ValueError) as e:
        print(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        return None

# SocketIO removed for simplicity

# CORS ì„¤ì • ê°•í™”
CORS(app,
     origins=['http://localhost:3000', 'http://127.0.0.1:3000'],
     methods=['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS'],
     allow_headers=['Content-Type', 'Authorization'],
     supports_credentials=True,
     max_age=3600)

# WebSocket functionality removed

# Register blueprints
app.register_blueprint(template_bp)

# Import and register template routes
try:
    from template_api_routes import template_routes
    app.register_blueprint(template_routes)
    print("âœ… í…œí”Œë¦¿ API ë¼ìš°íŠ¸ ë“±ë¡ ì™„ë£Œ")
except ImportError as e:
    print(f"âš ï¸ í…œí”Œë¦¿ API ë¼ìš°íŠ¸ ë“±ë¡ ì‹¤íŒ¨: {e}")

# Import and register admin routes
try:
    from admin_api import admin_bp
    app.register_blueprint(admin_bp)
    print("âœ… ê´€ë¦¬ì API ë¼ìš°íŠ¸ ë“±ë¡ ì™„ë£Œ")
except ImportError as e:
    print(f"âš ï¸ ê´€ë¦¬ì API ë¼ìš°íŠ¸ ë“±ë¡ ì‹¤íŒ¨: {e}")

# Supabase í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
supabase_url = os.getenv("SUPABASE_URL")
supabase_key = os.getenv("SUPABASE_ANON_KEY")

if supabase_url and supabase_key:
    supabase: Client = create_client(supabase_url, supabase_key)
else:
    supabase = None
    print("âš ï¸ Supabase ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. .env íŒŒì¼ì— SUPABASE_URLê³¼ SUPABASE_ANON_KEYë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")

# CrewAI ê´€ë ¨ ì„¤ì •
CREWAI_BASE_DIR = os.path.join(os.path.dirname(current_dir), 'CrewAi')  # CrewAI ì†ŒìŠ¤ ì½”ë“œ ê²½ë¡œ
PROJECTS_BASE_DIR = os.path.join(os.path.dirname(current_dir), 'Projects')  # ìƒì„±ëœ í”„ë¡œì íŠ¸ ì €ì¥ ê²½ë¡œ
execution_status = {}  # ì „ì—­ ë³€ìˆ˜ë¡œ ì‹¤í–‰ ìƒíƒœ ê´€ë¦¬
# Client management simplified

# ë³´ì•ˆ í—¤ë” ì„¤ì •
@app.after_request
def set_security_headers(response):
    # XSS ë³´í˜¸
    response.headers['X-Content-Type-Options'] = 'nosniff'
    response.headers['X-Frame-Options'] = 'DENY'
    response.headers['X-XSS-Protection'] = '1; mode=block'

    # HSTS (HTTPS ê°•ì œ)
    response.headers['Strict-Transport-Security'] = 'max-age=31536000; includeSubDomains'

    # CSP (Content Security Policy)
    response.headers['Content-Security-Policy'] = "default-src 'self'; script-src 'self' 'unsafe-inline' 'unsafe-eval' https://unpkg.com https://cdnjs.cloudflare.com; style-src 'self' 'unsafe-inline'; img-src 'self' data: https:; connect-src 'self' http://localhost:* https://unpkg.com https://cdnjs.cloudflare.com"

    return response

# Port configuration - í†µí•© í¬íŠ¸
PORT = 3000

# ë¼ìš°íŒ… ì„¤ì •
CREWAI_URL = "http://localhost:3001"  # ë‚´ë¶€ CrewAI ì„œë²„
METAGPT_URL = "http://localhost:3002"  # ë‚´ë¶€ MetaGPT ì„œë²„

# Global variables
execution_status = {}
request_counts = {}  # IPë³„ ìš”ì²­ ì¹´ìš´íŠ¸
request_timestamps = {}  # IPë³„ ìš”ì²­ ì‹œê°„

# ==================== SECURITY DECORATORS ====================

def rate_limit(max_requests=60, window_seconds=60):
    """Rate limiting decorator"""
    def decorator(f):
        @wraps(f)
        def decorated(*args, **kwargs):
            client_ip = request.environ.get('HTTP_X_FORWARDED_FOR', request.environ.get('REMOTE_ADDR', 'unknown'))
            current_time = time.time()

            # IPë³„ ìš”ì²­ ê¸°ë¡ ì´ˆê¸°í™”
            if client_ip not in request_counts:
                request_counts[client_ip] = []

            # ìœˆë„ìš° ì‹œê°„ ë°–ì˜ ìš”ì²­ ì œê±°
            request_counts[client_ip] = [
                timestamp for timestamp in request_counts[client_ip]
                if current_time - timestamp < window_seconds
            ]

            # ìš”ì²­ ì œí•œ í™•ì¸
            if len(request_counts[client_ip]) >= max_requests:
                return jsonify({
                    'error': 'Rate limit exceeded',
                    'message': f'ìµœëŒ€ {max_requests}ê°œì˜ ìš”ì²­ì´ {window_seconds}ì´ˆ ë‚´ì— í—ˆìš©ë©ë‹ˆë‹¤',
                    'retry_after': window_seconds
                }), 429

            # í˜„ì¬ ìš”ì²­ ê¸°ë¡
            request_counts[client_ip].append(current_time)

            return f(*args, **kwargs)

        return decorated
    return decorator

def validate_json_input(required_fields=None):
    """JSON ì…ë ¥ ê²€ì¦ ë°ì½”ë ˆì´í„°"""
    def decorator(f):
        @wraps(f)
        def decorated(*args, **kwargs):
            if not request.is_json:
                return jsonify({'error': 'Content-Type must be application/json'}), 400

            data = request.get_json()
            if not data:
                return jsonify({'error': 'Empty JSON data'}), 400

            # í•„ìˆ˜ í•„ë“œ ê²€ì¦
            if required_fields:
                missing_fields = [field for field in required_fields if field not in data]
                if missing_fields:
                    return jsonify({
                        'error': 'Missing required fields',
                        'missing_fields': missing_fields
                    }), 400

            return f(*args, **kwargs)

        return decorated
    return decorator

# ==================== AUTHENTICATION DECORATORS ====================

def token_required(f):
    """JWT token required decorator"""
    @wraps(f)
    def decorated(*args, **kwargs):
        token = None
        auth_header = request.headers.get('Authorization')

        if auth_header:
            try:
                token = auth_header.split(' ')[1]  # Bearer <token>
            except IndexError:
                return jsonify({'error': 'Invalid token format'}), 401

        if not token:
            return jsonify({'error': 'Token is missing'}), 401

        token_result = db.verify_jwt_token(token)
        if not token_result['success']:
            return jsonify({'error': token_result['error']}), 401

        request.current_user = token_result['payload']
        return f(*args, **kwargs)

    return decorated

def optional_auth(f):
    """Optional authentication decorator"""
    @wraps(f)
    def decorated(*args, **kwargs):
        token = None
        auth_header = request.headers.get('Authorization')

        if auth_header:
            try:
                token = auth_header.split(' ')[1]
                token_result = db.verify_jwt_token(token)
                if token_result['success']:
                    request.current_user = token_result['payload']
            except:
                pass

        if not hasattr(request, 'current_user'):
            request.current_user = None

        return f(*args, **kwargs)

    return decorated


@app.route('/')
def index():
    """í†µí•© ëŒ€ì‹œë³´ë“œ ë©”ì¸ í˜ì´ì§€"""
    return send_from_directory('.', 'dashboard.html')

@app.route('/crewai')
def crewai_interface():
    """CrewAI ì¸í„°í˜ì´ìŠ¤"""
    return send_from_directory('.', 'crewai.html')

@app.route('/crewai/logs')
def crewai_logs():
    """CrewAI ë¡œê¹… ëŒ€ì‹œë³´ë“œ"""
    return send_from_directory('.', 'crewai_logs.html')

@app.route('/metagpt')
def metagpt_interface():
    """MetaGPT ì¸í„°í˜ì´ìŠ¤"""
    return send_from_directory('.', 'metagpt.html')

@app.route('/templates')
def templates_interface():
    """í”„ë¡œì íŠ¸ í…œí”Œë¦¿ ì¸í„°í˜ì´ìŠ¤"""
    return send_from_directory('.', 'templates.html')

@app.route('/projects')
def projects_interface():
    """í”„ë¡œì íŠ¸ ê´€ë¦¬ ëŒ€ì‹œë³´ë“œ"""
    return send_from_directory('.', 'projects.html')

@app.route('/admin')
def admin_interface():
    """ê´€ë¦¬ì ëŒ€ì‹œë³´ë“œ"""
    return send_from_directory('.', 'admin.html')


@app.route('/<path:filename>')
def serve_static(filename):
    """Static file serving"""
    return send_from_directory('.', filename)


# ==================== API ENDPOINTS ====================

@app.route('/api/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    database_status = db.test_connection()

    return jsonify({
        'status': 'OK',
        'message': 'AI Chat Interface Server is running',
        'server': 'Flask (Python)',
        'timestamp': datetime.now().isoformat(),
        'database': {
            'connected': database_status.get('connected', False),
            'message': database_status.get('message', ''),
            'simulation_mode': database_status.get('simulation_mode', False)
        }
    })


def check_crewai_service():
    """Check CrewAI service status"""
    try:
        # Check if CrewAI server is running using main page
        response = requests.get(f'{CREWAI_URL}/', timeout=2)
        return 'available' if response.status_code == 200 else 'unavailable'
    except:
        return 'unavailable'


def check_metagpt_service():
    """Check MetaGPT service status"""
    try:
        # Check MetaGPT environment
        metagpt_script = os.path.join(metagpt_path, 'run_metagpt.py')
        return 'available' if os.path.exists(metagpt_script) else 'unavailable'
    except:
        return 'unavailable'


@app.route('/api/crewai', methods=['POST'])
def handle_crewai_request():
    """Handle CrewAI requests with enhanced message classification and project management"""
    data = request.get_json()
    requirement = data.get('requirement')
    selected_models = data.get('selectedModels', {})
    pre_analysis_model = data.get('preAnalysisModel', 'gemini-flash')  # ì‚¬ì „ ë¶„ì„ ëª¨ë¸ ì¶”ê°€
    project_id = data.get('projectId')

    if not requirement:
        return jsonify({'error': 'Requirement is required'}), 400

    # ê°•í™”ëœ ë©”ì‹œì§€ ì²˜ë¦¬ ì‹œìŠ¤í…œ ì‚¬ìš©
    try:
        from enhanced_project_initializer import EnhancedProjectInitializer
        from message_classifier import MessageClassifier, MessageType

        # ë©”ì‹œì§€ ë¶„ë¥˜ê¸° ì´ˆê¸°í™”
        classifier = MessageClassifier()
        initializer = EnhancedProjectInitializer(PROJECTS_BASE_DIR)

        # ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘ (ê¸°ì¡´ í”„ë¡œì íŠ¸ ì •ë³´)
        context = {}
        if project_id:
            context = initializer.get_project_context(project_id) or {}

        # ë©”ì‹œì§€ ì²˜ë¦¬
        processing_result = initializer.process_user_message(requirement, context)

        # ì²˜ë¦¬ ê²°ê³¼ì— ë”°ë¥¸ ë¶„ê¸°
        if processing_result['action'] == 'project_created':
            # ìƒˆ í”„ë¡œì íŠ¸ ìƒì„±ë¨ - ê¸°ì¡´ ë¡œì§ìœ¼ë¡œ ì‹¤í–‰
            project_info = processing_result['project']
            requirement = project_info.get('original_requirements', requirement)  # ì •ì œëœ ìš”êµ¬ì‚¬í•­ ì‚¬ìš©
            project_path = project_info['project_path']
            project_name = project_info['project_name']

            # ê°•í™”ëœ ì‹¤í–‰ê¸° ì‚¬ìš© ì„¤ì •
            use_enhanced_executor = True

        elif processing_result['action'] == 'continue_project':
            # ê¸°ì¡´ í”„ë¡œì íŠ¸ ê³„ì† ì§„í–‰
            project_id_only = processing_result['project_id']
            project_path = os.path.join(PROJECTS_BASE_DIR, project_id_only)
            project_name = project_id_only
            use_enhanced_executor = True

        elif processing_result['action'] == 'resume_specific_project':
            # íŠ¹ì • í”„ë¡œì íŠ¸ ì¬ê°œ
            project_id_only = processing_result['project_id']
            project_path = os.path.join(PROJECTS_BASE_DIR, project_id_only)
            project_name = project_id_only
            resume_point = processing_result.get('resume_point')
            use_enhanced_executor = True

        elif processing_result['action'] == 'clarification_needed':
            # ëª…í™•í™” í•„ìš”
            return jsonify({
                'success': False,
                'error': 'Clarification needed',
                'message': processing_result['message'],
                'classification': processing_result.get('classification'),
                'suggestion': 'êµ¬ì²´ì ì¸ í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.'
            }), 400

        else:
            # ê¸°ë³¸ ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§ ì‚¬ìš©)
            use_enhanced_executor = False

    except ImportError:
        print("ê°•í™”ëœ ì‹œìŠ¤í…œì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        use_enhanced_executor = False
    except Exception as e:
        print(f"ê°•í™”ëœ ì‹œìŠ¤í…œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        use_enhanced_executor = False

    # Enhanced executorë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ë¡œì§ ì‚¬ìš©
    if not use_enhanced_executor or not 'project_path' in locals():
        # ê¸°ë³¸ í”„ë¡œì íŠ¸ ìƒì„± ë¡œì§
        if not project_id:
            existing_projects = [d for d in os.listdir(PROJECTS_BASE_DIR) if d.startswith('project_') and os.path.isdir(os.path.join(PROJECTS_BASE_DIR, d))]
            project_number = len(existing_projects) + 1
            project_name = f"project_{project_number:05d}"
            project_path = os.path.join(PROJECTS_BASE_DIR, project_name)
        else:
            # project_idê°€ ì´ë¯¸ "project_" ì ‘ë‘ì‚¬ë¥¼ ê°€ì§€ê³  ìˆëŠ”ì§€ í™•ì¸
            if project_id.startswith('project_'):
                project_name = project_id
            else:
                project_name = f"project_{project_id}"
            project_path = os.path.join(PROJECTS_BASE_DIR, project_name)

    # ì‹¤í–‰ ID ìƒì„±
    execution_id = str(uuid.uuid4())
    crew_id = f"crew_{int(time.time())}"

    # ğŸ” ì‚¬ì „ ë¶„ì„ ë° ìŠ¹ì¸ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    print(f"[CREWAI] ì‚¬ì „ ë¶„ì„ ì‹œì‘: execution_id={execution_id}")

    try:
        # 1. ì‚¬ì „ ë¶„ì„ ì„œë¹„ìŠ¤ í˜¸ì¶œ
        print(f"[CREWAI] ì‚¬ì „ ë¶„ì„ ëª¨ë¸: {pre_analysis_model}")
        analysis_result = pre_analysis_service.analyze_user_request(
            user_request=requirement,
            framework="crewai",
            model=pre_analysis_model
        )

        # 2. ë¶„ì„ ê²°ê³¼ ê²€ì¦
        if analysis_result.get('status') == 'error' or analysis_result.get('error'):
            error_msg = analysis_result.get('error', 'ì‚¬ì „ ë¶„ì„ ì‹¤íŒ¨')
            print(f"[CREWAI ERROR] ì‚¬ì „ ë¶„ì„ ì‹¤íŒ¨: {error_msg}")
            return jsonify({'error': error_msg}), 500

        print(f"[CREWAI] ì‚¬ì „ ë¶„ì„ ì„±ê³µ: {analysis_result.get('analysis', {}).get('summary', 'N/A')}")

        # 3. í”„ë¡œì íŠ¸ ì •ë³´ ë¯¸ë¦¬ ì¤€ë¹„ (ìŠ¹ì¸ í›„ ì‹¤í–‰ì— í•„ìš”)
        if not project_id:
            # ìƒˆ í”„ë¡œì íŠ¸ ê²½ë¡œ ìƒì„± (ì‹¤ì œ ë””ë ‰í† ë¦¬ëŠ” ìŠ¹ì¸ í›„ ìƒì„±)
            existing_projects = [d for d in os.listdir(PROJECTS_BASE_DIR) if d.startswith('project_') and os.path.isdir(os.path.join(PROJECTS_BASE_DIR, d))]
            project_number = len(existing_projects) + 1
            project_name = f"project_{project_number:05d}"
            project_path = os.path.join(PROJECTS_BASE_DIR, project_name)
        else:
            if project_id.startswith('project_'):
                project_name = project_id
            else:
                project_name = f"project_{project_id}"
            project_path = os.path.join(PROJECTS_BASE_DIR, project_name)

        print(f"[CREWAI] í”„ë¡œì íŠ¸ ê²½ë¡œ ì¤€ë¹„: {project_path}")

        # 4. ìŠ¹ì¸ ìš”ì²­ì— í¬í•¨í•  í”„ë¡œì íŠ¸ ë°ì´í„° êµ¬ì„±
        project_data = {
            'execution_id': execution_id,
            'crew_id': crew_id,
            'framework': 'crewai',
            'requirement': requirement,
            'selected_models': selected_models,
            'pre_analysis_model': pre_analysis_model,
            'project_id': project_id,
            'project_name': project_name,
            'project_path': project_path,
            'projects_base_dir': PROJECTS_BASE_DIR,
            'created_at': datetime.now().isoformat()
        }

        print(f"[CREWAI] í”„ë¡œì íŠ¸ ë°ì´í„° êµ¬ì„± ì™„ë£Œ: {project_data['project_name']}")

        # 5. ìŠ¹ì¸ ìš”ì²­ ìƒì„± (í”„ë¡œì íŠ¸ ë°ì´í„° í¬í•¨)
        approval_id = approval_workflow_manager.create_approval_request(
            analysis_result=analysis_result,
            project_data=project_data,  # ì‹¤í–‰ì— í•„ìš”í•œ ëª¨ë“  ì •ë³´ í¬í•¨
            project_id=project_id,
            requester="crewai_interface"
        )

        print(f"[CREWAI] ìŠ¹ì¸ ìš”ì²­ ìƒì„± ì™„ë£Œ: {approval_id}")

        # 6. ìŠ¹ì¸ ëŒ€ê¸° ì‘ë‹µ ë°˜í™˜
        return jsonify({
            'success': True,
            'message': 'AI ê³„íšì´ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤. ìŠ¹ì¸ì„ ê¸°ë‹¤ë¦¬ê³  ìˆìŠµë‹ˆë‹¤.',
            'approval_id': approval_id,
            'execution_id': execution_id,
            'status': 'pending_approval',
            'analysis': analysis_result.get('analysis', {}),
            'project_info': {
                'name': project_name,
                'path': project_path
            },
            'requires_approval': True
        })

    except Exception as analysis_error:
        print(f"[CREWAI ERROR] ì‚¬ì „ ë¶„ì„ ì˜¤ë¥˜: {analysis_error}")
        import traceback
        print(f"[CREWAI ERROR] ìŠ¤íƒ ì¶”ì :\n{traceback.format_exc()}")

        # ì‚¬ì „ ë¶„ì„ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë°˜í™˜ (ê¸°ì¡´ ë°©ì‹ ì§„í–‰ ì œê±°)
        return jsonify({
            'error': f'ì‚¬ì „ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(analysis_error)}',
            'details': 'AI ê³„íš ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.',
            'execution_id': execution_id
        }), 500

    try:
        # ìƒì„¸ ë¡œê¹… ì‹œì‘
        crewai_logger.start_execution_logging(execution_id, crew_id, {
            'requirement': requirement,
            'selected_models': selected_models,
            'project_id': project_id
        })

        crewai_logger.start_step_tracking(execution_id, crew_id, total_steps=10)

        # ë‹¨ê³„ 1: ì‹œìŠ¤í…œ ê²€ì¦
        crewai_logger.advance_step(execution_id, crew_id, "ì‹œìŠ¤í…œ ê²€ì¦", "ì‹œì‘", ExecutionPhase.VALIDATION)
        crewai_logger.log_system_check(execution_id, crew_id, "UTF-8 ì¸ì½”ë”© í™˜ê²½", True)
        crewai_logger.log_system_check(execution_id, crew_id, "í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ì ‘ê·¼", os.path.exists(PROJECTS_BASE_DIR))

        # ë‹¨ê³„ 2: í”„ë¡œì íŠ¸ ì´ˆê¸°í™”
        crewai_logger.advance_step(execution_id, crew_id, "í”„ë¡œì íŠ¸ ì´ˆê¸°í™”", "ì‹œì‘", ExecutionPhase.INITIALIZATION)

        if not project_id:
            # ìƒˆ í”„ë¡œì íŠ¸ ìƒì„±
            # í”„ë¡œì íŠ¸ ë²ˆí˜¸ ìƒì„± (ê¸°ì¡´ í”„ë¡œì íŠ¸ ê°œìˆ˜ + 1)
            existing_projects = [d for d in os.listdir(PROJECTS_BASE_DIR) if d.startswith('project_') and os.path.isdir(os.path.join(PROJECTS_BASE_DIR, d))]
            project_number = len(existing_projects) + 1
            project_name = f"project_{project_number:05d}"
            project_path = os.path.join(PROJECTS_BASE_DIR, project_name)
        else:
            # ê¸°ì¡´ í”„ë¡œì íŠ¸ ì‚¬ìš© - project_idê°€ ì´ë¯¸ project_ë¥¼ í¬í•¨í•˜ëŠ”ì§€ í™•ì¸
            if project_id.startswith('project_'):
                project_name = project_id
            else:
                project_name = f"project_{project_id}"
            project_path = os.path.join(PROJECTS_BASE_DIR, project_name)

        # ë‹¨ê³„ 3: í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
        crewai_logger.advance_step(execution_id, crew_id, "ë””ë ‰í† ë¦¬ ìƒì„±", project_path, ExecutionPhase.DIRECTORY_CREATION)

        try:
            os.makedirs(project_path, exist_ok=True)
            crewai_logger.log_directory_operation(execution_id, crew_id, "ìƒì„±", project_path, True)
        except Exception as dir_error:
            crewai_logger.log_directory_operation(execution_id, crew_id, "ìƒì„±", project_path, False, {"error": str(dir_error)})
            raise dir_error

        # ë‹¨ê³„ 4: í™˜ê²½ ì„¤ì •
        crewai_logger.advance_step(execution_id, crew_id, "í™˜ê²½ ì„¤ì •", "", ExecutionPhase.ENVIRONMENT_SETUP)

        # UTF-8 í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
        env_vars = {
            'PYTHONIOENCODING': 'utf-8',
            'PYTHONLEGACYWINDOWSSTDIO': '0',
            'CREWAI_PROJECT_PATH': project_path,
            'CREWAI_REQUIREMENT': requirement,
            'CREWAI_EXECUTION_ID': execution_id
        }

        crewai_logger.log_environment_setup(execution_id, crew_id, env_vars, True)

        # ë‹¨ê³„ 5: CrewAI ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
        crewai_logger.advance_step(execution_id, crew_id, "ìŠ¤í¬ë¦½íŠ¸ ìƒì„±", "", ExecutionPhase.FILE_GENERATION)

        # ê³ ë„í™”ëœ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±ê¸° ì‚¬ìš© (ëª¨ë“  CrewAI ìš”ì²­ì— ì ìš©)
        try:
            from enhanced_script_generator import generate_enhanced_crewai_script
            print(f"[CREWAI] ê³ ë„í™”ëœ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±ê¸° ì‚¬ìš©")
            script_content = generate_enhanced_crewai_script(requirement, selected_models, project_path, execution_id)
        except ImportError:
            print(f"[CREWAI] ìŠ¹ì¸ ê¸°ë°˜ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±ê¸° ì‚¬ìš© (fallback)")
            script_content = generate_crewai_execution_script_with_approval(
                requirement=requirement,
                selected_models=selected_models,
                project_path=project_path,
                execution_id=execution_id
            )

        script_path = os.path.join(project_path, "execute_crewai.py")

        try:
            # UTF-8 ì„œë¡œê²Œì´íŠ¸ ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì•ˆì „í•œ ë¬¸ìì—´ ì •ë¦¬
            import unicodedata

            # 1ë‹¨ê³„: ìœ ë‹ˆì½”ë“œ ì •ê·œí™”
            normalized_content = unicodedata.normalize('NFKC', script_content)

            # 2ë‹¨ê³„: ì„œë¡œê²Œì´íŠ¸ ë¬¸ì ì œê±°
            safe_content = ''.join(char for char in normalized_content
                                 if not (0xD800 <= ord(char) <= 0xDFFF))

            # 3ë‹¨ê³„: UTF-8 ì•ˆì „ ì¸ì½”ë”©/ë””ì½”ë”©
            safe_content = safe_content.encode('utf-8', errors='replace').decode('utf-8')

            # 4ë‹¨ê³„: íŒŒì¼ ì“°ê¸° (Windows í˜¸í™˜ì„± ê°•í™”)
            with open(script_path, 'w', encoding='utf-8', errors='replace', newline='\n') as f:
                f.write(safe_content)

            crewai_logger.log_file_generation(execution_id, crew_id, script_path, "Python Script", len(safe_content), True, {
                "original_length": len(script_content),
                "processed_length": len(safe_content),
                "encoding": "utf-8",
                "processing_steps": ["normalize", "surrogate_filter", "utf8_encode"]
            })
        except Exception as file_error:
            crewai_logger.log_file_generation(execution_id, crew_id, script_path, "Python Script", 0, False, {"error": str(file_error)})
            crewai_logger.log_error(execution_id, crew_id, file_error, "CrewAI ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ìƒì„±", {
                "script_path": script_path,
                "content_preview": script_content[:200] if script_content else "None"
            })
            raise file_error

        # ë‹¨ê³„ 6: ìš”êµ¬ì‚¬í•­ íŒŒì¼ ìƒì„±
        crewai_logger.advance_step(execution_id, crew_id, "ìš”êµ¬ì‚¬í•­ ì €ì¥", "", ExecutionPhase.FILE_GENERATION)

        requirements_path = os.path.join(project_path, "requirements.txt")
        requirements_content = "\n".join([
            "crewai>=0.28.8",
            "langchain>=0.1.0",
            "langchain-openai>=0.0.5",
            "python-dotenv>=1.0.0"
        ])

        try:
            # UTF-8 ì•ˆì „ ì„œë¡œê²Œì´íŠ¸ ì²˜ë¦¬
            safe_requirements = requirements_content.encode('utf-8', errors='replace').decode('utf-8')
            with open(requirements_path, 'w', encoding='utf-8', errors='replace') as f:
                f.write(safe_requirements)
            crewai_logger.log_file_generation(execution_id, crew_id, requirements_path, "Requirements", len(safe_requirements), True)
        except Exception as req_error:
            crewai_logger.log_file_generation(execution_id, crew_id, requirements_path, "Requirements", 0, False, {"error": str(req_error)})

        # ë‹¨ê³„ 7: CrewAI ì‹¤í–‰
        crewai_logger.advance_step(execution_id, crew_id, "CrewAI ì‹¤í–‰", "ì‹œì‘", ExecutionPhase.EXECUTION)

        # ì‹¤ì œ CrewAI ì‹¤í–‰ (ë°±ê·¸ë¼ìš´ë“œì—ì„œ)
        def execute_crewai_async():
            start_time = int(time.time() * 1000)  # ë°€ë¦¬ì´ˆ ë‹¨ìœ„ ì‹œì‘ ì‹œê°„
            try:
                # í˜„ì¬ í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (í•œê¸€ ì¸ì½”ë”© ê°•í™”)
                current_env = os.environ.copy()
                current_env.update(env_vars)

                # Windows íŠ¹ë³„ UTF-8 ì„¤ì •
                if sys.platform.startswith('win'):
                    current_env['PYTHONIOENCODING'] = 'utf-8'
                    current_env['PYTHONLEGACYWINDOWSSTDIO'] = '0'
                    current_env['PYTHONUTF8'] = '1'
                    current_env['CHCP'] = '65001'

                # CrewAI ì‹¤í–‰ ëª…ë ¹ (í•œê¸€ ì§€ì› ê°•í™”)
                cmd = [sys.executable, '-u', '-X', 'utf8', script_path] if sys.platform.startswith('win') else [sys.executable, '-u', script_path]

                crewai_logger.log_subprocess_start(execution_id, crew_id, script_path, current_env)

                # UTF-8 ì¸ì½”ë”© í…ŒìŠ¤íŠ¸
                test_korean = "í•œê¸€ í…ŒìŠ¤íŠ¸ ë¬¸ìì—´"
                crewai_logger.log_korean_encoding_test(execution_id, crew_id, test_korean, "UTF-8", True)

                # í”„ë¡œì„¸ìŠ¤ ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€ ë¡œì§
                script_name = os.path.basename(script_path)
                existing_processes = []

                try:
                    # í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ Python í”„ë¡œì„¸ìŠ¤ ì¤‘ ê°™ì€ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì—¬ë¶€ í™•ì¸
                    for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
                        try:
                            if proc.info['name'] and 'python' in proc.info['name'].lower():
                                cmdline = proc.info['cmdline'] or []
                                # ê°™ì€ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì„ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
                                if any(script_name in arg for arg in cmdline):
                                    existing_processes.append({
                                        'pid': proc.info['pid'],
                                        'cmdline': ' '.join(cmdline)
                                    })
                        except (psutil.NoSuchProcess, psutil.AccessDenied):
                            continue

                    if existing_processes:
                        warning_msg = f"âš ï¸ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ {script_name} í”„ë¡œì„¸ìŠ¤ ë°œê²¬ ({len(existing_processes)}ê°œ)"
                        crewai_logger.log_warning(execution_id, crew_id, warning_msg, {
                            'existing_processes': existing_processes,
                            'script_path': script_path
                        })
                        print(f"{warning_msg}")
                        for proc in existing_processes:
                            print(f"  - PID {proc['pid']}: {proc['cmdline'][:100]}...")

                        # ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤ê°€ ìˆì–´ë„ ê³„ì† ì§„í–‰ (ì‚¬ìš©ìê°€ ì˜ë„ì ìœ¼ë¡œ ì‹¤í–‰í–ˆì„ ìˆ˜ ìˆìŒ)
                        # í•˜ì§€ë§Œ ê²½ê³  ë¡œê·¸ëŠ” ë‚¨ê¹€

                except Exception as check_error:
                    crewai_logger.log_error(execution_id, crew_id, check_error, "í”„ë¡œì„¸ìŠ¤ ì¤‘ë³µ í™•ì¸")

                # ì„œë¸Œí”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ (ì¸ì½”ë”© ì•ˆì „ì„± ê°•í™”)
                try:
                    process = subprocess.Popen(
                        cmd,
                        cwd=project_path,
                        env=current_env,
                        stdout=subprocess.PIPE,
                        stderr=subprocess.PIPE,
                        text=True,
                        encoding='utf-8',
                        errors='replace',  # ì¸ì½”ë”© ì˜¤ë¥˜ ì‹œ ëŒ€ì²´ ë¬¸ì ì‚¬ìš©
                        universal_newlines=True
                    )
                except Exception as proc_error:
                    crewai_logger.log_error(execution_id, crew_id, proc_error, "ì„œë¸Œí”„ë¡œì„¸ìŠ¤ ìƒì„±")
                    # í´ë°± ë°©ì‹ìœ¼ë¡œ ì¬ì‹œë„
                    process = subprocess.Popen(
                        cmd,
                        cwd=project_path,
                        env=current_env,
                        stdout=subprocess.PIPE,
                        stderr=subprocess.PIPE,
                        text=True
                    )

                crewai_logger.log_subprocess_execution(execution_id, crew_id, " ".join(cmd), project_path, True, process.pid)

                # ì‹¤ì‹œê°„ ì¶œë ¥ ì²˜ë¦¬
                stdout, stderr = process.communicate()

                if stdout:
                    crewai_logger.log_subprocess_output(execution_id, crew_id, "stdout", stdout)
                    lines = stdout.split('\n')
                    for i, line in enumerate(lines[:20]):  # ì²˜ìŒ 20ì¤„ë§Œ ì²˜ë¦¬
                        if line.strip():
                            crewai_logger.log_output_processing(execution_id, crew_id, "stdout", line, i+1, True)

                if stderr:
                    crewai_logger.log_subprocess_output(execution_id, crew_id, "stderr", stderr)

                exit_code = process.returncode
                success = exit_code == 0

                # ì™„ë£Œ ë¡œê¹…
                end_time = int(time.time() * 1000)
                total_duration = end_time - start_time
                crewai_logger.log_completion(execution_id, crew_id, success, total_duration, {
                    "exit_code": exit_code,
                    "project_path": project_path,
                    "files_created": len([f for f in os.listdir(project_path) if os.path.isfile(os.path.join(project_path, f))])
                })

            except Exception as exec_error:
                crewai_logger.log_error(execution_id, crew_id, exec_error, "CrewAI ë¹„ë™ê¸° ì‹¤í–‰")

        # ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ ì‹œì‘
        execution_thread = threading.Thread(target=execute_crewai_async)
        execution_thread.daemon = True
        execution_thread.start()

        # ë‹¨ê³„ 8: ì‘ë‹µ ë°˜í™˜
        crewai_logger.advance_step(execution_id, crew_id, "ì‘ë‹µ ì¤€ë¹„", "ì™„ë£Œ", ExecutionPhase.COMPLETION)

        return jsonify({
            'success': True,
            'execution_id': execution_id,
            'crew_id': crew_id,
            'requirement': requirement,
            'project_path': project_path,
            'project_name': project_name,
            'result': f'CrewAI ì‹¤í–‰ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.\n\ní”„ë¡œì íŠ¸: {project_name}\nê²½ë¡œ: {project_path}\n\nì‘ì—…ì´ ì™„ë£Œë˜ë©´ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.',
            'models_used': selected_models,
            'agents_involved': ["Planner", "Researcher", "Writer"],
            'status': 'executing',
            'files_created': [
                os.path.basename(script_path),
                os.path.basename(requirements_path)
            ]
        })

    except Exception as e:
        crewai_logger.log_error(execution_id, crew_id, e, "CrewAI ìš”ì²­ ì²˜ë¦¬")
        return jsonify({
            'success': False,
            'execution_id': execution_id,
            'error': 'Error processing CrewAI request',
            'details': str(e)
        }), 500


def generate_crewai_execution_script(requirement: str, selected_models: dict, project_path: str, execution_id: str) -> str:
    """
    CrewAI ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± - í†µí•©ë˜ê³  ì•ˆì „í•œ ë°©ì‹
    ì´ì „ì˜ ëª¨ìˆœëœ ì´ì¤‘ ì²˜ë¦¬ êµ¬ì¡°ë¥¼ ë‹¨ì¼í™”í•˜ì—¬ ì¼ê´€ì„± í™•ë³´
    """
    import json
    from datetime import datetime

    # 1. ë‹¨ìˆœí™”ëœ ì•ˆì „í•œ í…ìŠ¤íŠ¸ ì²˜ë¦¬ í•¨ìˆ˜
    def safe_text_escape(text: str, max_length: int = 400) -> str:
        """ë‹¨ìˆœí™”ëœ í…ìŠ¤íŠ¸ ì²˜ë¦¬ - ìµœì†Œí•œì˜ ì´ìŠ¤ì¼€ì´í•‘ë§Œ ìˆ˜í–‰"""
        if len(text) > max_length:
            text = text[:max_length] + '...'
        # í•„ìˆ˜ ì´ìŠ¤ì¼€ì´í•‘ë§Œ ìˆ˜í–‰
        text = text.replace('"', "'").replace('\n', '\\n').replace('\r', '')
        return text

    def safe_path_escape(path: str) -> str:
        """ê²½ë¡œ ë¬¸ìì—´ ì•ˆì „ ì²˜ë¦¬ (Windows/Linux í˜¸í™˜)"""
        return path.replace('\\', '\\\\')

    # 2. ì•ˆì „í•œ ë§¤ê°œë³€ìˆ˜ ì¤€ë¹„
    safe_requirement = safe_text_escape(requirement)
    safe_project_path = safe_path_escape(project_path)

    # ëª¨ë¸ ì •ê·œí™” - ëª¨ë“  ëª¨ë¸ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš© (CrewAIì—ì„œ ì²˜ë¦¬)
    normalized_models = {}
    for role, model in selected_models.items():
        normalized_models[role] = model

    # ê¸°ë³¸ê°’ì´ ì—†ëŠ” ê²½ìš° gemini-flash ì„¤ì •
    if not normalized_models:
        normalized_models = {
            "planner": "gemini-flash",
            "researcher": "gemini-flash",
            "writer": "gemini-flash"
        }

    # 3. ìŠ¤í¬ë¦½íŠ¸ í…œí”Œë¦¿ (ë³€ìˆ˜ëª… ì¼ì¹˜ì„± í™•ë³´)
    script_template = '''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CrewAI ìë™ ìƒì„± ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
ì‹¤í–‰ ID: {execution_id}
ìƒì„± ì‹œê°„: {generation_time}
"""

import os
import sys
from datetime import datetime
from crewai import Agent, Task, Crew, Process, LLM
from langchain_openai import ChatOpenAI
import json

# UTF-8 ì¸ì½”ë”© í™˜ê²½ ì„¤ì • (ê°„ì†Œí™” ë²„ì „)
def setup_utf8_environment():
    """UTF-8 ì¸ì½”ë”© í™˜ê²½ ì„¤ì •"""
    import io

    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
    os.environ['PYTHONIOENCODING'] = 'utf-8'
    os.environ['PYTHONUTF8'] = '1'

    # Windows ì½˜ì†” UTF-8 ì„¤ì •
    if sys.platform.startswith('win'):
        try:
            os.system('chcp 65001 > nul 2>&1')
        except:
            pass

    # stdout/stderr UTF-8 ì¬êµ¬ì„±
    if hasattr(sys.stdout, 'reconfigure'):
        try:
            sys.stdout.reconfigure(encoding='utf-8', errors='replace')
            sys.stderr.reconfigure(encoding='utf-8', errors='replace')
        except:
            pass

    return True

# í™˜ê²½ ì„¤ì • ì‹¤í–‰
setup_utf8_environment()

print("âœ… UTF-8 ì¸ì½”ë”© í™˜ê²½ ì„¤ì • ì™„ë£Œ")
print("ğŸš€ CrewAI ì‹¤í–‰ ì‹œì‘...")
print("ğŸ¯ ìš”êµ¬ì‚¬í•­: {requirement_display}")
print(f"ğŸ“ í”„ë¡œì íŠ¸ ê²½ë¡œ: {project_path}")
print(f"ğŸ†” ì‹¤í–‰ ID: {execution_id}")
print("\\n" + "="*50 + "\\n")

# LLM ëª¨ë¸ ì„¤ì •
def get_llm_model(role_name: str):
    """ì—­í• ë³„ LLM ëª¨ë¸ ë°˜í™˜"""
    # ë™ì  ëª¨ë¸ ë§¤í•‘ - ì‚¬ìš©ì ì„ íƒ ëª¨ë¸ ì‚¬ìš©
    models = {normalized_models_str}
    model_id = models.get(role_name.lower(), 'gemini-flash')

    print("ğŸ¤– " + role_name + " ì—­í•  â†’ " + model_id + " ëª¨ë¸")

    # gemini ëª¨ë¸ ì‚¬ìš©ì‹œ CrewAIì˜ LLM í´ë˜ìŠ¤ ì‚¬ìš©
    if 'gemini' in model_id:
        from crewai import LLM
        return LLM(
            model="gemini/" + model_id,
            temperature=0.7
        )
    else:
        # OpenAI ëª¨ë¸ì˜ ê²½ìš°
        from langchain_openai import ChatOpenAI
        return ChatOpenAI(
            model=model_id,
            temperature=0.7,
            max_tokens=2000
        )

# CrewAI ì—ì´ì „íŠ¸ ì •ì˜
print("ğŸ‘¥ ì—ì´ì „íŠ¸ íŒ€ êµ¬ì„±ì¤‘...")

planner = Agent(
    role="Project Planner",
    goal="í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ì„ ë¶„ì„í•˜ê³  ì²´ê³„ì ì¸ ê°œë°œ ê³„íšì„ ìˆ˜ë¦½í•©ë‹ˆë‹¤.",
    backstory="ë‹¹ì‹ ì€ ì†Œí”„íŠ¸ì›¨ì–´ í”„ë¡œì íŠ¸ ê´€ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë³µì¡í•œ ìš”êµ¬ì‚¬í•­ì„ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ë‹¨ê³„ë¡œ ë¶„í•´í•˜ëŠ” ëŠ¥ë ¥ì´ ë›°ì–´ë‚©ë‹ˆë‹¤.",
    verbose=True,
    allow_delegation=False,
    llm=get_llm_model("planner")
)

researcher = Agent(
    role="Research Specialist",
    goal="í”„ë¡œì íŠ¸ì— í•„ìš”í•œ ìµœì ì˜ ê¸°ìˆ  ìŠ¤íƒê³¼ êµ¬í˜„ ë°©ë²•ì„ ì¡°ì‚¬í•©ë‹ˆë‹¤.",
    backstory="ë‹¹ì‹ ì€ ê¸°ìˆ  ë¦¬ì„œì¹˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ìµœì‹  ê¸°ìˆ  ë™í–¥ì„ íŒŒì•…í•˜ê³ , í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ì— ê°€ì¥ ì í•©í•œ ë„êµ¬ì™€ ë°©ë²•ë¡ ì„ ì„ ë³„í•˜ëŠ”ë° ì „ë¬¸ì„±ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.",
    verbose=True,
    allow_delegation=False,
    llm=get_llm_model("researcher")
)

writer = Agent(
    role="Technical Writer",
    goal="ì¡°ì‚¬ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤ì œ ë™ì‘í•˜ëŠ” ì½”ë“œì™€ ì™„ì „í•œ ë¬¸ì„œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.",
    backstory="ë‹¹ì‹ ì€ ê¸°ìˆ  ë¬¸ì„œ ë° ì½”ë“œ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì—°êµ¬ ê²°ê³¼ë¥¼ ì‹¤ì œ ë™ì‘í•˜ëŠ” ê³ í’ˆì§ˆ ì½”ë“œë¡œ ë³€í™˜í•˜ê³ , ì´í•´í•˜ê¸° ì‰¬ìš´ ë¬¸ì„œë¥¼ ì‘ì„±í•˜ëŠ” ëŠ¥ë ¥ì´ íƒì›”í•©ë‹ˆë‹¤.",
    verbose=True,
    allow_delegation=False,
    llm=get_llm_model("writer")
)

print("ğŸ“‹ ì‘ì—… íƒœìŠ¤í¬ ì„¤ì •ì¤‘...")

# ì›ë³¸ ìš”êµ¬ì‚¬í•­ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ì´ìŠ¤ì¼€ì´í•‘ ì œê±°ëœ ë²„ì „)
original_requirement = "{requirement_original}"

# íƒœìŠ¤í¬ ì²´ì¸ ì •ì˜
task1 = Task(
    description=f"""
ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ì„ ë¶„ì„í•˜ì—¬ ì²´ê³„ì ì¸ í”„ë¡œì íŠ¸ ê³„íšì„ ìˆ˜ë¦½í•˜ì„¸ìš”:

**ìš”êµ¬ì‚¬í•­:**
{{original_requirement}}

**ê³„íšì— í¬í•¨í•  ë‚´ìš©:**
1. í”„ë¡œì íŠ¸ ëª©í‘œ ë° ë²”ìœ„ ì •ì˜
2. í•µì‹¬ ê¸°ëŠ¥ ëª©ë¡ ë° ìš°ì„ ìˆœìœ„
3. ê¸°ìˆ ì  ìš”êµ¬ì‚¬í•­ ë¶„ì„
4. ê°œë°œ ë‹¨ê³„ ë° ë§ˆì¼ìŠ¤í†¤
5. ì˜ˆìƒ ê°œë°œ ì¼ì •

êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ê³„íšì„ í•œê¸€ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
    """,
    expected_output="ìƒì„¸í•œ í”„ë¡œì íŠ¸ ê³„íšì„œ (ë§ˆí¬ë‹¤ìš´ í˜•ì‹, í•œê¸€)",
    agent=planner
)

task2 = Task(
    description="""
Plannerê°€ ìˆ˜ë¦½í•œ ê³„íšì„ ë°”íƒ•ìœ¼ë¡œ ê¸°ìˆ ì  ì¡°ì‚¬ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”:

**ì¡°ì‚¬ í•­ëª©:**
1. ê¶Œì¥ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ ë° í”„ë ˆì„ì›Œí¬
2. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° íŒ¨í‚¤ì§€ ëª©ë¡
3. ê°œë°œ í™˜ê²½ êµ¬ì„± ê°€ì´ë“œ
4. ì•„í‚¤í…ì²˜ íŒ¨í„´ ë° ë””ìì¸ ê¶Œì¥ì‚¬í•­
5. í…ŒìŠ¤íŠ¸ ë° ë°°í¬ ì „ëµ
6. ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

ì‹¤ì œ êµ¬í˜„ ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ ê¸°ìˆ  ì†”ë£¨ì…˜ì„ ì œì‹œí•´ì£¼ì„¸ìš”.
    """,
    expected_output="ê¸°ìˆ  ì¡°ì‚¬ ë³´ê³ ì„œ ë° êµ¬í˜„ ê°€ì´ë“œ (ë§ˆí¬ë‹¤ìš´ í˜•ì‹, í•œê¸€)",
    agent=researcher
)

task3 = Task(
    description="""
ê³„íšê³¼ ì¡°ì‚¬ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì™„ì„±ëœ í”„ë¡œì íŠ¸ë¥¼ êµ¬í˜„í•˜ì„¸ìš”:

**êµ¬í˜„ ë‚´ìš©:**
1. í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ êµ¬ì¡°
2. í•µì‹¬ ê¸°ëŠ¥ë³„ ì†ŒìŠ¤ ì½”ë“œ (ì™„ì „ ë™ì‘)
3. ì„¤ì • íŒŒì¼ (requirements.txt, package.json ë“±)
4. README.md (ì„¤ì¹˜, ì„¤ì •, ì‹¤í–‰ ë°©ë²•)
5. ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì½”ë“œ
6. ì‹¤í–‰ ì˜ˆì‹œ ë° ì‚¬ìš©ë²•

ëª¨ë“  ì½”ë“œëŠ” ì‹¤ì œë¡œ ë™ì‘í•´ì•¼ í•˜ë©°, ì¶©ë¶„í•œ ì£¼ì„ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
    """,
    expected_output="ì™„ì „íˆ êµ¬í˜„ëœ í”„ë¡œì íŠ¸ (ì½”ë“œ, ë¬¸ì„œ, ì„¤ì • íŒŒì¼ í¬í•¨)",
    agent=writer
)

# CrewAI íŒ€ êµ¬ì„± ë° ì‹¤í–‰
print("ğŸš€ CrewAI íŒ€ ì‹¤í–‰ ì‹œì‘...")

crew = Crew(
    agents=[planner, researcher, writer],
    tasks=[task1, task2, task3],
    verbose=2,
    process=Process.sequential
)

try:
    # ì‹¤í–‰ ì‹œì‘
    start_time = datetime.now()
    print("â° ì‹¤í–‰ ì‹œì‘ ì‹œê°„: " + start_time.strftime('%Y-%m-%d %H:%M:%S'))

    result = crew.kickoff()

    end_time = datetime.now()
    duration = end_time - start_time

    print("\\n" + "="*50)
    print("ğŸ‰ CrewAI ì‹¤í–‰ ì™„ë£Œ!")
    print("â±ï¸ ì´ ì†Œìš”ì‹œê°„: " + str(duration))
    print("="*50 + "\\n")

    # ê²°ê³¼ ì €ì¥
    output_file = os.path.join("{project_path}", "crewai_result.md")

    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("# CrewAI í”„ë¡œì íŠ¸ ìƒì„± ê²°ê³¼\\n\\n")
        f.write(f"**ì‹¤í–‰ ID**: {execution_id}\\n")
        f.write("**ìƒì„± ì‹œê°„**: " + start_time.strftime('%Y-%m-%d %H:%M:%S') + "\\n")
        f.write("**ì™„ë£Œ ì‹œê°„**: " + end_time.strftime('%Y-%m-%d %H:%M:%S') + "\\n")
        f.write("**ì†Œìš” ì‹œê°„**: " + str(duration) + "\\n\\n")
        f.write("**ì›ë³¸ ìš”êµ¬ì‚¬í•­**:\\n" + "{requirement_original}" + "\\n\\n")
        f.write("---\\n\\n")
        f.write("## ìƒì„± ê²°ê³¼\\n\\n")
        f.write(str(result))

    print(f"ğŸ“„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {{os.path.abspath(output_file)}}")
    print("âœ… ëª¨ë“  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

except Exception as e:
    import traceback
    error_details = traceback.format_exc()

    print(f"\\nâŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:")
    print(f"ì˜¤ë¥˜ ë‚´ìš©: {{str(e)}}")
    print(f"ìƒì„¸ ì •ë³´:\\n{{error_details}}")

    # ì˜¤ë¥˜ ë¡œê·¸ ì €ì¥
    error_file = os.path.join("{project_path}", "execution_error.log")
    with open(error_file, 'w', encoding='utf-8') as f:
        f.write(f"CrewAI ì‹¤í–‰ ì˜¤ë¥˜ ë¡œê·¸\\n")
        f.write(f"ì‹¤í–‰ ID: {execution_id}\\n")
        f.write("ì˜¤ë¥˜ ë°œìƒ ì‹œê°„: " + datetime.now().strftime('%Y-%m-%d %H:%M:%S') + "\\n\\n")
        f.write("ì˜¤ë¥˜ ë©”ì‹œì§€: " + str(e) + "\\n\\n")
        f.write("ìƒì„¸ ì¶”ì  ì •ë³´:\\n" + error_details)

    print("ğŸ—‚ï¸ ì˜¤ë¥˜ ë¡œê·¸ ì €ì¥: " + os.path.abspath(error_file))

    sys.exit(1)
'''

    # 4. í…œí”Œë¦¿ ë³€ìˆ˜ ê°’ ì¤€ë¹„ (ë³€ìˆ˜ëª… ì¼ì¹˜ í™•ë³´)
    normalized_models_str = json.dumps(normalized_models, ensure_ascii=False, indent=8).replace('\n', '\n    ')

    template_vars = {
        'execution_id': execution_id,
        'generation_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'requirement_display': safe_requirement[:100] + ('...' if len(safe_requirement) > 100 else ''),
        'requirement_original': requirement,  # ì›ë³¸ ìš”êµ¬ì‚¬í•­ (ì´ìŠ¤ì¼€ì´í•‘ ì—†ìŒ)
        'project_path': safe_project_path,
        'normalized_models_str': normalized_models_str
    }

    # 5. ì•ˆì „í•œ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
    try:
        formatted_script = script_template.format(**template_vars)

        # ìµœì¢… UTF-8 ì•ˆì „ì„± í™•ë³´
        return formatted_script.encode('utf-8', errors='replace').decode('utf-8')

    except Exception as e:
        # í´ë°± ìŠ¤í¬ë¦½íŠ¸ (ìµœì†Œí•œì˜ ë™ì‘ ë³´ì¥)
        fallback_script = f'''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CrewAI ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì˜¤ë¥˜ ë°œìƒ - í´ë°± ëª¨ë“œ
ì‹¤í–‰ ID: {execution_id}
ì˜¤ë¥˜: {str(e)}
"""

print("âš ï¸ CrewAI ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
print(f"ì‹¤í–‰ ID: {execution_id}")
print(f"ì˜¤ë¥˜ ë‚´ìš©: {str(e)}")
print("\\në¬¸ì œ í•´ê²° í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

import sys
sys.exit(1)
'''
        return fallback_script



@app.route('/api/metagpt', methods=['POST'])
def handle_metagpt_request():
    """Handle MetaGPT requests"""
    data = request.get_json()
    requirement = data.get('requirement')
    selected_models = data.get('selectedModels', {})

    if not requirement:
        return jsonify({'error': 'Requirement is required'}), 400

    try:
        print(f'MetaGPT request: {requirement}')
        print(f'Selected models: {selected_models}')

        ai_type = data.get('aiType', 'meta-gpt')
        print(f'AI Type: {ai_type}')

        # MetaGPT ì²˜ë¦¬ - ì‹¤ì œ MetaGPT ëª¨ë“ˆ í˜¸ì¶œ
        if ai_type == 'meta-gpt':
            return call_metagpt_module(requirement, selected_models)

    except Exception as e:
        return jsonify({
            'error': 'Error processing MetaGPT request',
            'details': str(e)
        }), 500


def call_metagpt_module(requirement, selected_models):
    """ì‹¤ì œ MetaGPT ëª¨ë“ˆ í˜¸ì¶œ"""
    try:
        # MetaGPT ëª¨ë“ˆ ê²½ë¡œ í™•ì¸ (ì´ë¯¸ ì „ì—­ì—ì„œ ì„¤ì •ë¨)
        metagpt_path_full = metagpt_path

        if not os.path.exists(metagpt_path_full):
            return jsonify({
                'success': False,
                'error': 'MetaGPT module not found',
                'message': 'MetaGPT ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
                'path_checked': metagpt_path_full
            }), 404

        # MetaGPT ëª¨ë“ˆì—ì„œ ì‹¤ì œ ì²˜ë¦¬
        # ì—¬ê¸°ì„œëŠ” subprocessë¡œ MetaGPT ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
        import subprocess
        import json

        # MetaGPT ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œ
        script_path = os.path.join(metagpt_path_full, 'run_step_by_step.py')

        if os.path.exists(script_path):
            # ì‹¤ì œ MetaGPT ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ (1ë‹¨ê³„ë¶€í„° ì‹œì‘)
            result = subprocess.run([
                sys.executable, script_path,
                requirement,  # ì²« ë²ˆì§¸ ì¸ì: ìš”êµ¬ì‚¬í•­
                '1'          # ë‘ ë²ˆì§¸ ì¸ì: ì‹œì‘ ë‹¨ê³„
            ], capture_output=True, text=True, timeout=30)

            if result.returncode == 0:
                try:
                    response_data = json.loads(result.stdout)
                    return jsonify(response_data)
                except json.JSONDecodeError:
                    return jsonify({
                        'success': True,
                        'message': result.stdout,
                        'type': 'text_response'
                    })
            else:
                return jsonify({
                    'success': False,
                    'error': 'MetaGPT execution failed',
                    'details': result.stderr
                }), 500
        else:
            # ìŠ¤í¬ë¦½íŠ¸ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ MetaGPT í˜¸ì¶œ
            return call_basic_metagpt(requirement, metagpt_path_full)

    except Exception as e:
        return jsonify({
            'success': False,
            'error': 'MetaGPT module call failed',
            'details': str(e)
        }), 500


def call_basic_metagpt(requirement, metagpt_path):
    """ê¸°ë³¸ MetaGPT í˜¸ì¶œ"""
    try:
        # ê¸°ì¡´ì˜ ë°ëª¨ í”„ë¡œì íŠ¸ ìƒì„±
        project_path = create_demo_project(requirement)

        return jsonify({
            'success': True,
            'requirement': requirement,
            'message': "MetaGPTì—ì„œ í”„ë¡œì íŠ¸ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.",
            'project_path': project_path,
            'agents': ["ProductManager", "Architect", "Engineer"],
            'process': "Basic project generation completed",
            'workspace': f"Project created at: {project_path}",
            'note': "ë‹¨ê³„ë³„ ìŠ¹ì¸ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•˜ë ¤ë©´ MetaGPT ëª¨ë“ˆ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤."
        })

    except Exception as e:
        return jsonify({
            'success': False,
            'error': 'Basic MetaGPT call failed',
            'details': str(e)
        }), 500


def analyze_project_requirement(requirement):
    """í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ ë¶„ì„"""
    req_lower = requirement.lower()

    # í”„ë¡œì íŠ¸ íƒ€ì… ë¶„ì„
    if any(word in req_lower for word in ["ê²Œì„", "game"]):
        project_type = "ê²Œì„"
        domain = "ì—”í„°í…Œì¸ë¨¼íŠ¸"
        technology = "Python/JavaScript"
    elif any(word in req_lower for word in ["ì‡¼í•‘ëª°", "shopping", "ecommerce"]):
        project_type = "ì´ì»¤ë¨¸ìŠ¤"
        domain = "ë¹„ì¦ˆë‹ˆìŠ¤"
        technology = "React/Node.js"
    elif any(word in req_lower for word in ["ì›¹", "web", "ì‚¬ì´íŠ¸"]):
        project_type = "ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜"
        domain = "ì›¹ ê°œë°œ"
        technology = "HTML/CSS/JavaScript"
    elif any(word in req_lower for word in ["api", "ì„œë²„", "server"]):
        project_type = "ë°±ì—”ë“œ ì„œë¹„ìŠ¤"
        domain = "ë°±ì—”ë“œ"
        technology = "Python/Flask"
    else:
        project_type = "ì¼ë°˜ ì• í”Œë¦¬ì¼€ì´ì…˜"
        domain = "ì†Œí”„íŠ¸ì›¨ì–´"
        technology = "Python"

    # ë³µì¡ë„ ë¶„ì„
    if any(word in req_lower for word in ["ê°„ë‹¨í•œ", "simple", "basic"]):
        complexity = "ë‚®ìŒ"
        estimated_time = "30-60ë¶„"
    elif any(word in req_lower for word in ["ë³µì¡í•œ", "advanced", "ì™„ì „í•œ"]):
        complexity = "ë†’ìŒ"
        estimated_time = "2-4ì‹œê°„"
    else:
        complexity = "ì¤‘ê°„"
        estimated_time = "1-2ì‹œê°„"

    return {
        "project_type": project_type,
        "domain": domain,
        "technology": technology,
        "complexity": complexity,
        "estimated_time": estimated_time,
        "key_features": extract_key_features(requirement),
        "requirements": extract_requirements(requirement)
    }


def extract_key_features(requirement):
    """í•µì‹¬ ê¸°ëŠ¥ ì¶”ì¶œ"""
    features = []
    req_lower = requirement.lower()

    if "í™˜ìœ¨" in req_lower or "exchange" in req_lower:
        features = ["ì‹¤ì‹œê°„ í™˜ìœ¨ ì¡°íšŒ", "í†µí™” ë³€í™˜", "API ì—°ë™", "ë°ì´í„° ì‹œê°í™”"]
    elif "ê²Œì„" in req_lower:
        features = ["ê²Œì„ ë¡œì§", "ì ìˆ˜ ì‹œìŠ¤í…œ", "ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤", "ê²Œì„ ìƒíƒœ ê´€ë¦¬"]
    elif "ì‡¼í•‘ëª°" in req_lower:
        features = ["ìƒí’ˆ ê´€ë¦¬", "ì¥ë°”êµ¬ë‹ˆ", "ê²°ì œ ì‹œìŠ¤í…œ", "ì‚¬ìš©ì ì¸ì¦", "ì£¼ë¬¸ ê´€ë¦¬"]
    elif "í• ì¼" in req_lower or "todo" in req_lower:
        features = ["í• ì¼ ì¶”ê°€/ì‚­ì œ", "ì™„ë£Œ ìƒíƒœ ê´€ë¦¬", "í•„í„°ë§", "ë°ì´í„° ì €ì¥"]
    else:
        features = ["ê¸°ë³¸ ê¸°ëŠ¥", "ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤", "ë°ì´í„° ì²˜ë¦¬"]

    return features


def extract_requirements(requirement):
    """ì„¸ë¶€ ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ"""
    requirements = []
    req_lower = requirement.lower()

    if "react" in req_lower:
        requirements.append("React í”„ë ˆì„ì›Œí¬ ì‚¬ìš©")
    if "python" in req_lower:
        requirements.append("Python ì–¸ì–´ ì‚¬ìš©")
    if "api" in req_lower:
        requirements.append("RESTful API êµ¬í˜„")
    if "ë°ì´í„°ë² ì´ìŠ¤" in req_lower or "database" in req_lower:
        requirements.append("ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™")
    if "ì¸ì¦" in req_lower or "auth" in req_lower:
        requirements.append("ì‚¬ìš©ì ì¸ì¦ ì‹œìŠ¤í…œ")

    return requirements if requirements else ["í‘œì¤€ ê°œë°œ í”„ë¡œì„¸ìŠ¤ ì ìš©"]


def generate_team_plan(requirement, project_analysis):
    """íŒ€ êµ¬ì„± ê³„íš ìƒì„±"""
    base_team = [
        {
            "role": "ProductManager",
            "name": "ì œí’ˆ ê´€ë¦¬ì",
            "responsibility": f"{project_analysis['project_type']} ìš”êµ¬ì‚¬í•­ ë¶„ì„ ë° PRD ì‘ì„±",
            "estimated_time": "15-20ë¶„",
            "deliverables": ["ì œí’ˆ ìš”êµ¬ì‚¬í•­ ë¬¸ì„œ", "ì‚¬ìš©ì ìŠ¤í† ë¦¬", "ì„±ê³µ ì§€í‘œ"]
        },
        {
            "role": "Architect",
            "name": "ì‹œìŠ¤í…œ ì„¤ê³„ì",
            "responsibility": f"{project_analysis['technology']} ê¸°ë°˜ ì•„í‚¤í…ì²˜ ì„¤ê³„",
            "estimated_time": "20-25ë¶„",
            "deliverables": ["ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜", "API ëª…ì„¸ì„œ", "ë°ì´í„° ëª¨ë¸"]
        },
        {
            "role": "Engineer",
            "name": "ê°œë°œì",
            "responsibility": f"{project_analysis['project_type']} êµ¬í˜„ ë° ì½”ë”©",
            "estimated_time": "30-45ë¶„",
            "deliverables": ["ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œ", "í…ŒìŠ¤íŠ¸ ì½”ë“œ", "ë¬¸ì„œí™”"]
        }
    ]

    # ë³µì¡ë„ì— ë”°ë¥¸ íŒ€ì› ì¶”ê°€
    if project_analysis["complexity"] == "ë†’ìŒ":
        base_team.extend([
            {
                "role": "ProjectManager",
                "name": "í”„ë¡œì íŠ¸ ê´€ë¦¬ì",
                "responsibility": "í”„ë¡œì íŠ¸ ì¼ì • ê´€ë¦¬ ë° í’ˆì§ˆ ë³´ì¦",
                "estimated_time": "10-15ë¶„",
                "deliverables": ["í”„ë¡œì íŠ¸ ê³„íšì„œ", "ì¼ì • ê´€ë¦¬", "í’ˆì§ˆ ë³´ê³ ì„œ"]
            },
            {
                "role": "QaEngineer",
                "name": "í’ˆì§ˆ ë³´ì¦ ì—”ì§€ë‹ˆì–´",
                "responsibility": "í…ŒìŠ¤íŠ¸ ì „ëµ ìˆ˜ë¦½ ë° í’ˆì§ˆ ê²€ì¦",
                "estimated_time": "15-20ë¶„",
                "deliverables": ["í…ŒìŠ¤íŠ¸ ê³„íšì„œ", "í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤", "í’ˆì§ˆ ë³´ê³ ì„œ"]
            }
        ])

    return {
        "team_size": len(base_team),
        "team_members": base_team,
        "total_estimated_time": project_analysis["estimated_time"],
        "workflow": "ìˆœì°¨ì  ë‹¨ê³„ë³„ ìŠ¹ì¸ í”„ë¡œì„¸ìŠ¤"
    }


def generate_execution_plan(requirement, project_analysis, team_plan):
    """ì‹¤í–‰ ê³„íš ìƒì„±"""
    phases = []

    for i, member in enumerate(team_plan["team_members"]):
        phases.append({
            "phase": i + 1,
            "role": member["role"],
            "name": member["name"],
            "title": f"{member['name']} ì‘ì—… ë‹¨ê³„",
            "description": member["responsibility"],
            "estimated_time": member["estimated_time"],
            "deliverables": member["deliverables"],
            "approval_required": True,
            "dependencies": [phases[i-1]["phase"]] if i > 0 else []
        })

    return {
        "total_phases": len(phases),
        "phases": phases,
        "execution_mode": "ë‹¨ê³„ë³„ ìŠ¹ì¸ ê¸°ë°˜",
        "user_interaction": "ê° ë‹¨ê³„ë§ˆë‹¤ ì‚¬ìš©ì ìŠ¹ì¸ í•„ìš”",
        "project_folder": f"metagpt_{int(time.time())}",
        "estimated_budget": "$5.00",
        "success_criteria": [
            "ëª¨ë“  ë‹¨ê³„ ì™„ë£Œ",
            "ì‚¬ìš©ì ìŠ¹ì¸ íšë“",
            "ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œ ìƒì„±",
            "ë¬¸ì„œí™” ì™„ë£Œ"
        ]
    }


def create_demo_project(requirement):
    """Create a demo project based on requirement"""
    import uuid
    from datetime import datetime

    # Generate unique project name
    project_name = f"project_{uuid.uuid4().hex[:8]}_{int(time.time())}"

    # Create project directory - MetaGPT í´ë” ì•ˆì— workspace ìƒì„±
    workspace_dir = os.path.join(metagpt_path, 'workspace')
    project_path = os.path.join(workspace_dir, project_name)

    os.makedirs(project_path, exist_ok=True)

    # Generate project files based on requirement
    files_content = generate_project_files(requirement, project_name)

    # Create files
    for filename, content in files_content.items():
        file_path = os.path.join(project_path, filename)
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)

    return project_path


def generate_project_files(requirement, project_name):
    """Generate project files based on requirement"""

    # Simple project template
    files = {
        'main.py': f'''#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
{project_name}
Generated based on: {requirement}
"""

def main():
    """Main function for {requirement}"""
    print("Welcome to {project_name}")
    print("Requirement: {requirement}")

    # TODO: Implement the actual functionality
    print("This is a demo implementation.")
    print("Please implement the required features.")

if __name__ == "__main__":
    main()
''',

        'README.md': f'''# {project_name}

## Description
{requirement}

## Generated Files
- `main.py` - Main application file
- `README.md` - This documentation file
- `requirements.txt` - Python dependencies

## Usage
```bash
python main.py
```

## Development
This project was generated automatically based on the requirement:
> {requirement}

## Next Steps
1. Implement the core functionality in `main.py`
2. Add necessary dependencies to `requirements.txt`
3. Write tests for your implementation
4. Update this README with specific usage instructions

Generated by: MetaGPT + VS Code Integration
Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
''',

        'requirements.txt': '''# Python dependencies
# Add your project dependencies here

# Example:
# requests>=2.28.0
# flask>=2.0.0
''',

        '.gitignore': '''# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual environments
venv/
env/
ENV/

# IDE
.vscode/
.idea/
*.swp
*.swo

# OS
.DS_Store
Thumbs.db
'''
    }

    return files




def run_metagpt_background(execution_id, requirement, selected_models, script_path):
    """Execute MetaGPT in background"""
    try:
        # Execute Python process
        process = subprocess.Popen(
            [sys.executable, script_path, requirement, json.dumps(selected_models)],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            cwd=current_dir
        )

        stdout, stderr = process.communicate(timeout=300)  # 5 minute timeout

        if process.returncode == 0:
            try:
                result = json.loads(stdout) if stdout.strip() else {}
                execution_status[execution_id].update({
                    'status': 'completed',
                    'result': result,
                    'end_time': datetime.now()
                })
            except json.JSONDecodeError:
                execution_status[execution_id].update({
                    'status': 'completed',
                    'result': {'output': stdout},
                    'end_time': datetime.now()
                })
        else:
            execution_status[execution_id].update({
                'status': 'failed',
                'error': stderr,
                'end_time': datetime.now()
            })

    except subprocess.TimeoutExpired:
        process.kill()
        execution_status[execution_id].update({
            'status': 'failed',
            'error': 'MetaGPT execution timeout (5 minutes)',
            'end_time': datetime.now()
        })
    except Exception as e:
        execution_status[execution_id].update({
            'status': 'failed',
            'error': str(e),
            'end_time': datetime.now()
        })


@app.route('/api/execution/<execution_id>/status', methods=['GET'])
def get_execution_status(execution_id):
    """Query execution status"""
    status = execution_status.get(execution_id)
    if status:
        # Convert datetime objects to strings
        if isinstance(status.get('start_time'), datetime):
            status['start_time'] = status['start_time'].isoformat()
        if isinstance(status.get('end_time'), datetime):
            status['end_time'] = status['end_time'].isoformat()
        return jsonify({'success': True, 'data': status})
    else:
        return jsonify({
            'success': False,
            'error': 'Execution information not found.'
        }), 404


# ==================== SERVICE MANAGEMENT ENDPOINTS ====================

@app.route('/api/services/crewai/start', methods=['POST'])
def start_crewai_service():
    """Start CrewAI service"""
    try:
        crewai_server_path = os.path.join(crewai_path, 'crewai_platform', 'server.py')
        if os.path.exists(crewai_server_path):
            # Start CrewAI server in background
            subprocess.Popen([sys.executable, crewai_server_path], cwd=os.path.dirname(crewai_server_path))
            return jsonify({
                'success': True,
                'message': 'CrewAI service started.',
                'url': 'http://localhost:3003'
            })
        else:
            return jsonify({
                'success': False,
                'error': 'CrewAI server file not found.'
            }), 404
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'Failed to start CrewAI service: {str(e)}'
        }), 500


@app.route('/api/services/status', methods=['GET'])
def get_services_status():
    """Query all service status"""
    return jsonify({
        'crewai': {
            'status': check_crewai_service(),
            'url': CREWAI_URL
        },
        'metagpt': {
            'status': check_metagpt_service(),
            'path': metagpt_path
        }
    })


# ==================== NEW DATABASE API ENDPOINTS ====================

@app.route('/api/v2/projects', methods=['GET'])
@optional_auth
def get_projects_v2():
    """Get projects list from database"""
    limit = request.args.get('limit', 20, type=int)
    # Pass user_id=None to show all projects (for now)
    result = db.get_projects(user_id=None, limit=limit)

    return jsonify(result)

@app.route('/api/v2/projects', methods=['POST'])
@rate_limit(max_requests=10, window_seconds=60)
@validate_json_input(['name'])
@optional_auth
def create_project_v2():
    """Create new project in database"""
    data = request.get_json()

    # ë³´ì•ˆ ê²€ì¦
    security_issues = check_request_security(data)
    if security_issues:
        return jsonify({
            'success': False,
            'error': 'Security validation failed',
            'details': security_issues
        }), 400

    # ì…ë ¥ ë°ì´í„° ê²€ì¦
    validation_result = validate_request_data(data, 'project')
    if not validation_result['valid']:
        return jsonify({
            'success': False,
            'error': 'Input validation failed',
            'details': validation_result['errors']
        }), 400

    # ê²€ì¦ëœ ë°ì´í„°ë¡œ í”„ë¡œì íŠ¸ ìƒì„±
    result = db.create_project(validation_result['data'])
    status_code = 201 if result.get('success') else 400

    return jsonify(result), status_code

@app.route('/api/v2/projects/<project_id>', methods=['GET'])
@optional_auth
def get_project_v2(project_id):
    """Get single project from database"""
    result = db.get_project_by_id(project_id)
    status_code = 200 if result.get('success') else 404

    return jsonify(result), status_code

@app.route('/api/v2/projects/<project_id>', methods=['PUT'])
@optional_auth
def update_project_v2(project_id):
    """Update project in database"""
    data = request.get_json()

    if not data:
        return jsonify({
            'success': False,
            'error': 'ì—…ë°ì´íŠ¸í•  ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤'
        }), 400

    result = db.update_project(project_id, data)
    status_code = 200 if result.get('success') else 400

    return jsonify(result), status_code

@app.route('/api/v2/projects/<project_id>', methods=['DELETE'])
@optional_auth
def delete_project_v2(project_id):
    """Delete project from database"""
    result = db.delete_project(project_id)
    status_code = 200 if result.get('success') else 400

    return jsonify(result), status_code

@app.route('/api/v2/projects/<project_id>/role-llm-mapping', methods=['POST'])
@rate_limit(max_requests=20, window_seconds=60)
@validate_json_input(['mappings'])
@optional_auth
def set_role_llm_mapping(project_id):
    """Set role-LLM mapping for project"""
    data = request.get_json()

    # ë³´ì•ˆ ê²€ì¦
    security_issues = check_request_security(data)
    if security_issues:
        return jsonify({
            'success': False,
            'error': 'Security validation failed',
            'details': security_issues
        }), 400

    # ì…ë ¥ ë°ì´í„° ê²€ì¦
    validation_result = validate_request_data(data, 'llm_mapping')
    if not validation_result['valid']:
        return jsonify({
            'success': False,
            'error': 'Input validation failed',
            'details': validation_result['errors']
        }), 400

    # ê²€ì¦ëœ ë°ì´í„°ë¡œ ë§¤í•‘ ì„¤ì •
    result = db.set_project_role_llm_mapping(project_id, validation_result['mappings'])
    status_code = 200 if result.get('success') else 400

    return jsonify(result), status_code

@app.route('/api/v2/projects/<project_id>/role-llm-mapping', methods=['GET'])
@optional_auth
def get_role_llm_mapping(project_id):
    """Get role-LLM mapping for project"""
    result = db.get_project_role_llm_mapping(project_id)
    status_code = 200 if result.get('success') else 404

    return jsonify(result), status_code

# ==================== AUTHENTICATION ENDPOINTS ====================

@app.route('/api/auth/login', methods=['POST'])
def login():
    """User login endpoint"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({'success': False, 'error': 'ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤'}), 400

        user_id = data.get('user_id')
        password = data.get('password')

        if not user_id or not password:
            return jsonify({'success': False, 'error': 'ì‚¬ìš©ì IDì™€ ë¹„ë°€ë²ˆí˜¸ê°€ í•„ìš”í•©ë‹ˆë‹¤'}), 400

        # Check if it's admin login
        if admin_auth.verify_password(user_id, password):
            token = admin_auth.generate_token(user_id)
            return jsonify({
                'success': True,
                'token': token,
                'user': {
                    'user_id': user_id,
                    'role': 'admin',
                    'display_name': 'ì‹œìŠ¤í…œ ê´€ë¦¬ì'
                },
                'message': 'ë¡œê·¸ì¸ ì„±ê³µ'
            })

        # Check database users
        result = db.verify_user(user_id, password)
        if result['success']:
            # Generate JWT token for database user
            user_data = {
                'id': user_id,
                'email': result['user'].get('email', f"{user_id}@example.com"),
                'role': result['user'].get('role', 'user'),
                'display_name': result['user'].get('display_name', user_id)
            }
            token = db.generate_jwt_token(user_data)

            return jsonify({
                'success': True,
                'token': token,
                'user': user_data,
                'message': 'ë¡œê·¸ì¸ ì„±ê³µ'
            })
        else:
            return jsonify({'success': False, 'error': 'ì˜ëª»ëœ ì‚¬ìš©ì ID ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ì…ë‹ˆë‹¤'}), 401

    except Exception as e:
        return jsonify({'success': False, 'error': f'ë¡œê·¸ì¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}'}), 500

@app.route('/api/v2/auth/token', methods=['POST'])
@rate_limit(max_requests=5, window_seconds=60)
@validate_json_input()
def generate_auth_token():
    """Generate authentication token"""
    data = request.get_json()

    # Generate token with provided user data
    user_data = {
        'id': data.get('user_id'),
        'email': data.get('email', f"{data.get('user_id')}@example.com"),
        'role': data.get('role', 'user')
    }

    token = db.generate_jwt_token(user_data)

    return jsonify({
        'success': True,
        'token': token,
        'user': user_data,
        'message': 'ì¸ì¦ í† í°ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤'
    })

@app.route('/api/v2/auth/verify', methods=['POST'])
def verify_auth_token():
    """Verify authentication token"""
    auth_header = request.headers.get('Authorization')

    if not auth_header:
        return jsonify({
            'success': False,
            'error': 'ì¸ì¦ í—¤ë”ê°€ í•„ìš”í•©ë‹ˆë‹¤'
        }), 401

    try:
        token = auth_header.split(' ')[1]
        result = db.verify_jwt_token(token)

        return jsonify(result)
    except IndexError:
        return jsonify({
            'success': False,
            'error': 'í† í° í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤'
        }), 401

# ==================== LEGACY API ENDPOINTS ====================

@app.route('/api/projects-legacy', methods=['GET'])
def get_projects_list():
    """í”„ë¡œì íŠ¸ ëª©ë¡ ì¡°íšŒ (Legacy)"""
    try:
        # MetaGPT workspaceì—ì„œ í”„ë¡œì íŠ¸ ëª©ë¡ ì¡°íšŒ
        projects_path = os.path.join(metagpt_path, 'workspace')

        if not os.path.exists(projects_path):
            return jsonify({
                'success': True,
                'projects': [],
                'message': 'MetaGPT workspace ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.'
            })

        projects = []
        for project_dir in os.listdir(projects_path):
            project_path = os.path.join(projects_path, project_dir)
            if os.path.isdir(project_path):
                metadata_file = os.path.join(project_path, 'project_metadata.json')
                if os.path.exists(metadata_file):
                    try:
                        with open(metadata_file, 'r', encoding='utf-8') as f:
                            metadata = json.load(f)

                        # ì§„í–‰ ìƒí™© íŒŒì•…
                        step_files = []
                        for i in range(1, 6):
                            step_file_pattern = f"step_{i}_*.json"
                            step_files_found = [f for f in os.listdir(project_path) if f.startswith(f"step_{i}_")]
                            if step_files_found:
                                step_files.append(i)

                        completed_steps = len(step_files)
                        progress_percentage = (completed_steps / 5) * 100

                        projects.append({
                            'project_name': metadata.get('project_name', project_dir),
                            'project_id': metadata.get('project_id', project_dir),
                            'requirement': metadata.get('requirement', ''),
                            'created_at': metadata.get('created_at', ''),
                            'current_step': metadata.get('current_step', 1),
                            'completed_steps': completed_steps,
                            'total_steps': 5,
                            'progress_percentage': progress_percentage,
                            'workspace_path': project_path,
                            'status': 'ì™„ë£Œ' if completed_steps >= 5 else f'{completed_steps}/5 ë‹¨ê³„ ì§„í–‰ ì¤‘'
                        })
                    except Exception as e:
                        print(f"í”„ë¡œì íŠ¸ ë©”íƒ€ë°ì´í„° ì½ê¸° ì‹¤íŒ¨: {project_dir} - {e}")

        # ìµœì‹  ìˆœìœ¼ë¡œ ì •ë ¬
        projects.sort(key=lambda x: x['created_at'], reverse=True)

        return jsonify({
            'success': True,
            'projects': projects
        })

    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'í”„ë¡œì íŠ¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}'
        }), 500


@app.route('/api/projects/<project_name>', methods=['GET'])
def get_project_details(project_name):
    """íŠ¹ì • í”„ë¡œì íŠ¸ ìƒì„¸ ì •ë³´ ì¡°íšŒ"""
    try:
        # MetaGPT workspaceì—ì„œ íŠ¹ì • í”„ë¡œì íŠ¸ ì¡°íšŒ
        projects_path = os.path.join(metagpt_path, 'workspace')
        project_path = os.path.join(projects_path, project_name)

        if not os.path.exists(project_path):
            return jsonify({
                'success': False,
                'error': 'í”„ë¡œì íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }), 404

        metadata_file = os.path.join(project_path, 'project_metadata.json')
        if not os.path.exists(metadata_file):
            return jsonify({
                'success': False,
                'error': 'í”„ë¡œì íŠ¸ ë©”íƒ€ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }), 404

        with open(metadata_file, 'r', encoding='utf-8') as f:
            metadata = json.load(f)

        # ê° ë‹¨ê³„ë³„ ê²°ê³¼ ì½ê¸°
        step_results = {}
        for i in range(1, 6):
            step_files = [f for f in os.listdir(project_path) if f.startswith(f"step_{i}_")]
            if step_files:
                step_file = os.path.join(project_path, step_files[0])
                try:
                    with open(step_file, 'r', encoding='utf-8') as f:
                        step_data = json.load(f)
                    step_results[i] = step_data
                except Exception as e:
                    print(f"ë‹¨ê³„ {i} íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")

        return jsonify({
            'success': True,
            'project': {
                'metadata': metadata,
                'step_results': step_results,
                'next_step': len(step_results) + 1 if len(step_results) < 5 else None
            }
        })

    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'í”„ë¡œì íŠ¸ ìƒì„¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}'
        }), 500


@app.route('/api/metagpt/step', methods=['POST'])
def handle_metagpt_step():
    """Handle MetaGPT step-by-step workflow"""
    data = request.get_json()

    requirement = data.get('requirement')
    step_number = data.get('step', 1)
    user_response = data.get('user_response')  # 'approve', 'reject', 'modify'
    modifications = data.get('modifications', '')

    if not requirement:
        return jsonify({'error': 'Requirement is required'}), 400

    try:
        # MetaGPT ê²½ë¡œ ì‚¬ìš© (ì „ì—­ì—ì„œ ì„¤ì •ë¨)
        script_path = os.path.join(metagpt_path, 'run_step_by_step.py')

        if not os.path.exists(script_path):
            return jsonify({
                'success': False,
                'error': 'MetaGPT step-by-step script not found'
            }), 404

        # ì‚¬ìš©ì ì…ë ¥ ì¤€ë¹„
        user_input = {}
        if user_response:
            user_input = {
                'response': user_response,
                'modifications': modifications
            }

        # MetaGPT ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
        args = [sys.executable, script_path, requirement, str(step_number)]
        if user_input:
            args.append(json.dumps(user_input))

        result = subprocess.run(args, capture_output=True, text=True, timeout=60)

        if result.returncode == 0:
            try:
                response_data = json.loads(result.stdout)
                return jsonify(response_data)
            except json.JSONDecodeError:
                return jsonify({
                    'success': True,
                    'message': result.stdout,
                    'type': 'text_response'
                })
        else:
            return jsonify({
                'success': False,
                'error': 'MetaGPT step execution failed',
                'details': result.stderr
            }), 500

    except Exception as e:
        return jsonify({
            'success': False,
            'error': 'Error processing MetaGPT step',
            'details': str(e)
        }), 500


# ==================== í”„ë¡ì‹œ ë¼ìš°íŒ… ====================

@app.route('/api/crewai/projects', methods=['GET'])
def proxy_crewai_projects():
    """CrewAI í”„ë¡œì íŠ¸ ëª©ë¡ í”„ë¡ì‹œ"""
    try:
        response = requests.get(f'{CREWAI_URL}/api/projects', timeout=10)
        return jsonify(response.json()), response.status_code
    except Exception as e:
        return jsonify({
            'success': False,
            'error': 'CrewAI ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
            'details': str(e)
        }), 503

@app.route('/api/crewai/<path:endpoint>', methods=['GET', 'POST', 'PUT', 'DELETE'])
def proxy_crewai(endpoint):
    """CrewAI API í”„ë¡ì‹œ"""
    try:
        url = f'{CREWAI_URL}/api/{endpoint}'

        if request.method == 'GET':
            response = requests.get(url, params=request.args, timeout=10)
        elif request.method == 'POST':
            response = requests.post(url, json=request.get_json(), timeout=30)
        elif request.method == 'PUT':
            response = requests.put(url, json=request.get_json(), timeout=30)
        elif request.method == 'DELETE':
            response = requests.delete(url, timeout=10)

        return jsonify(response.json()), response.status_code
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'CrewAI ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {endpoint}',
            'details': str(e)
        }), 503

@app.route('/api/metagpt/<path:endpoint>', methods=['GET', 'POST', 'PUT', 'DELETE'])
def proxy_metagpt(endpoint):
    """MetaGPT API í”„ë¡ì‹œ"""
    try:
        # MetaGPTëŠ” ë‚´ì¥ ì²˜ë¦¬ë¡œ ëŒ€ì²´
        if endpoint == 'projects':
            return get_projects_list()
        elif endpoint.startswith('step'):
            return handle_metagpt_step()
        else:
            return jsonify({
                'success': False,
                'error': f'MetaGPT ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {endpoint}'
            }), 404
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'MetaGPT ì²˜ë¦¬ ì‹¤íŒ¨: {endpoint}',
            'details': str(e)
        }), 500


# ==================== PROJECT MANAGEMENT API ====================

@app.route('/api/projects', methods=['GET'])
@rate_limit(max_requests=30, window_seconds=60)
def get_projects():
    """í”„ë¡œì íŠ¸ ëª©ë¡ ì¡°íšŒ"""
    try:
        limit = request.args.get('limit', 20, type=int)
        result = db.get_projects(limit=limit)

        if result['success']:
            return jsonify({
                'success': True,
                'projects': result['projects'],
                'count': result['count'],
                'simulation': result.get('simulation', False)
            })
        else:
            return jsonify({
                'success': False,
                'error': result['error']
            }), 500

    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'í”„ë¡œì íŠ¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}'
        }), 500


@app.route('/api/projects', methods=['POST'])
@rate_limit(max_requests=10, window_seconds=60)
@validate_json_input(['name'])
def create_project():
    """ìƒˆ í”„ë¡œì íŠ¸ ìƒì„±"""
    try:
        data = request.get_json()

        # ì…ë ¥ ë°ì´í„° ê²€ì¦
        validation_result = validate_request_data(data, 'project')
        if not validation_result['valid']:
            return jsonify({
                'success': False,
                'error': 'Invalid input data',
                'details': validation_result['errors']
            }), 400

        # ë³´ì•ˆ ê²€ì‚¬
        security_issues = check_request_security(data)
        if security_issues:
            return jsonify({
                'success': False,
                'error': 'Security validation failed',
                'details': security_issues
            }), 400

        # í”„ë¡œì íŠ¸ ìƒì„±
        result = db.create_project(validation_result['data'])

        if result['success']:
            return jsonify({
                'success': True,
                'project': result['project'],
                'message': result['message'],
                'simulation': result.get('simulation', False)
            }), 201
        else:
            return jsonify({
                'success': False,
                'error': result['error']
            }), 500

    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'í”„ë¡œì íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}'
        }), 500


@app.route('/api/projects/<project_id>', methods=['GET'])
@rate_limit(max_requests=60, window_seconds=60)
def get_project(project_id):
    """íŠ¹ì • í”„ë¡œì íŠ¸ ì¡°íšŒ"""
    try:
        result = db.get_project_by_id(project_id)

        if result['success']:
            return jsonify({
                'success': True,
                'project': result['project'],
                'simulation': result.get('simulation', False)
            })
        else:
            return jsonify({
                'success': False,
                'error': result['error']
            }), 404 if 'find' in result['error'] else 500

    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'í”„ë¡œì íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}'
        }), 500


@app.route('/api/projects/<project_id>', methods=['PUT'])
@rate_limit(max_requests=20, window_seconds=60)
@validate_json_input()
def update_project(project_id):
    """í”„ë¡œì íŠ¸ ì—…ë°ì´íŠ¸"""
    try:
        data = request.get_json()

        # ì…ë ¥ ë°ì´í„° ê²€ì¦ (ì—…ë°ì´íŠ¸ì´ë¯€ë¡œ í•„ìˆ˜ í•„ë“œ ì—†ìŒ)
        validation_result = validate_request_data(data, 'project')
        if not validation_result['valid']:
            return jsonify({
                'success': False,
                'error': 'Invalid input data',
                'details': validation_result['errors']
            }), 400

        # ë³´ì•ˆ ê²€ì‚¬
        security_issues = check_request_security(data)
        if security_issues:
            return jsonify({
                'success': False,
                'error': 'Security validation failed',
                'details': security_issues
            }), 400

        # í”„ë¡œì íŠ¸ ì—…ë°ì´íŠ¸
        result = db.update_project(project_id, validation_result['data'])

        if result['success']:
            return jsonify({
                'success': True,
                'project': result['project'],
                'message': result['message'],
                'simulation': result.get('simulation', False)
            })
        else:
            return jsonify({
                'success': False,
                'error': result['error']
            }), 500

    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'í”„ë¡œì íŠ¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}'
        }), 500


# ==================== ROLE-LLM MAPPING API ====================

@app.route('/api/projects/<project_id>/role-llm-mapping', methods=['GET'])
@rate_limit(max_requests=60, window_seconds=60)
def get_project_role_mapping(project_id):
    """í”„ë¡œì íŠ¸ ì—­í• -LLM ë§¤í•‘ ì¡°íšŒ"""
    try:
        result = db.get_project_role_llm_mapping(project_id)

        if result['success']:
            return jsonify({
                'success': True,
                'mappings': result['mappings'],
                'simulation': result.get('simulation', False)
            })
        else:
            return jsonify({
                'success': False,
                'error': result['error']
            }), 500

    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'LLM ë§¤í•‘ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}'
        }), 500


@app.route('/api/projects/<project_id>/role-llm-mapping', methods=['POST'])
@rate_limit(max_requests=20, window_seconds=60)
@validate_json_input(['mappings'])
def set_project_role_mapping(project_id):
    """í”„ë¡œì íŠ¸ ì—­í• -LLM ë§¤í•‘ ì„¤ì •"""
    try:
        data = request.get_json()
        mappings = data.get('mappings', [])

        # ë§¤í•‘ ë°ì´í„° ê²€ì¦
        validation_result = validate_request_data({'mappings': mappings}, 'llm_mapping')
        if not validation_result['valid']:
            return jsonify({
                'success': False,
                'error': 'Invalid mapping data',
                'details': validation_result['errors']
            }), 400

        # ë³´ì•ˆ ê²€ì‚¬
        security_issues = check_request_security(data)
        if security_issues:
            return jsonify({
                'success': False,
                'error': 'Security validation failed',
                'details': security_issues
            }), 400

        # ë§¤í•‘ ì„¤ì •
        result = db.set_project_role_llm_mapping(project_id, validation_result['mappings'])

        if result['success']:
            return jsonify({
                'success': True,
                'mappings': result['mappings'],
                'message': result['message'],
                'simulation': result.get('simulation', False)
            })
        else:
            return jsonify({
                'success': False,
                'error': result['error']
            }), 500

    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'LLM ë§¤í•‘ ì„¤ì • ì‹¤íŒ¨: {str(e)}'
        }), 500


# ==================== DATABASE UTILITIES API ====================

@app.route('/api/database/test', methods=['GET'])
@rate_limit(max_requests=10, window_seconds=60)
def test_database():
    """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸"""
    try:
        result = db.test_connection()
        return jsonify({
            'success': True,
            'result': result
        })

    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'ë°ì´í„°ë² ì´ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}'
        }), 500


@app.route('/api/database/status', methods=['GET'])
@rate_limit(max_requests=30, window_seconds=60)
def database_status():
    """ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ í™•ì¸"""
    try:
        connected = db.is_connected()
        test_result = db.test_connection()

        return jsonify({
            'connected': connected,
            'status': test_result,
            'environment': {
                'supabase_url_configured': bool(os.getenv('SUPABASE_URL')),
                'supabase_key_configured': bool(os.getenv('SUPABASE_ANON_KEY')),
                'jwt_secret_configured': bool(os.getenv('JWT_SECRET_KEY'))
            }
        })

    except Exception as e:
        return jsonify({
            'connected': False,
            'error': str(e)
        }), 500


# ==================== METAGPT API ENDPOINTS ====================

@app.route('/api/metagpt/projects', methods=['GET'])
def get_metagpt_projects():
    """Get all MetaGPT projects"""
    try:
        # Use global db instance
        result = db.get_projects()

        if result.get('success'):
            # Filter for MetaGPT projects
            metagpt_projects = [
                project for project in result['projects']
                if project.get('selected_ai') == 'meta-gpt'
            ]

            return jsonify({
                'success': True,
                'projects': metagpt_projects,
                'count': len(metagpt_projects)
            })
        else:
            return jsonify(result), 400

    except Exception as e:
        print(f"Error getting MetaGPT projects: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/metagpt/projects', methods=['POST'])
def create_metagpt_project():
    """Create a new MetaGPT project with workflow stages"""
    try:
        data = request.get_json()
        # Use global db instance

        # Create project with MetaGPT specific settings
        project_data = {
            'name': data.get('name', 'Untitled MetaGPT Project'),
            'description': data.get('description', ''),
            'selected_ai': 'meta-gpt',
            'project_type': data.get('project_type', 'web_app'),
            'status': 'planning',
            'current_stage': 'requirement',
            'progress_percentage': 0
        }

        result = db.create_metagpt_project(project_data)

        if result.get('success'):
            return jsonify(result)
        else:
            return jsonify(result), 400

    except Exception as e:
        print(f"Error creating MetaGPT project: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/metagpt/projects/<project_id>', methods=['GET'])
def get_metagpt_project(project_id):
    """Get specific MetaGPT project with workflow stages"""
    try:
        # Use global db instance
        project_result = db.get_project_by_id(project_id)
        project = project_result.get('project') if project_result.get('success') else None

        if not project:
            return jsonify({
                'success': False,
                'error': 'Project not found'
            }), 404

        # Get workflow stages
        workflow_stages = db.get_metagpt_workflow_stages(project_id)

        # Get role-LLM mapping
        role_llm_mapping = db.get_metagpt_role_llm_mapping(project_id)

        return jsonify({
            'success': True,
            'project': project,
            'workflow_stages': workflow_stages,
            'role_llm_mapping': role_llm_mapping
        })

    except Exception as e:
        print(f"Error getting MetaGPT project: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/metagpt/projects/<project_id>/workflow-stages', methods=['GET'])
def get_metagpt_workflow_stages(project_id):
    """Get workflow stages for a MetaGPT project"""
    try:
        # Use global db instance
        stages = db.get_metagpt_workflow_stages(project_id)

        return jsonify({
            'success': True,
            'workflow_stages': stages,
            'count': len(stages)
        })

    except Exception as e:
        print(f"Error getting workflow stages: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/metagpt/projects/<project_id>/workflow-stages/<stage_id>', methods=['PUT'])
def update_metagpt_workflow_stage(project_id, stage_id):
    """Update a specific workflow stage"""
    try:
        data = request.get_json()
        # Use global db instance

        status = data.get('status', 'in_progress')
        output_content = data.get('output_content', '')

        result = db.update_metagpt_stage_status(stage_id, status, output_content)

        if result.get('success'):
            return jsonify(result)
        else:
            return jsonify(result), 400

    except Exception as e:
        print(f"Error updating workflow stage: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/metagpt/projects/<project_id>/role-llm-mapping', methods=['GET'])
def get_metagpt_role_llm_mapping(project_id):
    """Get role-LLM mapping for a MetaGPT project"""
    try:
        # Use global db instance
        mapping = db.get_metagpt_role_llm_mapping(project_id)

        return jsonify({
            'success': True,
            'role_llm_mapping': mapping
        })

    except Exception as e:
        print(f"Error getting role-LLM mapping: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/metagpt/projects/<project_id>/role-llm-mapping', methods=['POST'])
def set_metagpt_role_llm_mapping(project_id):
    """Set role-LLM mapping for a MetaGPT project"""
    try:
        data = request.get_json()
        # Use global db instance

        result = db.set_metagpt_role_llm_mapping(project_id, data)

        if result.get('success'):
            return jsonify(result)
        else:
            return jsonify(result), 400

    except Exception as e:
        print(f"Error setting role-LLM mapping: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


# Deliverable endpoints will be implemented later when needed


@app.route('/api/metagpt/dashboard', methods=['GET'])
def get_metagpt_dashboard():
    """Get MetaGPT dashboard view data"""
    try:
        # Use global db instance

        # Get dashboard data using the view
        if db.is_connected():
            dashboard_data = db.supabase.table('metagpt_project_dashboard').select('*').execute()
            performance_data = db.supabase.table('metagpt_performance_summary').select('*').execute()

            return jsonify({
                'success': True,
                'dashboard': dashboard_data.data,
                'performance': performance_data.data
            })
        else:
            # Simulation mode fallback
            projects = db.get_projects_by_ai('meta-gpt')
            return jsonify({
                'success': True,
                'dashboard': projects,
                'performance': [],
                'simulation_mode': True
            })

    except Exception as e:
        print(f"Error getting MetaGPT dashboard: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# ==================== CREWAI DIRECT INTEGRATION ====================
# CrewAI ì„œë²„ ê¸°ëŠ¥ì„ ì§ì ‘ í†µí•© - ë³„ë„ ì„œë²„ ë¶ˆí•„ìš”

def start_background_execution(crew_id, inputs, script_path):
    """ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ì„ ì‹œì‘í•˜ëŠ” ê³µí†µ í•¨ìˆ˜"""
    execution_id = str(uuid.uuid4())

    execution_status[execution_id] = {
        "status": "running",
        "start_time": datetime.now(),
        "progress": 0,
        "message": "í”„ë¡œê·¸ë¨ì„ ì‹œì‘í•˜ê³  ìˆìŠµë‹ˆë‹¤...",
        "crew_id": crew_id
    }

    # ê°•í™”ëœ ë¡œê¹… ì‹œì‘
    crewai_logger.start_execution_logging(execution_id, crew_id, inputs)
    crewai_logger.log_validation(execution_id, crew_id, "script_path",
                                os.path.exists(script_path), {"script_path": script_path})

    # ì‹¤í–‰ ì´ë ¥ DBì— 'running' ìƒíƒœë¡œ ê¸°ë¡ ì‹œì‘
    try:
        if supabase:
            supabase.table('execution_history').insert({
                "id": execution_id,
                "crew_id": crew_id,
                "inputs": inputs,
                "status": "running",
                "started_at": execution_status[execution_id]['start_time'].isoformat()
            }).execute()
    except Exception as e:
        print(f"ì‹¤í–‰ ì´ë ¥ ì‹œì‘ ê¸°ë¡ ì‹¤íŒ¨: {e}")

    thread = threading.Thread(
        target=run_program_background,
        args=(crew_id, inputs, execution_id, script_path, supabase)
    )
    thread.start()

    return jsonify({
        "success": True,
        "execution_id": execution_id,
        "message": "í”„ë¡œê·¸ë¨ ì‹¤í–‰ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤."
    })

def run_program_background(crew_id, inputs, execution_id, script_path, supabase_client):
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ í”„ë¡œê·¸ë¨ ì‹¤í–‰ (ê³µí†µ ë¡œì§)"""
    start_time = time.time()
    env = os.environ.copy()
    project_name = None
    output_path = None

    # í¬ë£¨ ìƒì„±ê¸°('creator')ì¸ ê²½ìš° íŠ¹ë³„ ì²˜ë¦¬
    is_creating_crew = inputs.pop('is_crew_creator', None) == "true"

    # ì´ˆê¸°í™” ë‹¨ê³„ ì‹œì‘
    crewai_logger.start_phase(execution_id, crew_id, ExecutionPhase.INITIALIZATION)

    try:
        if is_creating_crew:
            project_name = inputs.get('project_name', 'new-crew-project')
            crewai_logger.log(
                execution_id, crew_id, ExecutionPhase.INITIALIZATION,
                crewai_logger.LogLevel.INFO,
                f"í¬ë£¨ ìƒì„± ëª¨ë“œ - í”„ë¡œì íŠ¸ëª…: {project_name}",
                {"project_name": project_name, "is_creator": True}
            )

        # ì´ˆê¸°í™” ë‹¨ê³„ ì™„ë£Œ
        crewai_logger.end_phase(execution_id, crew_id, ExecutionPhase.INITIALIZATION, True)

        # ì¤€ë¹„ ë‹¨ê³„ ì‹œì‘
        crewai_logger.start_phase(execution_id, crew_id, ExecutionPhase.PREPARATION)

        # ì‹¤í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸
        execution_status[execution_id].update({
            "progress": 25,
            "message": "í”„ë¡œê·¸ë¨ì„ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤..."
        })
        crewai_logger.log_progress_update(execution_id, crew_id, 25, "í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ì¤‘")

        # UTF-8 ì¸ì½”ë”© í™˜ê²½ë³€ìˆ˜ ì„¤ì • (Windows CP949 ë¬¸ì œ í•´ê²°)
        env['PYTHONIOENCODING'] = 'utf-8'
        env['PYTHONLEGACYWINDOWSSTDIO'] = '0'

        # í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ë¡œê¹…
        env_vars = {'PYTHONIOENCODING': 'utf-8', 'PYTHONLEGACYWINDOWSSTDIO': '0'}
        for key, value in inputs.items():
            env_key = f"CREWAI_{key.upper()}"
            env[env_key] = str(value)
            env_vars[env_key] = str(value)

        # í¬ë£¨ ìƒì„±ê¸°ì¼ ê²½ìš°, ì¶œë ¥ ê²½ë¡œë¥¼ í™˜ê²½ ë³€ìˆ˜ì— ì¶”ê°€
        if is_creating_crew:
            output_path = os.path.join(PROJECTS_BASE_DIR, project_name)
            env['CREWAI_OUTPUT_PATH'] = output_path
            env_vars['CREWAI_OUTPUT_PATH'] = output_path
            crewai_logger.log_file_operation(
                execution_id, crew_id, "output_directory_set", output_path, True,
                {"directory_exists": os.path.exists(os.path.dirname(output_path))}
            )

        # ì¤€ë¹„ ë‹¨ê³„ ì™„ë£Œ
        crewai_logger.end_phase(execution_id, crew_id, ExecutionPhase.PREPARATION, True,
                               {"environment_variables": len(env_vars), "script_validated": True})

        # ì‹¤í–‰ ë‹¨ê³„ ì‹œì‘
        crewai_logger.start_phase(execution_id, crew_id, ExecutionPhase.EXECUTION)
        crewai_logger.log_subprocess_start(execution_id, crew_id, script_path, env)

        # Simplified execution without real-time streaming
        process = subprocess.Popen(
            ["python", "-u", script_path],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            env=env,
            text=True,
            bufsize=1
        )

        full_output = []
        full_error = []

        # ëª¨ë‹ˆí„°ë§ ë‹¨ê³„ ì‹œì‘
        crewai_logger.start_phase(execution_id, crew_id, ExecutionPhase.MONITORING)

        # stdout, stderr ìŠ¤íŠ¸ë¦¼ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì½ê¸°
        line_count = 0
        while True:
            output = process.stdout.readline()
            if output:
                full_output.append(output)
                line_count += 1

                # ì£¼ìš” ì¶œë ¥ ë¡œê¹… (ë„ˆë¬´ ë§ì€ ë¡œê·¸ ë°©ì§€)
                if line_count % 10 == 1 or "ERROR" in output.upper() or "SUCCESS" in output.upper():
                    crewai_logger.log_subprocess_output(execution_id, crew_id, "stdout", output.strip())

                # CrewAI ì—­í• ë³„ ì‹¤í–‰ ê°ì§€ ë° ë¡œê¹… (Planner â†’ Researcher â†’ Writer ìˆœì„œ)
                role_keywords = {
                    "Planner": ["ê³„íš", "plan", "planning", "Planner", "ì „ëµ"],
                    "Researcher": ["ì—°êµ¬", "research", "Researcher", "ì¡°ì‚¬", "ë¶„ì„"],
                    "Writer": ["ì‘ì„±", "write", "Writer", "ê¸€", "ë¬¸ì„œ"]
                }

                for role, keywords in role_keywords.items():
                    if any(keyword in output for keyword in keywords):
                        if "ì‹œì‘" in output or "start" in output.lower():
                            crewai_logger.log_crewai_role_execution(execution_id, crew_id, role, "ì‹¤í–‰ì¤‘")
                        elif "ì™„ë£Œ" in output or "complete" in output.lower() or "finish" in output.lower():
                            crewai_logger.log_crewai_role_execution(execution_id, crew_id, role, "ì™„ë£Œ")
                        break

                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (ëŒ€ëµì )
                if line_count % 20 == 0:
                    progress = min(50 + (line_count // 20) * 5, 90)
                    execution_status[execution_id]["progress"] = progress
                    crewai_logger.log_progress_update(execution_id, crew_id, progress,
                                                    f"í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ({line_count}ì¤„ ì²˜ë¦¬)")

            if process.poll() is not None and not output:
                break

        # ëª¨ë‹ˆí„°ë§ ë‹¨ê³„ ì™„ë£Œ
        crewai_logger.end_phase(execution_id, crew_id, ExecutionPhase.MONITORING, True,
                               {"total_output_lines": line_count})

        # í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ í›„ ìµœì¢… ê²°ê³¼ ì²˜ë¦¬
        return_code = process.poll()
        stderr_output = process.stderr.read()
        if stderr_output:
            full_error.append(stderr_output)
            crewai_logger.log_subprocess_output(execution_id, crew_id, "stderr", stderr_output)

        # ì™„ë£Œ ë‹¨ê³„ ì‹œì‘
        crewai_logger.start_phase(execution_id, crew_id, ExecutionPhase.COMPLETION)

        # ì‹¤í–‰ ì™„ë£Œ ì²˜ë¦¬
        if return_code == 0:
            end_time = datetime.now()
            final_output = "".join(full_output)
            total_duration = int((time.time() - start_time) * 1000)

            execution_status[execution_id].update({
                "status": "completed",
                "progress": 100,
                "message": "í”„ë¡œê·¸ë¨ ì‹¤í–‰ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
                "output": final_output,
                "end_time": end_time
            })

            # ì„±ê³µ ì™„ë£Œ ë¡œê¹…
            crewai_logger.log_completion(
                execution_id, crew_id, True, total_duration,
                {
                    "return_code": return_code,
                    "output_lines": len(full_output),
                    "output_size_chars": len(final_output),
                    "is_crew_creation": is_creating_crew
                }
            )

            # DBì— ìµœì¢… ê²°ê³¼ ì—…ë°ì´íŠ¸
            if supabase_client:
                try:
                    supabase_client.table('execution_history').update({
                        "status": "completed",
                        "final_output": final_output,
                        "ended_at": end_time.isoformat(),
                        "duration_seconds": (end_time - execution_status[execution_id]['start_time']).total_seconds()
                    }).eq('id', execution_id).execute()
                except Exception as e:
                    print(f"ì‹¤í–‰ ì´ë ¥ ì™„ë£Œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

            # í¬ë£¨ ìƒì„±ê¸° ì‹¤í–‰ ì„±ê³µ ì‹œ, ìƒì„±ëœ í¬ë£¨ ì •ë³´ë¥¼ DBì— ì €ì¥
            if is_creating_crew and supabase_client and project_name:
                try:
                    # 'ê¸°ë³¸' í”„ë¡œì íŠ¸ê°€ ì—†ìœ¼ë©´ ìƒì„±
                    default_project_name = "ì‚¬ìš©ì ìƒì„± í¬ë£¨"
                    project_res = supabase.table('projects').select('id').eq('name', default_project_name).single().execute()
                    if not project_res.data:
                        project_res = supabase.table('projects').insert({"name": default_project_name}).select('id').single().execute()

                    project_id = project_res.data['id']

                    # ìƒì„±ëœ í¬ë£¨ ì •ë³´ ì €ì¥
                    insert_res = supabase_client.table('crews').insert({
                        "project_id": project_id,
                        "name": project_name,
                        "description": inputs.get('user_request'),
                        "crew_type": 'generated',
                        "file_path": project_name,
                        "status": 'active'
                    }).select('id').single().execute()

                except Exception as db_error:
                    print(f"DB ì €ì¥ ì˜¤ë¥˜: {db_error}")

        else:
            end_time = datetime.now()
            error_message = "".join(full_error)
            total_duration = int((time.time() - start_time) * 1000)

            execution_status[execution_id].update({
                "status": "failed",
                "progress": 0,
                "message": "í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "error": error_message,
                "end_time": end_time
            })

            # ì‹¤íŒ¨ ì™„ë£Œ ë¡œê¹…
            crewai_logger.log_completion(
                execution_id, crew_id, False, total_duration,
                {
                    "return_code": return_code,
                    "error_message": error_message,
                    "stderr_lines": len(full_error)
                }
            )

    except Exception as e:
        end_time = datetime.now()
        total_duration = int((time.time() - start_time) * 1000)

        # ì˜ˆì™¸ ë¡œê¹…
        crewai_logger.log_error(
            execution_id, crew_id, e, "run_program_background",
            {
                "script_path": script_path,
                "is_creating_crew": is_creating_crew,
                "project_name": project_name
            }
        )
        error_message = str(e)
        execution_status[execution_id].update({
            "status": "failed",
            "progress": 0,
            "message": "í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "error": error_message,
            "end_time": datetime.now()
        })

@app.route('/api/services/crewai/status')
@rate_limit(10, 60)
def crewai_server_status():
    """CrewAI ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ - ì§ì ‘ í†µí•©"""
    try:
        # Supabase ì—°ê²° ìƒíƒœ í™•ì¸
        if supabase:
            # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë¡œ ì—°ê²° í™•ì¸
            supabase.table('projects').select('id').limit(1).execute()

        return jsonify({
            'success': True,
            'status': 'integrated',
            'integration_type': 'direct',
            'supabase_connected': bool(supabase),
            'projects_path': PROJECTS_BASE_DIR
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'status': 'error',
            'error': str(e),
            'integration_type': 'direct'
        }), 503

@app.route('/api/services/crewai/projects')
@rate_limit(20, 60)
def crewai_get_projects():
    """ëª¨ë“  í”„ë¡œì íŠ¸ì™€ ê·¸ì— ì†í•œ í¬ë£¨ ëª©ë¡ì„ ì¡°íšŒ - ì§ì ‘ í†µí•©"""
    try:
        if not supabase:
            return jsonify({"success": False, "error": "Supabase is not configured."}), 500

        # 1. ëª¨ë“  í”„ë¡œì íŠ¸ ì¡°íšŒ
        projects_res = supabase.table('projects').select('*').execute()
        if not projects_res.data:
            return jsonify({"success": True, "data": []})

        projects = projects_res.data
        project_ids = [p['id'] for p in projects]

        # 2. í”„ë¡œì íŠ¸ì— ì†í•œ ëª¨ë“  í¬ë£¨ ì¡°íšŒ
        crews_res = supabase.table('crews').select('*').in_('project_id', project_ids).execute()
        crews_by_project = {}
        if crews_res.data:
            for crew in crews_res.data:
                pid = crew['project_id']
                if pid not in crews_by_project:
                    crews_by_project[pid] = []
                crews_by_project[pid].append(crew)

        # 3. ë°ì´í„° ì¡°í•©
        for project in projects:
            project['crews'] = crews_by_project.get(project['id'], [])

        return jsonify({"success": True, "data": projects})

    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/services/crewai/crews/<crew_id>/inputs')
@rate_limit(20, 60)
def crewai_get_crew_inputs(crew_id):
    """íŠ¹ì • í¬ë£¨ì˜ ì…ë ¥ í•„ë“œ ì¡°íšŒ - ì§ì ‘ í†µí•©"""
    try:
        if not supabase:
            return jsonify({"success": False, "error": "Supabase is not configured."}), 500

        result = supabase.table('crew_inputs').select('*').eq('crew_id', crew_id).order('display_order').execute()
        return jsonify({"success": True, "data": result.data})

    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/services/crewai/execute', methods=['POST'])
@rate_limit(5, 300)  # 5ë¶„ê°„ 5íšŒë¡œ ì œí•œ (ì‹¤í–‰ì€ ìì› ì§‘ì•½ì )
@validate_json_input(['crew_id', 'inputs'])
def crewai_execute():
    """í¬ë£¨ ì‹¤í–‰ - ì§ì ‘ í†µí•©"""
    try:
        data = request.get_json()
        crew_id = data['crew_id']
        inputs = data['inputs']

        if not supabase:
            return jsonify({"success": False, "error": "Supabase is not configured."}), 500

        # DBì—ì„œ í¬ë£¨ ì •ë³´ ì¡°íšŒ
        crew_res = supabase.table('crews').select('id, name, file_path, crew_type').eq('id', crew_id).single().execute()
        if not crew_res.data:
            return jsonify({"success": False, "error": "Crew not found."}), 404

        crew_info = crew_res.data

        # 'creator' íƒ€ì…ì˜ í¬ë£¨(ì˜ˆ: í¬ë£¨ ìƒì„±ê¸°)ëŠ” CrewAI ì†ŒìŠ¤ì˜ programs í´ë”ì—ì„œ ì°¾ìŒ
        if crew_info.get('crew_type') == 'creator':
            script_path = os.path.join(CREWAI_BASE_DIR, 'crewai_platform', 'programs', crew_info['file_path'])
        else:
            # 'base', 'generated' íƒ€ì… í¬ë£¨ëŠ” ëª¨ë‘ Projects í´ë” ê¸°ë°˜ìœ¼ë¡œ ê²½ë¡œë¥¼ ì°¾ìŒ
            project_folder = crew_info.get('file_path')
            if not project_folder:
                return jsonify({"success": False, "error": "Crew file_path is not defined in the database."}), 500
            script_path = os.path.join(PROJECTS_BASE_DIR, project_folder, 'run_crew.py')

        if not script_path or not os.path.exists(script_path):
            return jsonify({"success": False, "error": f"Execution script not found at {script_path}"}), 404

        # í¬ë£¨ ìƒì„±ì˜ ê²½ìš°, ì…ë ¥ê°’ì„ í™˜ê²½ë³€ìˆ˜ë¡œ ì „ë‹¬í•˜ê¸° ìœ„í•´ inputsì— ì¶”ê°€
        if crew_info.get('crew_type') == 'creator':
            inputs['is_crew_creator'] = "true"

        return start_background_execution(crew_id, inputs, script_path)

    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/services/crewai/execution/<execution_id>')
@rate_limit(30, 60)
def crewai_execution_status(execution_id):
    """ì‹¤í–‰ ìƒíƒœ ì¡°íšŒ - ì§ì ‘ í†µí•©"""
    try:
        status = execution_status.get(execution_id)
        if status:
            # datetime ê°ì²´ë¥¼ ì§ë ¬í™” ê°€ëŠ¥í•œ ë¬¸ìì—´ë¡œ ë³€í™˜
            if isinstance(status.get('start_time'), datetime):
                status['start_time'] = status['start_time'].isoformat()
            if isinstance(status.get('end_time'), datetime):
                status['end_time'] = status['end_time'].isoformat()
            return jsonify({"success": True, "data": status})
        else:
            return jsonify({
                "success": False,
                "error": "ì‹¤í–‰ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }), 404
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

# ==================== END CREWAI INTEGRATION ====================

# ==================== METAGPT EXECUTION INTEGRATION ====================

@app.route('/api/services/metagpt/execute', methods=['POST'])
@rate_limit(3, 600)  # 10ë¶„ê°„ 3íšŒë¡œ ì œí•œ (MetaGPTëŠ” ë§¤ìš° ìì› ì§‘ì•½ì )
@validate_json_input(['requirement'])
def metagpt_execute():
    """MetaGPT ì‹¤í–‰ - 5ë‹¨ê³„ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ í”„ë¡œì„¸ìŠ¤"""
    try:
        data = request.get_json()
        requirement = data['requirement']
        selected_models = data.get('role_llm_mapping', {})

        # ì‹¤í–‰ ID ìƒì„±
        execution_id = str(uuid.uuid4())

        # ì‹¤í–‰ ì •ë³´ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ê¸°ë¡ ì‹œì‘
        execution_start_time = datetime.utcnow()

        try:
            # MetaGPT ë¸Œë¦¿ì§€ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
            import subprocess
            import json as json_module

            # í˜„ì¬ ë””ë ‰í„°ë¦¬ì—ì„œ MetaGPT ë¸Œë¦¿ì§€ ì‹¤í–‰
            bridge_path = os.path.join(os.path.dirname(__file__), 'metagpt_bridge.py')

            # ëª…ë ¹ì–´ êµ¬ì„±
            cmd = [
                sys.executable,  # python.exe
                bridge_path,
                requirement,
                json_module.dumps(selected_models) if selected_models else '{}'
            ]

            # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ (íƒ€ì„ì•„ì›ƒ: 20ë¶„)
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                cwd=os.path.dirname(__file__)
            )

            # ê²°ê³¼ ëŒ€ê¸° (ìµœëŒ€ 20ë¶„)
            try:
                stdout, stderr = process.communicate(timeout=1200)  # 20ë¶„

                if process.returncode == 0:
                    # ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ
                    try:
                        metagpt_result = json_module.loads(stdout)

                        # ë°ì´í„°ë² ì´ìŠ¤ì— ê²°ê³¼ ì €ì¥
                        execution_record = {
                            'project_type': 'metagpt',
                            'execution_id': execution_id,
                            'requirement': requirement,
                            'role_llm_mapping': selected_models,
                            'status': 'completed',
                            'started_at': execution_start_time.isoformat(),
                            'completed_at': datetime.utcnow().isoformat(),
                            'duration_seconds': (datetime.utcnow() - execution_start_time).total_seconds(),
                            'result_data': metagpt_result,
                            'agents_involved': metagpt_result.get('agents_involved', []),
                            'success': True
                        }

                        # ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ë¡œì§
                        try:
                            # MetaGPT ì›Œí¬í”Œë¡œìš° ë‹¨ê³„ ìƒì„±
                            workflow_stages = [
                                {'stage_number': 1, 'stage_name': 'ìš”êµ¬ì‚¬í•­ ë¶„ì„', 'responsible_role': 'Product Manager', 'role_icon': 'ğŸ“‹'},
                                {'stage_number': 2, 'stage_name': 'ì‹œìŠ¤í…œ ì„¤ê³„', 'responsible_role': 'Architect', 'role_icon': 'ğŸ—ï¸'},
                                {'stage_number': 3, 'stage_name': 'í”„ë¡œì íŠ¸ ê³„íš', 'responsible_role': 'Project Manager', 'role_icon': 'ğŸ“Š'},
                                {'stage_number': 4, 'stage_name': 'ì½”ë“œ ê°œë°œ', 'responsible_role': 'Engineer', 'role_icon': 'ğŸ’»'},
                                {'stage_number': 5, 'stage_name': 'í’ˆì§ˆ ë³´ì¦', 'responsible_role': 'QA Engineer', 'role_icon': 'ğŸ§ª'}
                            ]

                            # í”„ë¡œì íŠ¸ ë°ì´í„° ìƒì„±
                            project_data = {
                                'name': f"MetaGPT-{execution_id[:8]}",
                                'description': requirement[:200],
                                'selected_ai': 'meta-gpt',
                                'status': 'completed',
                                'progress_percentage': 100,
                                'execution_metadata': execution_record,
                                'created_at': execution_start_time.isoformat(),
                                'updated_at': datetime.utcnow().isoformat()
                            }

                            # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                            if database.supabase:
                                # í”„ë¡œì íŠ¸ ì €ì¥
                                project_result = database.supabase.table('projects').insert(project_data).execute()
                                project_id = project_result.data[0]['id'] if project_result.data else None

                                if project_id:
                                    # MetaGPT ì›Œí¬í”Œë¡œìš° ë‹¨ê³„ ì €ì¥
                                    for stage in workflow_stages:
                                        stage_data = {
                                            'project_id': project_id,
                                            'stage_number': stage['stage_number'],
                                            'stage_name': stage['stage_name'],
                                            'responsible_role': stage['responsible_role'],
                                            'role_icon': stage['role_icon'],
                                            'status': 'completed',
                                            'progress_percentage': 100
                                        }
                                        database.supabase.table('metagpt_workflow_stages').insert(stage_data).execute()

                                execution_record['database_id'] = project_id
                                print(f"MetaGPT ì‹¤í–‰ ê²°ê³¼ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ: {project_id}")
                            else:
                                print("Supabase ì—°ê²° ì—†ìŒ - ë¡œì»¬ ë¡œê·¸ë§Œ ê¸°ë¡")
                        except Exception as db_save_error:
                            print(f"ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {db_save_error}")

                        print(f"MetaGPT ì‹¤í–‰ ì™„ë£Œ ê¸°ë¡: {execution_record}")

                        return jsonify({
                            'success': True,
                            'execution_id': execution_id,
                            'status': 'completed',
                            'requirement': requirement,
                            'result': metagpt_result,
                            'duration_seconds': execution_record['duration_seconds'],
                            'agents_involved': metagpt_result.get('agents_involved', [])
                        })

                    except json_module.JSONDecodeError:
                        # JSON íŒŒì‹± ì‹¤íŒ¨
                        return jsonify({
                            'success': False,
                            'execution_id': execution_id,
                            'error': 'MetaGPT ê²°ê³¼ íŒŒì‹± ì˜¤ë¥˜',
                            'raw_output': stdout,
                            'stderr': stderr
                        }), 500

                else:
                    # í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ì‹¤íŒ¨
                    return jsonify({
                        'success': False,
                        'execution_id': execution_id,
                        'error': f'MetaGPT ì‹¤í–‰ ì‹¤íŒ¨ (exit code: {process.returncode})',
                        'stderr': stderr,
                        'stdout': stdout
                    }), 500

            except subprocess.TimeoutExpired:
                # íƒ€ì„ì•„ì›ƒ ë°œìƒ
                process.kill()
                return jsonify({
                    'success': False,
                    'execution_id': execution_id,
                    'error': 'MetaGPT ì‹¤í–‰ ì‹œê°„ ì´ˆê³¼ (20ë¶„)',
                    'status': 'timeout'
                }), 408

        except Exception as execution_error:
            return jsonify({
                'success': False,
                'execution_id': execution_id,
                'error': f'MetaGPT ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(execution_error)}'
            }), 500

    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'MetaGPT API ì˜¤ë¥˜: {str(e)}'
        }), 500

@app.route('/api/services/metagpt/status')
@rate_limit(10, 60)
def metagpt_status():
    """MetaGPT ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
    try:
        # MetaGPT ë¸Œë¦¿ì§€ íŒŒì¼ ì¡´ì¬ í™•ì¸
        bridge_path = os.path.join(os.path.dirname(__file__), 'metagpt_bridge.py')
        bridge_exists = os.path.exists(bridge_path)

        # MetaGPT ë””ë ‰í„°ë¦¬ ì¡´ì¬ í™•ì¸
        metagpt_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'MetaGPT')
        metagpt_exists = os.path.exists(metagpt_dir)

        return jsonify({
            'success': True,
            'status': 'available' if (bridge_exists and metagpt_exists) else 'unavailable',
            'bridge_exists': bridge_exists,
            'metagpt_directory_exists': metagpt_exists,
            'bridge_path': bridge_path,
            'metagpt_path': metagpt_dir,
            'execution_timeout': '20 minutes',
            'rate_limit': '3 requests per 10 minutes'
        })

    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'MetaGPT ìƒíƒœ í™•ì¸ ì˜¤ë¥˜: {str(e)}'
        }), 500

# ==================== END METAGPT INTEGRATION ====================

# ==================== OLLAMA INTEGRATION ====================

@app.route('/api/ollama/status', methods=['GET'])
@rate_limit(max_requests=30, window_seconds=60)
def ollama_status():
    """Ollama ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
    try:
        is_available = ollama_client.is_available()

        return jsonify({
            'success': True,
            'available': is_available,
            'service': 'Ollama Local',
            'endpoint': ollama_client.base_url,
            'message': 'Ollama ì„œë¹„ìŠ¤ê°€ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤' if is_available else 'Ollama ì„œë¹„ìŠ¤ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'available': False,
            'error': f'Ollama ìƒíƒœ í™•ì¸ ì˜¤ë¥˜: {str(e)}'
        }), 500

@app.route('/api/ollama/models', methods=['GET'])
@rate_limit(max_requests=20, window_seconds=60)
def ollama_models():
    """Ollama ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ"""
    try:
        result = ollama_client.get_models()

        if result['success']:
            return jsonify({
                'success': True,
                'models': result['models'],
                'count': result['count'],
                'service': 'Ollama Local'
            })
        else:
            return jsonify({
                'success': False,
                'error': result['error'],
                'models': []
            }), 500

    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'Ollama ëª¨ë¸ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}',
            'models': []
        }), 500

@app.route('/api/ollama/models/<model_name>', methods=['GET'])
@rate_limit(max_requests=10, window_seconds=60)
def ollama_model_info(model_name):
    """íŠ¹ì • Ollama ëª¨ë¸ ì •ë³´ ì¡°íšŒ"""
    try:
        result = ollama_client.get_model_info(model_name)

        if result['success']:
            return jsonify({
                'success': True,
                'model': result
            })
        else:
            return jsonify({
                'success': False,
                'error': result['error']
            }), 404

    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'Ollama ëª¨ë¸ ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}'
        }), 500

@app.route('/api/ollama/generate', methods=['POST'])
@rate_limit(max_requests=10, window_seconds=300)  # 5ë¶„ê°„ 10íšŒ ì œí•œ
@validate_json_input(['model', 'prompt'])
def ollama_generate():
    """Ollamaë¥¼ í†µí•œ í…ìŠ¤íŠ¸ ìƒì„±"""
    try:
        data = request.get_json()
        model = data['model']
        prompt = data['prompt']
        system = data.get('system', '')
        temperature = data.get('temperature', 0.7)
        max_tokens = data.get('max_tokens', 1000)

        result = ollama_client.generate_completion(
            model=model,
            prompt=prompt,
            system=system,
            temperature=temperature,
            max_tokens=max_tokens
        )

        if result['success']:
            return jsonify({
                'success': True,
                'response': result['response'],
                'model': result['model'],
                'provider': result['provider'],
                'performance': {
                    'total_duration': result.get('total_duration', 0),
                    'load_duration': result.get('load_duration', 0),
                    'prompt_eval_count': result.get('prompt_eval_count', 0),
                    'eval_count': result.get('eval_count', 0)
                }
            })
        else:
            return jsonify({
                'success': False,
                'error': result['error']
            }), 500

    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'Ollama í…ìŠ¤íŠ¸ ìƒì„± ì˜¤ë¥˜: {str(e)}'
        }), 500

@app.route('/api/ollama/chat', methods=['POST'])
@rate_limit(max_requests=10, window_seconds=300)  # 5ë¶„ê°„ 10íšŒ ì œí•œ
@validate_json_input(['model', 'messages'])
def ollama_chat():
    """Ollamaë¥¼ í†µí•œ ì±„íŒ… ì™„ì„±"""
    try:
        data = request.get_json()
        model = data['model']
        messages = data['messages']
        temperature = data.get('temperature', 0.7)
        max_tokens = data.get('max_tokens', 1000)

        result = ollama_client.chat_completion(
            model=model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens
        )

        if result['success']:
            return jsonify({
                'success': True,
                'message': result['message'],
                'model': result['model'],
                'provider': result['provider'],
                'performance': {
                    'total_duration': result.get('total_duration', 0),
                    'load_duration': result.get('load_duration', 0),
                    'prompt_eval_count': result.get('prompt_eval_count', 0),
                    'eval_count': result.get('eval_count', 0)
                }
            })
        else:
            return jsonify({
                'success': False,
                'error': result['error']
            }), 500

    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'Ollama ì±„íŒ… ì™„ì„± ì˜¤ë¥˜: {str(e)}'
        }), 500

@app.route('/api/llm/models', methods=['GET'])
@rate_limit(max_requests=20, window_seconds=60)
def get_all_llm_models():
    """ëª¨ë“  LLM ëª¨ë¸ ëª©ë¡ ì¡°íšŒ (í´ë¼ìš°ë“œ + ë¡œì»¬)"""
    try:
        # ê¸°ë³¸ í´ë¼ìš°ë“œ LLM ëª¨ë¸ë“¤
        cloud_models = [
            { 'id': 'gpt-4', 'name': 'GPT-4', 'description': 'ë²”ìš© ê³ ì„±ëŠ¥ ëª¨ë¸', 'provider': 'OpenAI', 'type': 'cloud' },
            { 'id': 'gpt-4o', 'name': 'GPT-4o', 'description': 'ë©€í‹°ëª¨ë‹¬ ìµœì‹  ëª¨ë¸', 'provider': 'OpenAI', 'type': 'cloud' },
            { 'id': 'claude-3', 'name': 'Claude-3 Sonnet', 'description': 'ì¶”ë¡  íŠ¹í™” ëª¨ë¸', 'provider': 'Anthropic', 'type': 'cloud' },
            { 'id': 'claude-3-haiku', 'name': 'Claude-3 Haiku', 'description': 'ë¹ ë¥¸ ì‘ë‹µ ëª¨ë¸', 'provider': 'Anthropic', 'type': 'cloud' },
            { 'id': 'gemini-pro', 'name': 'Gemini Pro', 'description': 'ë©€í‹°ëª¨ë‹¬ ëª¨ë¸', 'provider': 'Google', 'type': 'cloud' },
            { 'id': 'gemini-flash', 'name': 'Gemini Flash', 'description': 'ë¹ ë¥¸ ì‘ë‹µ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸', 'provider': 'Google', 'type': 'cloud' },
            { 'id': 'deepseek-coder', 'name': 'DeepSeek Coder', 'description': 'ì½”ë”© ì „ë¬¸ ëª¨ë¸', 'provider': 'DeepSeek', 'type': 'cloud' },
            { 'id': 'codellama', 'name': 'Code Llama', 'description': 'ì½”ë“œ ìƒì„± íŠ¹í™”', 'provider': 'Meta', 'type': 'cloud' }
        ]

        all_models = cloud_models.copy()

        # Ollama ë¡œì»¬ ëª¨ë¸ë“¤ ì¶”ê°€
        if ollama_client.is_available():
            ollama_result = ollama_client.get_models()
            if ollama_result['success']:
                for model in ollama_result['models']:
                    model['type'] = 'local'
                    all_models.append(model)

        return jsonify({
            'success': True,
            'models': all_models,
            'count': len(all_models),
            'cloud_count': len(cloud_models),
            'local_count': len(all_models) - len(cloud_models),
            'ollama_available': ollama_client.is_available()
        })

    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'LLM ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}',
            'models': []
        }), 500

# ==================== END OLLAMA INTEGRATION ====================


# ===================== ìŠ¹ì¸ ì‹œìŠ¤í…œ API =====================

@app.route('/approval')
def approval_page():
    """ìŠ¹ì¸ ì‹œìŠ¤í…œ í˜ì´ì§€"""
    return render_template('approval.html')

# ===================== ìƒˆë¡œìš´ 3ë‹¨ê³„ ìŠ¹ì¸ ì‹œìŠ¤í…œ API =====================

@app.route('/api/pre-analysis', methods=['POST'])
def create_pre_analysis():
    """ì‚¬ì „ ë¶„ì„ ìš”ì²­ ìƒì„±"""
    try:
        # ì•ˆì „í•œ JSON íŒŒì‹± ì‚¬ìš©
        data = get_json_safely()

        if not data:
            return jsonify({'error': 'ìš”ì²­ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤'}), 400

        user_request = data.get('user_request')
        framework = data.get('framework', 'crewai')
        model = data.get('model', 'gemini-flash')
        project_id = data.get('project_id')

        if not user_request:
            return jsonify({'error': 'ì‚¬ìš©ì ìš”ì²­ì´ í•„ìš”í•©ë‹ˆë‹¤'}), 400

        # ì‚¬ì „ ë¶„ì„ ìˆ˜í–‰
        analysis_result = pre_analysis_service.analyze_user_request(
            user_request=user_request,
            framework=framework,
            model=model
        )

        if analysis_result.get('status') == 'error':
            return jsonify({'error': analysis_result.get('error')}), 500

        # ìŠ¹ì¸ ìš”ì²­ ìƒì„±
        approval_id = approval_workflow_manager.create_approval_request(
            analysis_result=analysis_result,
            project_id=project_id,
            requester="api"
        )

        return jsonify({
            'success': True,
            'analysis_id': analysis_result.get('analysis_id'),
            'approval_id': approval_id,
            'analysis_result': analysis_result
        })

    except Exception as e:
        print(f"ì‚¬ì „ ë¶„ì„ ìƒì„± ì˜¤ë¥˜: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/approval/pending', methods=['GET'])
def get_pending_approvals():
    """ìŠ¹ì¸ ëŒ€ê¸° ì¤‘ì¸ ìš”ì²­ ëª©ë¡ ì¡°íšŒ"""
    try:
        project_id = request.args.get('project_id')
        pending_approvals = approval_workflow_manager.get_pending_approvals(project_id)

        return jsonify(pending_approvals)

    except Exception as e:
        print(f"ìŠ¹ì¸ ëŒ€ê¸° ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/approval/<approval_id>', methods=['GET'])
def get_approval_request(approval_id):
    """íŠ¹ì • ìŠ¹ì¸ ìš”ì²­ ì¡°íšŒ"""
    try:
        approval_request = approval_workflow_manager.get_approval_request(approval_id)

        if not approval_request:
            return jsonify({'error': 'ìŠ¹ì¸ ìš”ì²­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'}), 404

        return jsonify(approval_request)

    except Exception as e:
        print(f"ìŠ¹ì¸ ìš”ì²­ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/approval/<approval_id>/respond', methods=['POST'])
def respond_to_approval(approval_id):
    """ìŠ¹ì¸ ìš”ì²­ì— ëŒ€í•œ ì‘ë‹µ ì²˜ë¦¬ - ê°•í™”ëœ ë²„ì „"""
    import traceback

    # ìš”ì²­ ì‹œì‘ ë¡œê¹…
    start_time = datetime.now()
    print(f"[APPROVAL API] ìŠ¹ì¸ ì‘ë‹µ ìš”ì²­ ì‹œì‘: {approval_id} at {start_time}")

    try:
        # 1. ì…ë ¥ ë°ì´í„° ê²€ì¦
        data = request.get_json()
        if not data:
            error_msg = "ìš”ì²­ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. JSON í˜•ì‹ì˜ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            print(f"[APPROVAL ERROR] {error_msg}")
            return jsonify({
                'success': False,
                'error': error_msg,
                'error_code': 'MISSING_DATA',
                'approval_id': approval_id
            }), 400

        # 2. í•„ìˆ˜ í•„ë“œ ê²€ì¦
        action = data.get('action')
        feedback = data.get('feedback', '')
        revisions = data.get('revisions', [])
        timestamp = data.get('timestamp')

        print(f"[APPROVAL DATA] action={action}, feedback_length={len(feedback)}, revisions_count={len(revisions) if isinstance(revisions, list) else 0}")

        if not action:
            error_msg = "action í•„ë“œê°€ í•„ìˆ˜ì…ë‹ˆë‹¤."
            print(f"[APPROVAL ERROR] {error_msg}")
            return jsonify({
                'success': False,
                'error': error_msg,
                'error_code': 'MISSING_ACTION',
                'approval_id': approval_id
            }), 400

        if action not in ['approve', 'reject', 'request_revision']:
            error_msg = f"ì˜ëª»ëœ ì•¡ì…˜: {action}. í—ˆìš©ëœ ê°’: approve, reject, request_revision"
            print(f"[APPROVAL ERROR] {error_msg}")
            return jsonify({
                'success': False,
                'error': error_msg,
                'error_code': 'INVALID_ACTION',
                'approval_id': approval_id,
                'allowed_actions': ['approve', 'reject', 'request_revision']
            }), 400

        # 3. ìŠ¹ì¸ ì›Œí¬í”Œë¡œìš° ë§¤ë‹ˆì € í™•ì¸
        if not approval_workflow_manager:
            error_msg = "ìŠ¹ì¸ ì›Œí¬í”Œë¡œìš° ë§¤ë‹ˆì €ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            print(f"[APPROVAL ERROR] {error_msg}")
            return jsonify({
                'success': False,
                'error': error_msg,
                'error_code': 'WORKFLOW_MANAGER_NOT_INITIALIZED',
                'approval_id': approval_id
            }), 500

        print(f"[APPROVAL PROCESS] ìŠ¹ì¸ ì²˜ë¦¬ ì‹œì‘: {approval_id}, action={action}")

        # 3.5. ìŠ¹ì¸ ìš”ì²­ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        approval_request = approval_workflow_manager.get_approval_request(approval_id)
        if not approval_request:
            print(f"[APPROVAL ERROR] ìŠ¹ì¸ ìš”ì²­ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {approval_id}")
            print(f"[APPROVAL INFO] ë©”ëª¨ë¦¬ ì €ì¥ì†Œì— {len(approval_workflow_manager.approval_storage)}ê°œ ìŠ¹ì¸ ìš”ì²­ ì €ì¥ë¨")
            print(f"[APPROVAL INFO] ì €ì¥ëœ ID ëª©ë¡: {list(approval_workflow_manager.approval_storage.keys())}")

            return jsonify({
                'success': False,
                'error': f'ìŠ¹ì¸ ìš”ì²­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {approval_id}',
                'error_code': 'APPROVAL_REQUEST_NOT_FOUND',
                'approval_id': approval_id,
                'debug_info': {
                    'stored_approval_count': len(approval_workflow_manager.approval_storage),
                    'stored_approval_ids': list(approval_workflow_manager.approval_storage.keys())
                }
            }), 404

        # 4. ìŠ¹ì¸ ì‘ë‹µ ì²˜ë¦¬
        result = approval_workflow_manager.process_approval_response(
            approval_id=approval_id,
            action=action,
            feedback=feedback,
            revisions=revisions
        )

        print(f"[APPROVAL RESULT] ì²˜ë¦¬ ê²°ê³¼: success={result.get('success')}, message={result.get('message')}")

        if not result.get('success'):
            error_msg = result.get('error', 'ìŠ¹ì¸ ì²˜ë¦¬ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.')
            print(f"[APPROVAL ERROR] ì›Œí¬í”Œë¡œìš° ì²˜ë¦¬ ì‹¤íŒ¨: {error_msg}")
            return jsonify({
                'success': False,
                'error': error_msg,
                'error_code': 'WORKFLOW_PROCESSING_FAILED',
                'approval_id': approval_id,
                'action': action
            }), 500

        # 5. ìŠ¹ì¸ëœ ê²½ìš° í”„ë¡œì íŠ¸ ì‹¤í–‰ ì¬ê°œ
        execution_resumed = False
        resume_error = None

        if action == 'approve':
            try:
                print(f"[APPROVAL RESUME] í”„ë¡œì íŠ¸ ì‹¤í–‰ ì¬ê°œ ì‹œì‘: {approval_id}")

                # ìŠ¹ì¸ ìš”ì²­ì—ì„œ í”„ë¡œì íŠ¸ ì •ë³´ ì¶”ì¶œ
                approval_request = approval_workflow_manager.get_approval_request(approval_id)
                if not approval_request:
                    print(f"[APPROVAL WARNING] ìŠ¹ì¸ ìš”ì²­ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {approval_id}")
                elif not approval_request.get('project_data'):
                    print(f"[APPROVAL WARNING] í”„ë¡œì íŠ¸ ë°ì´í„°ê°€ ì—†ìŒ: {approval_id}")
                else:
                    project_data = approval_request['project_data']
                    execution_id = project_data.get('execution_id')
                    framework = project_data.get('framework')

                    print(f"[APPROVAL RESUME] execution_id={execution_id}, framework={framework}")

                    # í”„ë¡œì íŠ¸ ì‹¤í–‰ ì¬ê°œ (ë°±ê·¸ë¼ìš´ë“œì—ì„œ)
                    if framework == 'crewai':
                        threading.Thread(
                            target=resume_crewai_execution,
                            args=(execution_id, project_data),
                            daemon=True,
                            name=f"CrewAI-Resume-{execution_id[:8]}"
                        ).start()
                        execution_resumed = True
                        print(f"[APPROVAL RESUME] CrewAI ì‹¤í–‰ ì¬ê°œ ìŠ¤ë ˆë“œ ì‹œì‘ë¨")

                    elif framework == 'metagpt':
                        threading.Thread(
                            target=resume_metagpt_execution,
                            args=(execution_id, project_data),
                            daemon=True,
                            name=f"MetaGPT-Resume-{execution_id[:8]}"
                        ).start()
                        execution_resumed = True
                        print(f"[APPROVAL RESUME] MetaGPT ì‹¤í–‰ ì¬ê°œ ìŠ¤ë ˆë“œ ì‹œì‘ë¨")

                    else:
                        print(f"[APPROVAL WARNING] ì•Œ ìˆ˜ ì—†ëŠ” í”„ë ˆì„ì›Œí¬: {framework}")

            except Exception as resume_error:
                print(f"[APPROVAL ERROR] í”„ë¡œì íŠ¸ ì‹¤í–‰ ì¬ê°œ ì‹¤íŒ¨: {resume_error}")
                print(f"[APPROVAL ERROR] ì¬ê°œ ì˜¤ë¥˜ ìŠ¤íƒ:\n{traceback.format_exc()}")
                # ì¬ê°œ ì‹¤íŒ¨ëŠ” ì¹˜ëª…ì ì´ì§€ ì•Šìœ¼ë¯€ë¡œ ê³„ì† ì§„í–‰

        # 6. ì„±ê³µ ì‘ë‹µ ë°˜í™˜
        action_messages = {
            'approve': 'ìŠ¹ì¸ë˜ì—ˆìŠµë‹ˆë‹¤. í”„ë¡œì íŠ¸ ì‹¤í–‰ì´ ì¬ê°œë©ë‹ˆë‹¤.',
            'reject': 'ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.',
            'request_revision': 'ìˆ˜ì • ìš”ì²­ì´ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.'
        }

        response_data = {
            'success': True,
            'message': action_messages.get(action, f'{action} ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.'),
            'approval_id': approval_id,
            'action': action,
            'processed_at': datetime.now().isoformat(),
            'processing_time_ms': int((datetime.now() - start_time).total_seconds() * 1000)
        }

        # ìŠ¹ì¸ì¸ ê²½ìš° ì‹¤í–‰ ì¬ê°œ ì •ë³´ ì¶”ê°€
        if action == 'approve':
            response_data['execution_resumed'] = execution_resumed
            if resume_error:
                response_data['resume_warning'] = str(resume_error)

        print(f"[APPROVAL SUCCESS] ìŠ¹ì¸ ì²˜ë¦¬ ì™„ë£Œ: {approval_id}, action={action}, duration={(datetime.now() - start_time).total_seconds():.2f}s")

        return jsonify(response_data)

    except Exception as e:
        # 7. ì „ì²´ ì˜ˆì™¸ ì²˜ë¦¬
        error_duration = (datetime.now() - start_time).total_seconds()
        error_traceback = traceback.format_exc()

        print(f"[APPROVAL CRITICAL ERROR] ìŠ¹ì¸ ì²˜ë¦¬ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ:")
        print(f"  - approval_id: {approval_id}")
        print(f"  - ì²˜ë¦¬ ì‹œê°„: {error_duration:.2f}s")
        print(f"  - ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
        print(f"  - ì˜¤ë¥˜ ë©”ì‹œì§€: {str(e)}")
        print(f"  - ìŠ¤íƒ ì¶”ì :\n{error_traceback}")

        return jsonify({
            'success': False,
            'error': f'ìŠ¹ì¸ ì²˜ë¦¬ ì¤‘ ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}',
            'error_code': 'SYSTEM_ERROR',
            'error_type': type(e).__name__,
            'approval_id': approval_id,
            'processing_time_ms': int(error_duration * 1000)
        }), 500

@app.route('/api/approval/<approval_id>', methods=['POST'])
def process_approval_response(approval_id):
    """ìŠ¹ì¸ ì‘ë‹µ ì²˜ë¦¬"""
    try:
        data = request.get_json()
        action = data.get('action')
        feedback = data.get('feedback')
        revisions = data.get('revisions')

        if action not in ['approve', 'reject', 'request_revision']:
            return jsonify({'error': 'ìœ íš¨í•˜ì§€ ì•Šì€ ì•¡ì…˜ì…ë‹ˆë‹¤'}), 400

        result = approval_workflow_manager.process_approval_response(
            approval_id=approval_id,
            action=action,
            feedback=feedback,
            revisions=revisions
        )

        if result.get('success'):
            # ìŠ¹ì¸ëœ ê²½ìš° ì‹¤ì œ ì‹¤í–‰ ì‹œì‘
            if action == 'approve':
                approval_request = approval_workflow_manager.get_approval_request(approval_id)
                if approval_request:
                    # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ ì‹œì‘
                    threading.Thread(
                        target=start_execution_after_approval,
                        args=(approval_request,),
                        daemon=True
                    ).start()

        return jsonify(result)

    except Exception as e:
        print(f"ìŠ¹ì¸ ì‘ë‹µ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/approval/<approval_id>/revise', methods=['POST'])
def revise_analysis(approval_id):
    """ë¶„ì„ ê²°ê³¼ ìˆ˜ì • ì ìš©"""
    try:
        data = request.get_json()
        revised_analysis = data.get('revised_analysis')

        if not revised_analysis:
            return jsonify({'error': 'ìˆ˜ì •ëœ ë¶„ì„ ê²°ê³¼ê°€ í•„ìš”í•©ë‹ˆë‹¤'}), 400

        result = approval_workflow_manager.apply_revisions(
            approval_id=approval_id,
            revised_analysis=revised_analysis
        )

        return jsonify(result)

    except Exception as e:
        print(f"ìˆ˜ì • ì ìš© ì˜¤ë¥˜: {e}")
        return jsonify({'error': str(e)}), 500

def start_execution_after_approval(approval_request):
    """ìŠ¹ì¸ í›„ ì‹¤í–‰ ì‹œì‘"""
    try:
        framework = approval_request.get('metadata', {}).get('framework')
        project_id = approval_request.get('project_id')
        analysis_result = approval_request.get('analysis_result')
        analysis = analysis_result.get('analysis', {})

        print(f"ìŠ¹ì¸ í›„ ì‹¤í–‰ ì‹œì‘: í”„ë ˆì„ì›Œí¬={framework}, í”„ë¡œì íŠ¸={project_id}")

        # ê¸°ì¡´ ì‹¤í–‰ ë¡œì§ê³¼ ì—°ë™
        if framework == 'crewai':
            # CrewAI ì‹¤í–‰ - ìŠ¹ì¸ëœ êµ¬ì¡°í™” í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
            structured_prompt = create_structured_crewai_prompt(analysis)

            # í”„ë¡œì íŠ¸ ìƒì„± ë° ì‹¤í–‰
            execution_id = str(uuid.uuid4())

            # ìƒì„±ëœ êµ¬ì¡°í™” í”„ë¡¬í”„íŠ¸ë¡œ CrewAI ì‹¤í–‰
            inputs = {
                'original_request': analysis_result.get('original_request', ''),
                'structured_plan': structured_prompt,
                'project_summary': analysis.get('project_summary', ''),
                'objectives': analysis.get('objectives', []),
                'agents_config': analysis.get('agents', []),
                'workflow_config': analysis.get('workflow', []),
                'approval_id': approval_request.get('approval_id')
            }

            # ê¸°ë³¸ í¬ë£¨ ID ì‚¬ìš© (existing crew or create new)
            crew_id = "structured-crewai-execution"

            # ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ ì‹œì‘ - ê¸°ì¡´ í•¨ìˆ˜ í™œìš©
            start_structured_background_execution(execution_id, inputs, framework='crewai')

        elif framework == 'metagpt':
            # MetaGPT ì‹¤í–‰ - ìŠ¹ì¸ëœ êµ¬ì¡°í™” í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
            structured_requirement = create_structured_metagpt_requirement(analysis)

            execution_id = str(uuid.uuid4())

            # MetaGPT ì‹¤í–‰ ë°ì´í„° ì¤€ë¹„
            metagpt_data = {
                'requirement': structured_requirement,
                'original_request': analysis_result.get('original_request', ''),
                'project_summary': analysis.get('project_summary', ''),
                'workflow_stages': analysis.get('workflow', []),
                'approval_id': approval_request.get('approval_id')
            }

            # MetaGPT ì‹¤í–‰ ì‹œì‘
            start_structured_background_execution(execution_id, metagpt_data, framework='metagpt')

    except Exception as e:
        print(f"ìŠ¹ì¸ í›„ ì‹¤í–‰ ì˜¤ë¥˜: {e}")

def create_structured_crewai_prompt(analysis):
    """ë¶„ì„ ê²°ê³¼ë¥¼ CrewAIìš© êµ¬ì¡°í™” í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜"""
    agents = analysis.get('agents', [])
    workflow = analysis.get('workflow', [])
    objectives = analysis.get('objectives', [])

    prompt = f"""
# í”„ë¡œì íŠ¸ ê³„íš: {analysis.get('project_summary', '')}

## ëª©í‘œ
{chr(10).join(f'- {obj}' for obj in objectives)}

## ì—ì´ì „íŠ¸ ì—­í•  ë¶„ë‹´
{chr(10).join(f'''
### {agent.get('role', '')}
- **ì „ë¬¸ ë¶„ì•¼**: {agent.get('expertise', '')}
- **ì±…ì„ì‚¬í•­**: {', '.join(agent.get('responsibilities', []))}
- **ì‚°ì¶œë¬¼**: {', '.join(agent.get('deliverables', []))}
''' for agent in agents)}

## ì‘ì—… ê³„íš
{chr(10).join(f'''
### ë‹¨ê³„ {step.get('step', i+1)}: {step.get('title', '')}
- **ë‹´ë‹¹**: {step.get('agent', '')}
- **ì„¤ëª…**: {step.get('description', '')}
- **ì˜ˆìƒ ì‹œê°„**: {step.get('estimated_time', '')}
''' for i, step in enumerate(workflow))}

ì´ ê³„íšì— ë”°ë¼ ì²´ê³„ì ìœ¼ë¡œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ì„¸ìš”.
"""
    return prompt

def create_structured_metagpt_requirement(analysis):
    """ë¶„ì„ ê²°ê³¼ë¥¼ MetaGPTìš© êµ¬ì¡°í™” ìš”êµ¬ì‚¬í•­ìœ¼ë¡œ ë³€í™˜"""
    objectives = analysis.get('objectives', [])
    workflow = analysis.get('workflow', [])

    requirement = f"""
í”„ë¡œì íŠ¸: {analysis.get('project_summary', '')}

ìš”êµ¬ì‚¬í•­:
{chr(10).join(f'- {obj}' for obj in objectives)}

ê°œë°œ ë‹¨ê³„:
{chr(10).join(f'{i+1}. {step.get("title", "")}: {step.get("description", "")}' for i, step in enumerate(workflow))}

ì´ ìš”êµ¬ì‚¬í•­ì— ë”°ë¼ 5ë‹¨ê³„ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ í”„ë¡œì„¸ìŠ¤ë¥¼ ì§„í–‰í•˜ì„¸ìš”.
"""
    return requirement

def start_structured_background_execution(execution_id, data, framework):
    """ìŠ¹ì¸ëœ êµ¬ì¡°í™” ë°ì´í„°ë¡œ ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰"""
    try:
        execution_status[execution_id] = {
            'status': 'starting',
            'framework': framework,
            'start_time': datetime.now(),
            'approval_based': True,
            'data': data
        }

        if framework == 'crewai':
            # CrewAI êµ¬ì¡°í™” ì‹¤í–‰
            def run_crewai():
                try:
                    execution_status[execution_id]['status'] = 'running'

                    # êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ë¡œ CrewAI ì‹¤í–‰
                    # ì‹¤ì œ êµ¬í˜„ì‹œ generate_crewai_script_new.pyì˜ ë¡œì§ í™œìš©

                    execution_status[execution_id].update({
                        'status': 'completed',
                        'end_time': datetime.now()
                    })

                except Exception as e:
                    execution_status[execution_id].update({
                        'status': 'failed',
                        'error': str(e),
                        'end_time': datetime.now()
                    })

            threading.Thread(target=run_crewai, daemon=True).start()

        elif framework == 'metagpt':
            # MetaGPT êµ¬ì¡°í™” ì‹¤í–‰
            def run_metagpt():
                try:
                    execution_status[execution_id]['status'] = 'running'

                    # êµ¬ì¡°í™”ëœ ìš”êµ¬ì‚¬í•­ìœ¼ë¡œ MetaGPT ì‹¤í–‰
                    # ì‹¤ì œ êµ¬í˜„ì‹œ ê¸°ì¡´ MetaGPT ë¡œì§ í™œìš©

                    execution_status[execution_id].update({
                        'status': 'completed',
                        'end_time': datetime.now()
                    })

                except Exception as e:
                    execution_status[execution_id].update({
                        'status': 'failed',
                        'error': str(e),
                        'end_time': datetime.now()
                    })

            threading.Thread(target=run_metagpt, daemon=True).start()

    except Exception as e:
        print(f"êµ¬ì¡°í™” ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        execution_status[execution_id] = {
            'status': 'failed',
            'error': str(e),
            'end_time': datetime.now()
        }

# ===================== ê¸°ì¡´ ìŠ¹ì¸ ì‹œìŠ¤í…œ (í˜¸í™˜ì„± ìœ ì§€) =====================

@app.route('/api/projects/pending-approval')
def get_pending_approval_projects():
    """ìŠ¹ì¸ ëŒ€ê¸° ì¤‘ì¸ í”„ë¡œì íŠ¸ ëª©ë¡ ì¡°íšŒ"""
    try:
        from project_state_manager import ProjectStateManager, ProjectStatus

        projects_dir = os.path.join(os.path.dirname(__file__), '../Projects')
        pending_projects = []

        # ëª¨ë“  í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ìŠ¤ìº”
        if os.path.exists(projects_dir):
            for project_name in os.listdir(projects_dir):
                project_path = os.path.join(projects_dir, project_name)
                if os.path.isdir(project_path):
                    try:
                        manager = ProjectStateManager(project_path)
                        status_data = manager.load_project_status()
                        requirements_data = manager.load_original_requirements()

                        if (status_data and
                            status_data.get('status') == ProjectStatus.PLANNER_APPROVAL_PENDING.value):

                            # Planner ê²°ê³¼ ë¡œë“œ
                            planner_result_file = os.path.join(project_path, "planner_result.md")
                            plan_content = "ê³„íš ë‚´ìš©ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

                            if os.path.exists(planner_result_file):
                                with open(planner_result_file, 'r', encoding='utf-8') as f:
                                    plan_content = f.read()

                            project_info = {
                                'id': project_name,
                                'name': status_data.get('project_name', project_name),
                                'description': status_data.get('description', ''),
                                'status': status_data.get('status'),
                                'created_at': status_data.get('created_at'),
                                'current_agent': 'Planner',
                                'original_requirements': requirements_data.get('original_request', '') if requirements_data else '',
                                'plan_content': plan_content
                            }

                            pending_projects.append(project_info)
                    except Exception as e:
                        print(f"í”„ë¡œì íŠ¸ {project_name} ìƒíƒœ í™•ì¸ ì˜¤ë¥˜: {e}")
                        continue

        return jsonify(pending_projects)

    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/projects/<project_id>/approval', methods=['POST'])
def submit_project_approval(project_id):
    """í”„ë¡œì íŠ¸ ìŠ¹ì¸/ê±°ë¶€ ì²˜ë¦¬"""
    try:
        from project_state_manager import ProjectStateManager

        data = request.get_json()
        decision = data.get('decision')  # 'approved', 'rejected', 'modify_requested'
        feedback = data.get('feedback', '')

        projects_dir = os.path.join(os.path.dirname(__file__), '../Projects')
        project_path = os.path.join(projects_dir, project_id)

        if not os.path.exists(project_path):
            return jsonify({'error': 'í”„ë¡œì íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 404

        # ìŠ¹ì¸ íŒŒì¼ ìƒì„±
        approval_file = os.path.join(project_path, "planner_approval.json")
        approval_data = {
            'decision': decision,
            'feedback': feedback,
            'timestamp': datetime.now().isoformat(),
            'reviewer': 'user'
        }

        with open(approval_file, 'w', encoding='utf-8') as f:
            json.dump(approval_data, f, ensure_ascii=False, indent=2)

        # ìƒíƒœ ê´€ë¦¬ìë¥¼ í†µí•´ ìƒíƒœ ì—…ë°ì´íŠ¸
        manager = ProjectStateManager(project_path)

        if decision == 'approved':
            manager.mark_approval_granted('planner')
        elif decision in ['rejected', 'modify_requested']:
            manager.mark_approval_rejected('planner', feedback)

        return jsonify({
            'success': True,
            'message': f'í”„ë¡œì íŠ¸ {project_id}ì— ëŒ€í•œ ê²°ì •ì´ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.',
            'decision': decision
        })

    except Exception as e:
        return jsonify({'error': str(e)}), 500

# ===================== ë©”ì¸ ì‹¤í–‰ ë¸”ë¡ =====================

if __name__ == '__main__':
    print("AI Chat Interface Server (Flask) starting...")
    print(f"Server URL: http://localhost:{PORT}")
    print("Available endpoints:")
    print("  - GET  /                    (Main page)")
    print("  - POST /api/crewai          (CrewAI requests)")
    print("  - POST /api/metagpt         (MetaGPT requests)")
    print("  - GET  /api/health          (Health check)")
    print("  - GET  /api/services/status (Service status)")
    print("  - POST /api/services/crewai/start (Start CrewAI service)")
    print("  - GET  /api/projects        (Get projects)")
    print("  - POST /api/projects        (Create project)")
    print("  - GET  /api/projects/<id>   (Get project)")
    print("  - PUT  /api/projects/<id>   (Update project)")
    print("  - GET  /api/projects/<id>/role-llm-mapping (Get LLM mappings)")
    print("  - POST /api/projects/<id>/role-llm-mapping (Set LLM mappings)")
    print("  - GET  /api/database/test   (Test database)")
    print("  - GET  /api/database/status (Database status)")
    print("  MetaGPT Endpoints:")
    print("  - GET  /api/metagpt/projects (Get MetaGPT projects)")
    print("  - POST /api/metagpt/projects (Create MetaGPT project)")
    print("  - GET  /api/metagpt/projects/<id> (Get MetaGPT project)")
    print("  - GET  /api/metagpt/projects/<id>/workflow-stages (Get workflow stages)")
    print("  - PUT  /api/metagpt/projects/<id>/workflow-stages/<stage_id> (Update stage)")
    print("  - GET  /api/metagpt/projects/<id>/role-llm-mapping (Get MetaGPT LLM mappings)")
    print("  - POST /api/metagpt/projects/<id>/role-llm-mapping (Set MetaGPT LLM mappings)")
# Deliverable endpoints commented out for now
    print("  - GET  /api/metagpt/dashboard (Get MetaGPT dashboard)")

# ===================== CREWAI ë¡œê¹… API =====================

@app.route('/api/crewai/logs/<execution_id>', methods=['GET'])
def get_execution_logs(execution_id):
    """ì‹¤í–‰ ë¡œê·¸ ì¡°íšŒ"""
    try:
        logs = crewai_logger.get_execution_logs(execution_id)
        summary = crewai_logger.get_execution_summary(execution_id)

        return jsonify({
            "success": True,
            "execution_id": execution_id,
            "logs": logs,
            "summary": summary
        })
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/crewai/logs/<execution_id>/summary', methods=['GET'])
def get_execution_summary_api(execution_id):
    """ì‹¤í–‰ ìš”ì•½ ì •ë³´"""
    try:
        summary = crewai_logger.get_execution_summary(execution_id)

        if not summary:
            return jsonify({"success": False, "error": "Execution not found"}), 404

        return jsonify({
            "success": True,
            "summary": summary
        })
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/crewai/logs/<execution_id>/phases', methods=['GET'])
def get_execution_phases(execution_id):
    """ì‹¤í–‰ ë‹¨ê³„ë³„ ë¡œê·¸"""
    try:
        logs = crewai_logger.get_execution_logs(execution_id)

        # ë‹¨ê³„ë³„ ê·¸ë£¹í™”
        phases = {}
        for log in logs:
            phase = log['phase']
            if phase not in phases:
                phases[phase] = []
            phases[phase].append(log)

        return jsonify({
            "success": True,
            "execution_id": execution_id,
            "phases": phases
        })
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/crewai/logs/<execution_id>/errors', methods=['GET'])
def get_execution_errors(execution_id):
    """ì‹¤í–‰ ì—ëŸ¬ ë¡œê·¸ë§Œ ì¡°íšŒ"""
    try:
        logs = crewai_logger.get_execution_logs(execution_id)

        # ì—ëŸ¬ ë¡œê·¸ë§Œ í•„í„°ë§
        error_logs = [log for log in logs if log['level'] in ['ERROR', 'CRITICAL']]

        return jsonify({
            "success": True,
            "execution_id": execution_id,
            "error_count": len(error_logs),
            "errors": error_logs
        })
    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

# WebSocket event handlers removed

    print("\nğŸ” CrewAI Enhanced Logging:")
    print("  - GET  /api/crewai/logs/<execution_id> (Get execution logs)")
    print("  - GET  /api/crewai/logs/<execution_id>/summary (Get execution summary)")
    print("  - GET  /api/crewai/logs/<execution_id>/phases (Get phase logs)")
    print("  - GET  /api/crewai/logs/<execution_id>/errors (Get error logs)")
    print("  - WebSocket functionality removed")

# ===================== CrewAI ê°œì„ ëœ ìŠ¹ì¸ ì‹œìŠ¤í…œ API =====================

# ì „ì—­ ìŠ¹ì¸ ìƒíƒœ ê´€ë¦¬
approval_states = {}
approval_events = {}

@app.route('/api/crewai/approval/<execution_id>')
def crewai_approval_page(execution_id):
    """CrewAI ê°œì„ ëœ ìŠ¹ì¸ ì‹œìŠ¤í…œ í˜ì´ì§€"""
    if execution_id not in approval_states:
        return "ìŠ¹ì¸ ìš”ì²­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", 404

    approval_data = approval_states[execution_id]

    # HTML í…œí”Œë¦¿ ì§ì ‘ ë°˜í™˜
    html_content = f'''
    <!DOCTYPE html>
    <html lang="ko">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>CrewAI ìŠ¹ì¸ ì‹œìŠ¤í…œ - {approval_data.get("stage_name", "ë‹¨ê³„")}</title>
        <style>
            * {{ margin: 0; padding: 0; box-sizing: border-box; }}
            body {{ font-family: 'Arial', sans-serif; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; padding: 20px; }}
            .container {{ max-width: 1200px; margin: 0 auto; background: white; border-radius: 15px; box-shadow: 0 10px 30px rgba(0,0,0,0.3); overflow: hidden; }}
            .header {{ background: linear-gradient(135deg, #4834d4, #686de0); color: white; padding: 30px; text-align: center; }}
            .content {{ padding: 30px; }}
            .stage-badge {{ display: inline-block; padding: 8px 16px; border-radius: 20px; font-size: 14px; font-weight: bold; margin-bottom: 20px; }}
            .stage-1 {{ background-color: #e3f2fd; color: #1976d2; }}
            .stage-2 {{ background-color: #f3e5f5; color: #7b1fa2; }}
            .stage-3 {{ background-color: #e8f5e8; color: #388e3c; }}
            .functionality-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; margin: 20px 0; }}
            .function-card {{ border: 1px solid #e0e0e0; border-radius: 10px; padding: 20px; }}
            .priority-high {{ border-left: 4px solid #f44336; }}
            .priority-medium {{ border-left: 4px solid #ff9800; }}
            .priority-low {{ border-left: 4px solid #4caf50; }}
            .tech-stack {{ background-color: #f5f5f5; padding: 15px; border-radius: 8px; margin: 10px 0; }}
            .role-instructions {{ background-color: #fff3e0; padding: 20px; border-radius: 10px; margin: 20px 0; }}
            .buttons {{ display: flex; gap: 20px; justify-content: center; margin-top: 30px; }}
            .btn {{ padding: 15px 30px; border: none; border-radius: 8px; font-size: 16px; cursor: pointer; font-weight: bold; transition: all 0.3s; }}
            .btn-approve {{ background-color: #4caf50; color: white; }}
            .btn-reject {{ background-color: #f44336; color: white; }}
            .btn:hover {{ transform: translateY(-2px); box-shadow: 0 5px 15px rgba(0,0,0,0.2); }}
            .feedback-area {{ margin-top: 20px; }}
            .feedback-area textarea {{ width: 100%; padding: 15px; border: 1px solid #ddd; border-radius: 8px; resize: vertical; min-height: 80px; }}
        </style>
    </head>
    <body>
        <div class="container">
            <div class="header">
                <h1>ğŸ¤– CrewAI ìŠ¹ì¸ ì‹œìŠ¤í…œ</h1>
                <p>ë‹¨ê³„ë³„ ê²€í†  ë° ìŠ¹ì¸</p>
            </div>
            <div class="content">
                <div class="stage-badge stage-{approval_data.get("stage_number", "1")}">{approval_data.get("stage_name", "ë‹¨ê³„")}</div>

                <h2>ğŸ“‹ í•µì‹¬ ê¸°ëŠ¥ ë¶„ì„</h2>
                <div id="functionalitySection">
                    {approval_data.get("functionality_html", "<p>ê¸°ëŠ¥ ì •ë³´ë¥¼ ë¡œë”© ì¤‘...</p>")}
                </div>

                <div class="role-instructions">
                    <h3>ğŸ‘¤ ì—­í• ë³„ ì§€ì‹œì‚¬í•­</h3>
                    <div id="roleInstructions">
                        {approval_data.get("role_instructions", "<p>ì—­í•  ì§€ì‹œì‚¬í•­ì„ ë¡œë”© ì¤‘...</p>")}
                    </div>
                </div>

                <div class="feedback-area">
                    <h3>ğŸ’¬ í”¼ë“œë°± (ì„ íƒì‚¬í•­)</h3>
                    <textarea id="feedback" placeholder="ì¶”ê°€ ìš”êµ¬ì‚¬í•­ì´ë‚˜ ìˆ˜ì •ì‚¬í•­ì„ ì…ë ¥í•˜ì„¸ìš”..."></textarea>
                </div>

                <div class="buttons">
                    <button class="btn btn-approve" onclick="submitDecision('approved')">âœ… ìŠ¹ì¸</button>
                    <button class="btn btn-reject" onclick="submitDecision('rejected')">âŒ ê±°ë¶€</button>
                </div>
            </div>
        </div>

        <script>
            function submitDecision(decision) {{
                const feedback = document.getElementById('feedback').value;

                fetch('/api/crewai/approval/{execution_id}', {{
                    method: 'POST',
                    headers: {{'Content-Type': 'application/json'}},
                    body: JSON.stringify({{
                        decision: decision,
                        feedback: feedback
                    }})
                }})
                .then(response => response.json())
                .then(data => {{
                    if (data.success) {{
                        alert('ê²°ì •ì´ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤: ' + decision);
                        window.close();
                    }} else {{
                        alert('ì˜¤ë¥˜: ' + data.error);
                    }}
                }})
                .catch(error => {{
                    alert('ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: ' + error);
                }});
            }}
        </script>
    </body>
    </html>
    '''

    return html_content

@app.route('/api/crewai/approval/<execution_id>', methods=['POST'])
def submit_crewai_approval(execution_id):
    """CrewAI ìŠ¹ì¸ ê²°ì • ì²˜ë¦¬"""
    if execution_id not in approval_events:
        return jsonify({{'error': 'ìŠ¹ì¸ ìš”ì²­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'success': False}}), 404

    data = request.get_json()
    decision = data.get('decision')
    feedback = data.get('feedback', '')

    # ì „ì—­ ìŠ¹ì¸ ìƒíƒœ ì—…ë°ì´íŠ¸
    if execution_id in approval_states:
        approval_states[execution_id]['decision'] = decision
        approval_states[execution_id]['feedback'] = feedback
        approval_states[execution_id]['response'] = decision

    # ìŠ¹ì¸ ì´ë²¤íŠ¸ ì„¤ì •
    if execution_id in approval_events:
        approval_events[execution_id].set()

    return jsonify({{'success': True, 'message': f'ê²°ì •ì´ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤: {{decision}}'}})

@app.route('/api/crewai/approval/<execution_id>/register', methods=['POST'])
def register_crewai_approval_request(execution_id):
    """CrewAI ìŠ¹ì¸ ìš”ì²­ ë“±ë¡"""
    data = request.get_json()

    # ìŠ¹ì¸ ìƒíƒœ ì €ì¥
    approval_states[execution_id] = {
        'stage_name': data.get('stage_name', 'ë‹¨ê³„'),
        'stage_number': data.get('stage_number', '1'),
        'functionality_html': data.get('functionality_html', ''),
        'role_instructions': data.get('role_instructions', ''),
        'decision': None,
        'feedback': '',
        'response': None
    }

    # ìŠ¹ì¸ ì´ë²¤íŠ¸ ìƒì„±
    approval_events[execution_id] = threading.Event()

    return jsonify({'success': True, 'message': 'ìŠ¹ì¸ ìš”ì²­ì´ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.'})

@app.route('/api/crewai/approval/<execution_id>/status')
def get_crewai_approval_status(execution_id):
    """CrewAI ìŠ¹ì¸ ìƒíƒœ í™•ì¸"""
    if execution_id not in approval_states:
        return jsonify({'error': 'ìŠ¹ì¸ ìš”ì²­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 404

    approval_state = approval_states[execution_id]
    return jsonify({
        'execution_id': execution_id,
        'decision': approval_state.get('decision'),
        'feedback': approval_state.get('feedback'),
        'completed': approval_state.get('decision') is not None
    })

    print("\nğŸ”” Project Approval System:")
    print("  - GET  /approval (Approval UI page)")
    print("  - GET  /api/projects/pending-approval (Get pending projects)")
    print("  - POST /api/projects/<project_id>/approval (Submit approval decision)")

    print("\nğŸš€ CrewAI Enhanced Approval System:")
    print("  - GET  /api/crewai/approval/<execution_id> (Enhanced approval UI)")
    print("  - POST /api/crewai/approval/<execution_id> (Submit approval decision)")
    print("  - POST /api/crewai/approval/<execution_id>/register (Register approval request)")
    print("  - GET  /api/crewai/approval/<execution_id>/status (Get approval status)")

# ì‹¤í–‰ ì¬ê°œ í•¨ìˆ˜ë“¤
def resume_crewai_execution(execution_id, project_data):
    """CrewAI ì‹¤í–‰ ì¬ê°œ - ì •ì„ì ì¸ ë°©ë²•ìœ¼ë¡œ ì „ì²´ CrewAI ë¡œì§ ì‹¤í–‰"""
    import threading

    def run_full_crewai_execution():
        """ìŠ¹ì¸ëœ í”„ë¡œì íŠ¸ ë°ì´í„°ë¡œ ì „ì²´ CrewAI ì‹¤í–‰"""
        try:
            print(f"[CREWAI RESUME] ì „ì²´ CrewAI ì‹¤í–‰ ì‹œì‘: {execution_id}")

            # í”„ë¡œì íŠ¸ ë°ì´í„° ì¶”ì¶œ
            requirement = project_data.get('requirement')
            selected_models = project_data.get('selected_models', {})
            crew_id = project_data.get('crew_id')
            project_path = project_data.get('project_path')
            projects_base_dir = project_data.get('projects_base_dir')

            print(f"[CREWAI RESUME] í”„ë¡œì íŠ¸ ì •ë³´ ì¶”ì¶œ ì™„ë£Œ:")
            print(f"  - requirement: {requirement}")
            print(f"  - project_path: {project_path}")
            print(f"  - crew_id: {crew_id}")

            # ì‹¤í–‰ ìƒíƒœ ì´ˆê¸°í™”
            execution_status[execution_id] = {
                'status': 'running',
                'message': 'ìŠ¹ì¸ ì™„ë£Œ - CrewAI ì‹¤í–‰ ì‹œì‘',
                'start_time': datetime.now(),
                'execution_id': execution_id,
                'crew_id': crew_id,
                'requirement': requirement,
                'models': selected_models,
                'project_path': project_path,
                'phase': 'resumed_execution'
            }

            # CrewAI ë¡œê±° ì‹œì‘
            crewai_logger.start_execution_logging(execution_id, crew_id, {
                'requirement': requirement,
                'selected_models': selected_models,
                'project_id': project_data.get('project_id'),
                'resumed': True
            })

            crewai_logger.start_step_tracking(execution_id, crew_id, total_steps=10)

            # ë‹¨ê³„ 1: ì‹œìŠ¤í…œ ê²€ì¦
            crewai_logger.advance_step(execution_id, crew_id, "ì‹œìŠ¤í…œ ê²€ì¦", "ì‹œì‘", ExecutionPhase.VALIDATION)
            crewai_logger.log_system_check(execution_id, crew_id, "UTF-8 ì¸ì½”ë”© í™˜ê²½", True)

            # ë‹¨ê³„ 2: í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
            crewai_logger.advance_step(execution_id, crew_id, "ë””ë ‰í† ë¦¬ ìƒì„±", project_path, ExecutionPhase.DIRECTORY_CREATION)

            try:
                os.makedirs(project_path, exist_ok=True)
                crewai_logger.log_directory_operation(execution_id, crew_id, "ìƒì„±", project_path, True)
                print(f"[CREWAI RESUME] í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±: {project_path}")
            except Exception as dir_error:
                crewai_logger.log_directory_operation(execution_id, crew_id, "ìƒì„±", project_path, False, {"error": str(dir_error)})
                raise dir_error

            # ë‹¨ê³„ 3: í™˜ê²½ ì„¤ì •
            crewai_logger.advance_step(execution_id, crew_id, "í™˜ê²½ ì„¤ì •", "", ExecutionPhase.ENVIRONMENT_SETUP)

            env_vars = {
                'PYTHONIOENCODING': 'utf-8',
                'PYTHONLEGACYWINDOWSSTDIO': '0',
                'CREWAI_PROJECT_PATH': project_path,
                'CREWAI_REQUIREMENT': requirement,
                'CREWAI_EXECUTION_ID': execution_id,
                'CREWAI_RESUMED': 'true'
            }

            # ë‹¨ê³„ 4: CrewAI ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
            crewai_logger.advance_step(execution_id, crew_id, "ìŠ¤í¬ë¦½íŠ¸ ìƒì„±", "", ExecutionPhase.FILE_GENERATION)

            # ê³ ë„í™”ëœ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±ê¸° ì‚¬ìš©
            try:
                from enhanced_script_generator import generate_enhanced_crewai_script
                print(f"[CREWAI RESUME] ê³ ë„í™”ëœ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±ê¸° ì‚¬ìš©")
                script_content = generate_enhanced_crewai_script(requirement, selected_models, project_path, execution_id)
            except ImportError:
                print(f"[CREWAI RESUME] ê¸°ë³¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±ê¸° ì‚¬ìš© (fallback)")
                script_content = generate_crewai_execution_script(requirement, selected_models, project_path, execution_id)
            script_path = os.path.join(project_path, "crewai_script.py")

            try:
                with open(script_path, 'w', encoding='utf-8') as f:
                    f.write(script_content)
                crewai_logger.log_file_generation(execution_id, crew_id, script_path, "Python Script", len(script_content), True)
                print(f"[CREWAI RESUME] CrewAI ìŠ¤í¬ë¦½íŠ¸ ìƒì„±: {script_path}")
            except Exception as file_error:
                crewai_logger.log_file_generation(execution_id, crew_id, script_path, "Python Script", 0, False, {"error": str(file_error)})
                raise file_error

            # ë‹¨ê³„ 5: ìš”êµ¬ì‚¬í•­ íŒŒì¼ ìƒì„±
            crewai_logger.advance_step(execution_id, crew_id, "ìš”êµ¬ì‚¬í•­ ì €ì¥", "", ExecutionPhase.FILE_GENERATION)

            requirements_path = os.path.join(project_path, "requirements.txt")
            requirements_content = "\n".join([
                "crewai>=0.28.8",
                "langchain>=0.1.0",
                "langchain-openai>=0.0.5",
                "python-dotenv>=1.0.0"
            ])

            try:
                with open(requirements_path, 'w', encoding='utf-8') as f:
                    f.write(requirements_content)
                crewai_logger.log_file_generation(execution_id, crew_id, requirements_path, "Requirements", len(requirements_content), True)
                print(f"[CREWAI RESUME] ìš”êµ¬ì‚¬í•­ íŒŒì¼ ìƒì„±: {requirements_path}")
            except Exception as req_error:
                crewai_logger.log_file_generation(execution_id, crew_id, requirements_path, "Requirements", 0, False, {"error": str(req_error)})

            # ë‹¨ê³„ 6: CrewAI ì‹¤í–‰
            crewai_logger.advance_step(execution_id, crew_id, "CrewAI ì‹¤í–‰", "ì‹œì‘", ExecutionPhase.EXECUTION)

            def execute_crewai_subprocess():
                """CrewAI ì„œë¸Œí”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
                try:
                    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
                    current_env = os.environ.copy()
                    current_env.update(env_vars)

                    # ì‹¤í–‰ ëª…ë ¹
                    python_cmd = sys.executable
                    cmd = [python_cmd, script_path]

                    print(f"[CREWAI RESUME] ì„œë¸Œí”„ë¡œì„¸ìŠ¤ ì‹¤í–‰: {' '.join(cmd)}")

                    # ì„œë¸Œí”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
                    process = subprocess.Popen(
                        cmd,
                        cwd=project_path,
                        env=current_env,
                        stdout=subprocess.PIPE,
                        stderr=subprocess.PIPE,
                        text=True,
                        encoding='utf-8',
                        errors='replace'
                    )

                    crewai_logger.log_subprocess_execution(execution_id, crew_id, " ".join(cmd), project_path, True, process.pid)

                    # ì‹¤ì‹œê°„ ì¶œë ¥ ì²˜ë¦¬
                    stdout, stderr = process.communicate()
                    return_code = process.returncode

                    # ì‹¤í–‰ ì™„ë£Œ ì²˜ë¦¬
                    execution_status[execution_id].update({
                        'status': 'completed' if return_code == 0 else 'failed',
                        'message': 'CrewAI ì‹¤í–‰ ì™„ë£Œ' if return_code == 0 else 'CrewAI ì‹¤í–‰ ì‹¤íŒ¨',
                        'end_time': datetime.now(),
                        'return_code': return_code,
                        'output': stdout[:1000] if stdout else '',
                        'error': stderr[:1000] if stderr and return_code != 0 else ''
                    })

                    # ë¡œê¹…
                    if return_code == 0:
                        crewai_logger.log_completion(execution_id, crew_id, True, stdout[:500])
                        print(f"[CREWAI RESUME] ì‹¤í–‰ ì„±ê³µ: {execution_id}")
                    else:
                        crewai_logger.log_completion(execution_id, crew_id, False, stderr[:500])
                        print(f"[CREWAI RESUME] ì‹¤í–‰ ì‹¤íŒ¨: {execution_id}, error: {stderr}")

                except Exception as exec_error:
                    execution_status[execution_id].update({
                        'status': 'failed',
                        'message': f'CrewAI ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(exec_error)}',
                        'end_time': datetime.now(),
                        'error': str(exec_error)
                    })
                    crewai_logger.log_error(execution_id, crew_id, exec_error, "CrewAI ì„œë¸Œí”„ë¡œì„¸ìŠ¤ ì‹¤í–‰")
                    print(f"[CREWAI RESUME] ì‹¤í–‰ ì˜¤ë¥˜: {exec_error}")

            # ì„œë¸Œí”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
            execute_crewai_subprocess()

        except Exception as e:
            print(f"[CREWAI RESUME ERROR] ì „ì²´ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            execution_status[execution_id] = {
                'status': 'failed',
                'message': f'CrewAI ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}',
                'end_time': datetime.now(),
                'error': str(e),
                'execution_id': execution_id
            }
            crewai_logger.log_error(execution_id, project_data.get('crew_id', 'unknown'), e, "CrewAI ì „ì²´ ì‹¤í–‰")

    # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰
    execution_thread = threading.Thread(
        target=run_full_crewai_execution,
        name=f"CrewAI-FullExec-{execution_id[:8]}",
        daemon=True
    )
    execution_thread.start()

    print(f"[CREWAI RESUME] ì „ì²´ ì‹¤í–‰ ìŠ¤ë ˆë“œ ì‹œì‘: {execution_id}")
    return True

def resume_metagpt_execution(execution_id, project_data):
    """MetaGPT ì‹¤í–‰ ì¬ê°œ - ì™„ì „ êµ¬í˜„"""
    import subprocess
    import threading

    try:
        print(f"[METAGPT RESUME] ì‹¤í–‰ ì¬ê°œ ì‹œì‘: {execution_id}")

        # 1. ê¸°ì¡´ ì‹¤í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸
        if execution_id in execution_status:
            execution_status[execution_id].update({
                'status': 'running',
                'message': 'ìŠ¹ì¸ ì™„ë£Œ - MetaGPT ì‹¤í–‰ ì¬ê°œ ì¤‘...',
                'resumed_at': datetime.now(),
                'phase': 'execution_resumed'
            })
            print(f"[METAGPT RESUME] ì‹¤í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {execution_id}")

        # 2. í”„ë¡œì íŠ¸ ë°ì´í„° ì¶”ì¶œ
        requirement = project_data.get('requirement', 'AI í”„ë¡œê·¸ë¨ ê°œë°œ')
        selected_models = project_data.get('selected_models', {})
        project_path = project_data.get('project_path')

        print(f"[METAGPT RESUME] í”„ë¡œì íŠ¸ ì •ë³´:")
        print(f"  - requirement: {requirement}")
        print(f"  - project_path: {project_path}")

        # 3. MetaGPT ë‚´ì¥ ì²˜ë¦¬ ë°©ì‹ ì‚¬ìš© (ê¸°ì¡´ ì½”ë“œ ì¬í™œìš©)
        def run_metagpt_process():
            try:
                print(f"[METAGPT RESUME] MetaGPT ë‚´ì¥ ì²˜ë¦¬ ì‹œì‘: {execution_id}")

                # ì‹¤í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸
                if execution_id in execution_status:
                    execution_status[execution_id].update({
                        'status': 'running',
                        'message': 'MetaGPT ì²˜ë¦¬ ì¤‘...',
                        'current_step': 'metagpt_execution'
                    })

                # MetaGPT ìš”ì²­ ì²˜ë¦¬ (ê¸°ì¡´ í•¨ìˆ˜ ì¬ì‚¬ìš©)
                result = call_metagpt_module(requirement, selected_models)

                if hasattr(result, 'get_json') and result.get_json().get('success'):
                    # ì„±ê³µ
                    if execution_id in execution_status:
                        execution_status[execution_id].update({
                            'status': 'completed',
                            'message': 'MetaGPT ì‹¤í–‰ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.',
                            'end_time': datetime.now(),
                            'result': result.get_json()
                        })
                    print(f"[METAGPT RESUME] ì‹¤í–‰ ì„±ê³µ: {execution_id}")

                else:
                    # ì‹¤íŒ¨
                    error_msg = result.get_json().get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜') if hasattr(result, 'get_json') else str(result)
                    if execution_id in execution_status:
                        execution_status[execution_id].update({
                            'status': 'failed',
                            'message': 'MetaGPT ì‹¤í–‰ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.',
                            'end_time': datetime.now(),
                            'error': error_msg
                        })
                    print(f"[METAGPT RESUME] ì‹¤í–‰ ì‹¤íŒ¨: {execution_id}, error: {error_msg}")

            except Exception as proc_error:
                print(f"[METAGPT RESUME] í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ì˜¤ë¥˜: {proc_error}")
                if execution_id in execution_status:
                    execution_status[execution_id].update({
                        'status': 'failed',
                        'message': 'MetaGPT ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
                        'end_time': datetime.now(),
                        'error': str(proc_error)
                    })

        # 4. ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
        execution_thread = threading.Thread(
            target=run_metagpt_process,
            name=f"MetaGPT-Resume-{execution_id[:8]}",
            daemon=True
        )
        execution_thread.start()

        print(f"[METAGPT RESUME] ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ ìŠ¤ë ˆë“œ ì‹œì‘ë¨: {execution_id}")

        # 5. ì¦‰ì‹œ ìƒíƒœ ì—…ë°ì´íŠ¸
        if execution_id in execution_status:
            execution_status[execution_id].update({
                'status': 'running',
                'message': 'MetaGPT ì‹¤í–‰ì´ ì¬ê°œë˜ì—ˆìŠµë‹ˆë‹¤.',
                'resume_success': True,
                'thread_name': execution_thread.name
            })

        return True

    except Exception as e:
        print(f"[METAGPT RESUME ERROR] ì‹¤í–‰ ì¬ê°œ ì‹¤íŒ¨: {e}")
        import traceback
        print(f"[METAGPT RESUME ERROR] ìŠ¤íƒ ì¶”ì :\n{traceback.format_exc()}")

        if execution_id in execution_status:
            execution_status[execution_id].update({
                'status': 'failed',
                'message': f'MetaGPT ì‹¤í–‰ ì¬ê°œ ì‹¤íŒ¨: {str(e)}',
                'error': str(e),
                'end_time': datetime.now(),
                'resume_success': False
            })

        return False

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=PORT, debug=True)