#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í†µí•© CrewAI ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì‹œìŠ¤í…œ
ìƒˆë¡œìš´ ì ì‘í˜• ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì—”ì§„ê³¼ ê¸°ì¡´ ì‹œìŠ¤í…œ í†µí•©
"""

import os
from adaptive_script_generator import AdaptiveScriptGenerator
from datetime import datetime

def generate_enhanced_crewai_script(requirement, selected_models, project_path, execution_id, review_iterations=3, selected_tools=None, api_keys=None):
    """ìƒˆë¡œìš´ ì ì‘í˜• ì‹œìŠ¤í…œì„ ì‚¬ìš©í•œ CrewAI ìŠ¤í¬ë¦½íŠ¸ ìƒì„±

    Args:
        requirement: ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­
        selected_models: ì—­í• ë³„ LLM ëª¨ë¸ ë”•ì…”ë„ˆë¦¬
        project_path: í”„ë¡œì íŠ¸ ì €ì¥ ê²½ë¡œ
        execution_id: ì‹¤í–‰ ID
        review_iterations: ê²€í† -ì¬ì‘ì„± ë°˜ë³µ íšŸìˆ˜ (0-3)
        selected_tools: ì„ íƒëœ MCP/ë„êµ¬ ID ë¦¬ìŠ¤íŠ¸
        api_keys: ë„êµ¬ë³„ API í‚¤ ë”•ì…”ë„ˆë¦¬
    """

    print(f"ğŸš€ ìƒˆë¡œìš´ ì ì‘í˜• CrewAI ìƒì„± ì‹œìŠ¤í…œ ì‚¬ìš©")
    print(f"   ìš”êµ¬ì‚¬í•­: {requirement[:100]}...")
    print(f"   í”„ë¡œì íŠ¸ ê²½ë¡œ: {project_path}")
    print(f"   ì‹¤í–‰ ID: {execution_id}")
    print(f"   ê²€í† -ì¬ì‘ì„± ë°˜ë³µ: {review_iterations}íšŒ")

    if selected_tools:
        from mcp_manager import MCPManager
        mcp_manager = MCPManager()
        tool_names = mcp_manager.get_tool_names(selected_tools)
        print(f"   ì„ íƒëœ ë„êµ¬: {', '.join(tool_names)}")

    try:
        # ì ì‘í˜• ìŠ¤í¬ë¦½íŠ¸ ìƒì„±ê¸° ì´ˆê¸°í™”
        generator = AdaptiveScriptGenerator("model_config.json")

        # ìˆ˜ë™ ëª¨ë¸ ì„ íƒê³¼ ê´€ê³„ì—†ì´ í•­ìƒ ê³ í’ˆì§ˆ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
        if selected_models and any(selected_models.values()):
            print(f"ğŸ¯ ìˆ˜ë™ ëª¨ë¸ ì„ íƒ ê°ì§€: {selected_models}")
            print(f"ğŸš€ ìˆ˜ë™ ëª¨ë¸ì„ ì‚¬ìš©í•œ ê³ í’ˆì§ˆ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì‹œë„...")
            # ìˆ˜ë™ ì„ íƒëœ ëª¨ë¸ì„ AdaptiveScriptGeneratorì— ì „ë‹¬
            budget = "medium"
            strategy = "balanced"

            # ê³ í’ˆì§ˆ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± (ìˆ˜ë™ ëª¨ë¸ ì‚¬ìš©)
            result = generator.generate_optimal_script_with_manual_models(
                requirement=requirement,
                selected_models=selected_models,
                project_path=project_path,
                execution_id=execution_id,
                budget=budget,
                strategy=strategy,
                max_quality_iterations=2
            )
        else:
            print(f"ğŸ¤– ìë™ ëª¨ë¸ í• ë‹¹ ëª¨ë“œ ì‚¬ìš©")
            # ê¸°ì¡´ selected_models í˜•ì‹ì„ ìƒˆë¡œìš´ ì‹œìŠ¤í…œì— ë§ê²Œ ë³€í™˜
            budget = "medium"  # ê¸°ë³¸ê°’
            strategy = "balanced"  # ê¸°ë³¸ê°’

            # ê³ í’ˆì§ˆ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
            result = generator.generate_optimal_script(
                requirement=requirement,
                project_path=project_path,
                execution_id=execution_id,
                budget=budget,
                strategy=strategy,
                max_quality_iterations=2
            )

        print(f"âœ… ì ì‘í˜• ì‹œìŠ¤í…œ ìƒì„± ì™„ë£Œ!")
        print(f"   í’ˆì§ˆ ì ìˆ˜: {result.quality_score:.1f}/100")
        print(f"   í”„ë¡œë•ì…˜ ì¤€ë¹„: {'âœ…' if result.is_production_ready else 'âŒ'}")

        return result.script_content

    except ImportError as e:
        print(f"âŒ ì ì‘í˜• ì‹œìŠ¤í…œ import ì‹¤íŒ¨: {e}")
        print(f"ğŸ”„ ê³ í’ˆì§ˆ ëŒ€ì•ˆ ì‹œìŠ¤í…œ ì‹œë„...")

        # Import ì‹¤íŒ¨ ì‹œ ê³ í’ˆì§ˆ ëŒ€ì•ˆ ì‹œë„
        try:
            return generate_high_quality_alternative_script(requirement, selected_models, project_path, execution_id, review_iterations)
        except Exception:
            print(f"ğŸ”„ ìµœì¢… í´ë°± ì‹œìŠ¤í…œ ì‚¬ìš©...")
            return generate_fallback_script(requirement, selected_models, project_path, execution_id, review_iterations)

    except Exception as e:
        print(f"âŒ ì ì‘í˜• ì‹œìŠ¤í…œ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        print(f"ğŸ”„ ê³ í’ˆì§ˆ ëŒ€ì•ˆ ì‹œìŠ¤í…œ ì‹œë„...")

        # ì¼ë°˜ ì˜ˆì™¸ ì‹œ ê³ í’ˆì§ˆ ëŒ€ì•ˆ ë¨¼ì € ì‹œë„
        try:
            return generate_high_quality_alternative_script(requirement, selected_models, project_path, execution_id, review_iterations)
        except Exception as fallback_e:
            print(f"âŒ ê³ í’ˆì§ˆ ëŒ€ì•ˆë„ ì‹¤íŒ¨: {fallback_e}")
            print(f"ğŸ”„ ìµœì¢… í´ë°± ì‹œìŠ¤í…œ ì‚¬ìš©...")
            return generate_fallback_script(requirement, selected_models, project_path, execution_id, review_iterations)

def generate_high_quality_alternative_script(requirement, selected_models, project_path, execution_id, review_iterations=3):
    """ê³ í’ˆì§ˆ ëŒ€ì•ˆ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± (ì ì‘í˜• ì‹œìŠ¤í…œ ì‹¤íŒ¨ ì‹œ)"""

    print(f"ğŸš€ ê³ í’ˆì§ˆ ëŒ€ì•ˆ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì‹œì‘ (ê²€í† -ì¬ì‘ì„± {review_iterations}íšŒ)...")

    try:
        # project_00055 ìˆ˜ì¤€ì˜ ê³ í’ˆì§ˆ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
        from generate_crewai_script_new import generate_crewai_execution_script_with_approval

        print(f"ğŸ“‹ ì „ë¬¸ ì—ì´ì „íŠ¸ ê¸°ë°˜ ê³ í’ˆì§ˆ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±...")

        # ê³ í’ˆì§ˆ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± (ìŠ¹ì¸ ê¸°ë°˜ í…œí”Œë¦¿ ì‚¬ìš©)
        script_content = generate_crewai_execution_script_with_approval(
            requirement=requirement,
            selected_models=selected_models or {'planner': 'gemini-flash', 'researcher': 'gemini-flash', 'writer': 'gemini-flash'},
            project_path=project_path,
            execution_id=execution_id,
            review_iterations=review_iterations,
            selected_tools=selected_tools,
            api_keys=api_keys
        )

        print(f"âœ… ê³ í’ˆì§ˆ ëŒ€ì•ˆ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì™„ë£Œ!")

        # README.md ìƒì„±
        try:
            create_high_quality_readme(project_path, requirement, selected_models)
        except Exception as readme_e:
            print(f"âš ï¸ README ìƒì„± ì‹¤íŒ¨ (ë¬´ì‹œ): {readme_e}")

        return script_content

    except Exception as e:
        print(f"âŒ ê³ í’ˆì§ˆ ëŒ€ì•ˆ ìƒì„± ì‹¤íŒ¨: {e}")
        raise e

def create_high_quality_readme(project_path, requirement, selected_models):
    """ê³ í’ˆì§ˆ README.md íŒŒì¼ ìƒì„±"""
    import os

    readme_content = f'''# ê³ í’ˆì§ˆ CrewAI í”„ë¡œì íŠ¸

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”
**ìš”êµ¬ì‚¬í•­**: {requirement}

**ë¶„ì•¼**: ì „ë¬¸ AI ì—ì´ì „íŠ¸ í˜‘ì—… ì‹œìŠ¤í…œ

**í•µì‹¬ ê¸°ìˆ **: CrewAI, Python, ì „ë¬¸ ì—ì´ì „íŠ¸ êµ¬ì„±

## ğŸ¤– ì—ì´ì „íŠ¸ êµ¬ì„±
- **Planner** ({selected_models.get('planner', 'gemini-flash')}): ì „ëµ ìˆ˜ë¦½ ë° ê³„íš ì „ë¬¸ê°€
- **Researcher** ({selected_models.get('researcher', 'gemini-flash')}): ì •ë³´ ìˆ˜ì§‘ ë° ë¶„ì„ ì „ë¬¸ê°€
- **Writer** ({selected_models.get('writer', 'gemini-flash')}): ì½˜í…ì¸  ìƒì„± ë° ë¬¸ì„œí™” ì „ë¬¸ê°€

**í˜‘ì—… êµ¬ì¡°**: 3ê°œ ì „ë¬¸ ì—ì´ì „íŠ¸ê°€ ìˆœì°¨ì ìœ¼ë¡œ í˜‘ì—…í•˜ì—¬ ê³ í’ˆì§ˆ ê²°ê³¼ë¬¼ ìƒì„±

## ğŸš€ ì‹¤í–‰ ë°©ë²•
### 1. í™˜ê²½ ì„¤ì •
```bash
pip install -r requirements.txt
```

### 2. API í‚¤ ì„¤ì •
`.env` íŒŒì¼ì— í•„ìš”í•œ API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”

### 3. í”„ë¡œê·¸ë¨ ì‹¤í–‰
```bash
python crewai_script.py
```

### 4. ê²°ê³¼ í™•ì¸
ì‹¤í–‰ ê²°ê³¼ëŠ” `output/` í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤

## ğŸ“ˆ ì˜ˆìƒ ê²°ê³¼
- ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” ê³ í’ˆì§ˆ ê²°ê³¼ë¬¼
- ì „ë¬¸ ì—ì´ì „íŠ¸ í˜‘ì—…ì„ í†µí•œ ìµœì í™”ëœ ì†”ë£¨ì…˜
- ì²´ê³„ì ì¸ í”„ë¡œì íŠ¸ êµ¬ì¡° ë° ë¬¸ì„œ

## ğŸ”§ ê¸°ìˆ  ìŠ¤íƒ
- CrewAI
- Python
- ì„ íƒëœ LLM ëª¨ë¸ë“¤

## ğŸ“¦ ì£¼ìš” ì˜ì¡´ì„±
- crewai
- python-dotenv
'''

    readme_path = os.path.join(project_path, "README.md")
    with open(readme_path, 'w', encoding='utf-8') as f:
        f.write(readme_content)

    print(f"âœ… README.md ìƒì„± ì™„ë£Œ: {readme_path}")

def generate_fallback_script(requirement, selected_models, project_path, execution_id, review_iterations=3):
    """í´ë°± ìŠ¤í¬ë¦½íŠ¸ ìƒì„± (ê¸°ì¡´ ì‹œìŠ¤í…œ í˜¸í™˜)"""

    print(f"ğŸ“‹ í´ë°± ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì¤‘...")

    # ê°„ë‹¨í•œ í´ë°± ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
    fallback_script = f'''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í´ë°± CrewAI ìŠ¤í¬ë¦½íŠ¸
ì‹¤í–‰ ID: {execution_id}
ìš”êµ¬ì‚¬í•­: {requirement}
"""

import os
import sys
import json
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
from crewai import Agent, Task, Crew, Process
from langchain_litellm import ChatLiteLLM

# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ .env íŒŒì¼ì˜ ê²½ë¡œë¥¼ ì§€ì •
dotenv_path = os.path.join(os.path.dirname(__file__), '.env')
load_dotenv(dotenv_path=dotenv_path)

# API í‚¤ í™•ì¸
missing_keys = []
if not os.getenv('GOOGLE_API_KEY'):
    missing_keys.append('GOOGLE_API_KEY')
if not os.getenv('OPENAI_API_KEY'):
    missing_keys.append('OPENAI_API_KEY')

if missing_keys:
    print(f'âš ï¸  ê²½ê³ : ë‹¤ìŒ í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {{", ".join(missing_keys)}}', file=sys.stderr)
    print('   .env íŒŒì¼ì— í•´ë‹¹ í‚¤ë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ ì‹œìŠ¤í…œ í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.', file=sys.stderr)

# LLM ëª¨ë¸ ì„¤ì • (ChatLiteLLM ê°ì²´ ìƒì„±)
MODELS = {{}}
api_key_mapping = {{
    'gemini': 'GOOGLE_API_KEY',
    'openai': 'OPENAI_API_KEY',
    'anthropic': 'ANTHROPIC_API_KEY',
    'deepseek': 'DEEPSEEK_API_KEY'
}}

for role, model_name in {selected_models}.items():
    provider = model_name.split('/')[0] if '/' in model_name else 'gemini'
    api_key_env = api_key_mapping.get(provider, 'GOOGLE_API_KEY')

    MODELS[role] = ChatLiteLLM(
        model=model_name,
        api_key=os.getenv(api_key_env)
    )
    print(f"ğŸ“ {{role}} ì—­í• : {{model_name}} (API í‚¤: {{api_key_env}})")

# ê¸°ë³¸ ì—ì´ì „íŠ¸ êµ¬ì„±
# ì—ì´ì „íŠ¸ë“¤ì„ ëª¨ë¸ í‚¤ì— ë§ì¶° ë™ì ìœ¼ë¡œ ìƒì„±
agents = []
tasks = []

# ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í‚¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì—ì´ì „íŠ¸ ìƒì„±
model_keys = list(MODELS.keys()) if MODELS else ['researcher', 'writer', 'planner']

for i, role_key in enumerate(model_keys):
    if role_key == 'researcher' or 'research' in role_key.lower():
        agent = Agent(
            role="Senior Researcher",
            goal="Analyze requirements and research optimal solutions",
            backstory="Expert researcher with deep domain knowledge.",
            verbose=True,
            llm=MODELS[role_key],  # ChatLiteLLM ê°ì²´ ì§ì ‘ ì „ë‹¬
            allow_delegation=False
        )
    elif role_key == 'writer' or 'writ' in role_key.lower():
        agent = Agent(
            role="Professional Writer",
            goal="Create high-quality documentation and deliverables",
            backstory="Professional writer with expertise in technical documentation.",
            verbose=True,
            llm=MODELS[role_key],  # ChatLiteLLM ê°ì²´ ì§ì ‘ ì „ë‹¬
            allow_delegation=False
        )
    elif role_key == 'planner' or 'plan' in role_key.lower():
        agent = Agent(
            role="Strategic Planner",
            goal="Develop comprehensive implementation plans",
            backstory="Strategic planning expert with project management experience.",
            verbose=True,
            llm=MODELS[role_key],  # ChatLiteLLM ê°ì²´ ì§ì ‘ ì „ë‹¬
            allow_delegation=False
        )
    else:
        # ê¸°íƒ€ ì—­í• ë“¤ (data_scientist, data_engineer, visualization_specialist ë“±)
        agent = Agent(
            role=f"{{role_key.replace('_', ' ').title()}} Specialist",
            goal="ì „ë¬¸ ë¶„ì•¼ì—ì„œ ìµœê³  í’ˆì§ˆì˜ ê²°ê³¼ë¬¼ì„ ìƒì„±í•©ë‹ˆë‹¤.",
            backstory=f"ë‹¹ì‹ ì€ {{role_key.replace('_', ' ')}} ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•´ë‹¹ ë¶„ì•¼ì—ì„œ ë›°ì–´ë‚œ ì „ë¬¸ì„±ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.",
            verbose=True,
            llm=MODELS[role_key],  # ChatLiteLLM ê°ì²´ ì§ì ‘ ì „ë‹¬
            allow_delegation=False
        )

    agents.append(agent)

    # ê° ì—ì´ì „íŠ¸ì— ëŒ€í•œ íƒœìŠ¤í¬ ìƒì„±
    task = Task(
        description=f"ì „ë¬¸ ë¶„ì•¼ì—ì„œ ìµœê³  í’ˆì§ˆì˜ ê²°ê³¼ë¬¼ì„ ìƒì„±í•˜ì„¸ìš”: {requirement}",
        expected_output="ì „ë¬¸ ë¶„ì•¼ì˜ ê³ í’ˆì§ˆ ê²°ê³¼ë¬¼",
        agent=agent
    )
    tasks.append(task)

# í¬ë£¨ êµ¬ì„±
crew = Crew(
    agents=agents,
    tasks=tasks,
    process=Process.sequential,
    verbose=True
)

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("CrewAI í´ë°± ì‹œìŠ¤í…œ - ì‹¤í–‰ ì‹œì‘")
    print(f"ì‹¤í–‰ ID: {execution_id}")
    print(f"í”„ë¡œì íŠ¸ ê²½ë¡œ: {project_path}")

    try:
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        output_dir = Path("{project_path}") / "output"
        output_dir.mkdir(parents=True, exist_ok=True)

        # CrewAI ì‹¤í–‰
        start_time = datetime.now()
        result = crew.kickoff()
        end_time = datetime.now()

        print("ì‹¤í–‰ ì™„ë£Œ!")
        print(result)

        # ê²°ê³¼ ì €ì¥
        result_file = output_dir / f"crew_result_{{datetime.now().strftime('%Y%m%d_%H%M%S')}}.txt"
        with open(result_file, 'w', encoding='utf-8') as f:
            f.write(str(result))

        print(f"ê²°ê³¼ ì €ì¥: {{result_file}}")

    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {{e}}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
'''

    return fallback_script

# ===== ê¸°ì¡´ ì‹œìŠ¤í…œ í˜¸í™˜ì„± í•¨ìˆ˜ë“¤ =====

def apply_feedback_loop(script_content, requirement, selected_models, project_path, execution_id, max_iterations=2):
    """ê¸°ì¡´ ì‹œìŠ¤í…œ í˜¸í™˜ìš© í”¼ë“œë°± ë£¨í”„ (ë”ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)"""
    print("âš ï¸  ê¸°ì¡´ í”¼ë“œë°± ë£¨í”„ëŠ” ìƒˆë¡œìš´ í’ˆì§ˆ ë³´ì¦ ì‹œìŠ¤í…œìœ¼ë¡œ ëŒ€ì²´ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return script_content

def planner_review_script(script_content, requirement):
    """Planner agent reviews script and provides structured feedback"""

    feedback = {
        'quality_score': 5.0,  # Default baseline score
        'issues': [],
        'improvements': [],
        'structural_assessment': '',
        'recommendation': ''
    }

    # Analyze script structure
    lines = script_content.split('\n')

    # Check for common issues
    issues = []
    improvements = []

    # 1. Agent definition quality
    agent_count = script_content.count('Agent(')
    if agent_count < 3:
        issues.append("ë¶€ì¡±í•œ ì—ì´ì „íŠ¸ êµ¬ì„±: ìµœì†Œ 3ê°œ ì´ìƒì˜ ì „ë¬¸ ì—ì´ì „íŠ¸ í•„ìš”")
        improvements.append("ë„ë©”ì¸ë³„ ì „ë¬¸ ì—ì´ì „íŠ¸ ì¶”ê°€")
    elif agent_count >= 4:
        feedback['quality_score'] += 1.0

    # 2. Task chain logic
    task_count = script_content.count('Task(')
    if task_count != agent_count:
        issues.append("ì—ì´ì „íŠ¸-íƒœìŠ¤í¬ ë¶ˆì¼ì¹˜: ê° ì—ì´ì „íŠ¸ë§ˆë‹¤ ì „ìš© íƒœìŠ¤í¬ í•„ìš”")
        improvements.append("ì—ì´ì „íŠ¸ë³„ ì „ë¬¸ íƒœìŠ¤í¬ ì •ì˜")
    else:
        feedback['quality_score'] += 1.0

    # 3. Error handling
    if 'try:' not in script_content or 'except' not in script_content:
        issues.append("ì˜ˆì™¸ ì²˜ë¦¬ ë¶€ì¡±: í¬ê´„ì  ì—ëŸ¬ í•¸ë“¤ë§ í•„ìš”")
        improvements.append("try-except ë¸”ë¡ìœ¼ë¡œ ê²¬ê³ í•œ ì—ëŸ¬ ì²˜ë¦¬ êµ¬í˜„")
    else:
        feedback['quality_score'] += 1.0

    # 4. Output handling
    if 'output' not in script_content.lower() or 'save' not in script_content.lower():
        issues.append("ì¶œë ¥ ì²˜ë¦¬ ë¶€ì¡±: ê²°ê³¼ ì €ì¥ ë° ê´€ë¦¬ ë¡œì§ í•„ìš”")
        improvements.append("ê²°ê³¼ íŒŒì¼ ì €ì¥ ë° ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„")
    else:
        feedback['quality_score'] += 1.0

    # 5. Requirement integration
    if requirement.lower() not in script_content.lower():
        issues.append("ìš”êµ¬ì‚¬í•­ ë°˜ì˜ ë¶€ì¡±: ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ì´ ì¶©ë¶„íˆ ë°˜ì˜ë˜ì§€ ì•ŠìŒ")
        improvements.append("êµ¬ì²´ì  ìš”êµ¬ì‚¬í•­ì„ íƒœìŠ¤í¬ ì„¤ëª…ì— í†µí•©")

    # 6. Code quality
    if 'verbose=True' in script_content:
        feedback['quality_score'] += 0.5
    if 'encoding=\'utf-8\'' in script_content:
        feedback['quality_score'] += 0.5

    feedback['issues'] = issues
    feedback['improvements'] = improvements

    # Structural assessment
    if len(issues) == 0:
        feedback['structural_assessment'] = "ìš°ìˆ˜í•œ êµ¬ì¡°: ëª¨ë“  í•µì‹¬ ìš”ì†Œê°€ ì˜ êµ¬ì„±ë¨"
        feedback['recommendation'] = "í˜„ì¬ êµ¬ì¡° ìœ ì§€í•˜ë©° ì„¸ë¶€ êµ¬í˜„ ê°•í™”"
    elif len(issues) <= 2:
        feedback['structural_assessment'] = "ì–‘í˜¸í•œ êµ¬ì¡°: ì¼ë¶€ ê°œì„ ì‚¬í•­ ìˆìŒ"
        feedback['recommendation'] = "ì£¼ìš” ì´ìŠˆ í•´ê²° í›„ í’ˆì§ˆ í–¥ìƒ ê¸°ëŒ€"
    else:
        feedback['structural_assessment'] = "êµ¬ì¡° ê°œì„  í•„ìš”: ì—¬ëŸ¬ í•µì‹¬ ìš”ì†Œ ë³´ì™„ í•„ìš”"
        feedback['recommendation'] = "ì „ë©´ì  êµ¬ì¡° ì¬ê²€í†  ë° í•µì‹¬ ê¸°ëŠ¥ ê°•í™”"
        feedback['quality_score'] = max(3.0, feedback['quality_score'] - 1.0)

    return feedback

def writer_improve_script(script_content, planner_feedback, requirement, selected_models, project_path, execution_id):
    """Writer agent improves script based on Planner feedback"""

    improvements = planner_feedback['improvements']
    issues = planner_feedback['issues']

    # If major structural issues, regenerate with improvements
    if len(issues) > 3:
        print("[WRITER] ì£¼ìš” êµ¬ì¡°ì  ë¬¸ì œë¡œ ì¸í•œ ìŠ¤í¬ë¦½íŠ¸ ì¬ìƒì„±")
        if any(keyword in requirement.lower() for keyword in ['ì´ë ¥ì„œ', 'ë¬¸ì„œ', 'íŒŒì‹±', 'ì¶”ì¶œ', 'pdf', 'docx', 'resume']):
            return generate_improved_resume_processing_script(requirement, selected_models, project_path, execution_id, planner_feedback)
        else:
            return generate_improved_general_script(requirement, selected_models, project_path, execution_id, planner_feedback)

    # Otherwise, apply targeted improvements
    improved_script = script_content

    # Apply specific improvements
    for improvement in improvements:
        if "ì—ì´ì „íŠ¸ ì¶”ê°€" in improvement:
            improved_script = add_specialized_agents(improved_script)
        elif "íƒœìŠ¤í¬ ì •ì˜" in improvement:
            improved_script = improve_task_definitions(improved_script, requirement)
        elif "ì—ëŸ¬ ì²˜ë¦¬" in improvement:
            improved_script = enhance_error_handling(improved_script)
        elif "ê²°ê³¼ ì €ì¥" in improvement:
            improved_script = improve_output_handling(improved_script, project_path)

    return improved_script

def generate_improved_resume_processing_script(requirement, selected_models, project_path, execution_id, feedback):
    """Generate improved resume processing script based on feedback"""

    # Enhanced version with all feedback considerations
    script = '''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
High-Quality Resume Processing CrewAI Script
Generated: ''' + execution_id + '''
Improved based on Planner feedback
Requirement: ''' + requirement + '''
"""

import os
import sys
import json
import pandas as pd
import re
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
from crewai import Agent, Task, Crew, Process

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Model configuration
MODELS = ''' + str(selected_models) + '''

# Specialized agents for resume processing (Enhanced)
document_parser = Agent(
    role="Senior Document Parsing Expert",
    goal="Parse various document formats (PDF, DOCX, Excel) with 99% accuracy",
    backstory="""You are a senior document processing expert with 15+ years of experience.
    You have mastered parsing PDF, DOCX, Excel files and resolving complex encoding issues.
    Your expertise includes OCR processing, table extraction, and multi-language support.""",
    verbose=True,
    llm=MODELS.get('document_parser', 'gemini-flash'),
    allow_delegation=False
)

information_extractor = Agent(
    role="AI Information Extraction Specialist",
    goal="Extract structured information with precision using advanced NLP techniques",
    backstory="""You are an AI specialist in information extraction with deep expertise in
    regex patterns, named entity recognition, and semantic analysis. You excel at extracting
    personal information, education history, work experience, and skills from unstructured text.""",
    verbose=True,
    llm=MODELS.get('information_extractor', 'gpt-4'),
    allow_delegation=False
)

data_validator = Agent(
    role="Data Quality Assurance Expert",
    goal="Ensure 100% data accuracy and completeness through systematic validation",
    backstory="""You are a data quality expert specializing in validation frameworks.
    Your systematic approach includes data consistency checks, duplicate detection,
    format standardization, and comprehensive quality metrics.""",
    verbose=True,
    llm=MODELS.get('data_validator', 'claude-3'),
    allow_delegation=False
)

output_formatter = Agent(
    role="Multi-Format Output Specialist",
    goal="Generate perfect output in multiple formats with enterprise-grade quality",
    backstory="""You are an output formatting expert who creates production-ready results.
    You master JSON, Excel, CSV formatting with proper encoding, schema validation,
    and enterprise reporting standards.""",
    verbose=True,
    llm=MODELS.get('output_formatter', 'gemini-pro'),
    allow_delegation=False
)

# Enhanced task definitions
task1_parse_documents = Task(
    description=f"""Implement a comprehensive document parsing system for: {requirement}

**Core Requirements:**
- Support PDF, DOCX, Excel, TXT formats
- Handle OCR for scanned documents
- Extract tables and structured data
- Resolve encoding issues (UTF-8, CP949, Latin-1)
- Implement robust error recovery

**Quality Standards:**
- 99%+ text extraction accuracy
- Preserve document structure
- Handle corrupted files gracefully
- Support batch processing

**Deliverables:**
- Complete parsing functions with error handling
- Unit tests for each format
- Performance benchmarks
- Usage documentation
""",
    expected_output="Production-ready document parsing system with comprehensive error handling",
    agent=document_parser
)

task2_extract_information = Task(
    description="""Build advanced information extraction system with NLP techniques:

**Information Categories:**
1. Personal: Name, email, phone (regex validation)
2. Education: Institution, degree, major, dates, GPA
3. Experience: Company, role, duration, achievements
4. Skills: Technical skills, certifications, languages
5. Additional: Projects, publications, references

**Advanced Features:**
- Named entity recognition
- Confidence scoring for extractions
- Duplicate detection across sections
- Missing data identification
- Format standardization

**Quality Assurance:**
- Validation patterns for all data types
- Cross-reference consistency checks
- Accuracy confidence metrics
""",
    expected_output="Advanced information extraction system with NLP capabilities and quality metrics",
    agent=information_extractor
)

task3_validate_data = Task(
    description="""Implement comprehensive data validation and quality assurance:

**Validation Framework:**
- Field completeness analysis
- Data type validation
- Format consistency checks
- Cross-field logical validation
- Duplicate detection algorithms

**Quality Metrics:**
- Completion percentage by category
- Accuracy confidence scores
- Data consistency index
- Error categorization and reporting

**Output Standards:**
- Validated JSON with confidence scores
- Quality assessment report
- Data gap analysis
- Improvement recommendations
""",
    expected_output="Comprehensive data validation system with quality metrics and reporting",
    agent=data_validator
)

task4_format_output = Task(
    description="""Create enterprise-grade multi-format output system:

**Output Formats:**
1. JSON: Structured data with schema validation
2. Excel: Human-readable with formatting and charts
3. CSV: Analysis-ready format
4. PDF Report: Executive summary with visualizations

**Quality Features:**
- UTF-8 BOM encoding for Korean support
- Schema validation for JSON output
- Professional formatting for Excel
- Data visualization in reports
- Comprehensive error logging

**File Management:**
- Organized directory structure
- Timestamped filenames
- Backup and versioning
- Metadata tracking

Save to: """ + project_path + """/output/
""",
    expected_output="Enterprise-grade multi-format output system with professional quality",
    agent=output_formatter
)

# Create enhanced crew
crew = Crew(
    agents=[document_parser, information_extractor, data_validator, output_formatter],
    tasks=[task1_parse_documents, task2_extract_information, task3_validate_data, task4_format_output],
    process=Process.sequential,
    verbose=True
)

def main():
    """Enhanced main execution function with comprehensive error handling"""
    print("=" * 80)
    print("HIGH-QUALITY Resume Processing CrewAI - Starting Execution")
    print(f"Execution ID: ''' + execution_id + '''")
    print(f"Project Path: ''' + project_path + '''")
    print(f"Requirement: ''' + requirement + '''")
    print("=" * 80)

    try:
        # Create comprehensive output structure
        output_dir = Path(""" + f'"{project_path}"' + """) / "output"
        output_dir.mkdir(parents=True, exist_ok=True)

        logs_dir = output_dir / "logs"
        logs_dir.mkdir(exist_ok=True)

        reports_dir = output_dir / "reports"
        reports_dir.mkdir(exist_ok=True)

        # Execute CrewAI with monitoring
        print("\\nğŸš€ Starting CrewAI execution...")
        start_time = datetime.now()

        result = crew.kickoff()

        end_time = datetime.now()
        execution_time = (end_time - start_time).total_seconds()

        print("\\n" + "=" * 80)
        print("âœ… EXECUTION COMPLETED SUCCESSFULLY!")
        print(f"â±ï¸  Total execution time: {'{execution_time:.2f}'} seconds")
        print("=" * 80)
        print(result)

        # Save comprehensive results
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

        # Main result file
        result_file = output_dir / f"crew_result_{'{timestamp}'}.txt"
        with open(result_file, 'w', encoding='utf-8') as f:
            f.write(f"Execution Summary\\n")
            f.write(f"================\\n")
            f.write(f"Execution ID: """ + execution_id + """\\n")
            f.write(f"Requirement: """ + requirement + """\\n")
            f.write(f"Start Time: {'{start_time}'}\\n")
            f.write(f"End Time: {'{end_time}'}\\n")
            f.write(f"Duration: {'{execution_time:.2f}'} seconds\\n\\n")
            f.write(f"Results:\\n")
            f.write(f"========\\n")
            f.write(str(result))

        # Execution metadata
        metadata_file = output_dir / f"execution_metadata_{'{timestamp}'}.json"
        metadata = {'{'}
            "execution_id": \"""" + execution_id + """\",
            "requirement": \"""" + requirement + """\",
            "start_time": start_time.isoformat(),
            "end_time": end_time.isoformat(),
            "duration_seconds": execution_time,
            "agents_used": ["document_parser", "information_extractor", "data_validator", "output_formatter"],
            "status": "completed",
            "output_files": [str(result_file), str(metadata_file)]
        {'}'}

        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)

        print(f"\\nğŸ“ Results saved:")
        print(f"   ğŸ“„ Main result: {'{result_file}'}")
        print(f"   ğŸ“Š Metadata: {'{metadata_file}'}")
        print(f"   ğŸ“ Output directory: {'{output_dir}'}")

    except Exception as e:
        error_time = datetime.now()
        print(f"\\nâŒ ERROR OCCURRED: {'{e}'}")

        # Comprehensive error logging
        error_file = output_dir / f"error_log_{'{error_time.strftime(\\'%Y%m%d_%H%M%S\\')}'}.txt"
        with open(error_file, 'w', encoding='utf-8') as f:
            f.write(f"Error Report\\n")
            f.write(f"============\\n")
            f.write(f"Time: {'{error_time}'}\\n")
            f.write(f"Execution ID: """ + execution_id + """\\n")
            f.write(f"Error: {'{str(e)}'}\\n\\n")

            import traceback
            f.write("Full Traceback:\\n")
            f.write(traceback.format_exc())

        print(f"ğŸ“„ Error log saved: {'{error_file}'}")

        # Re-raise for upstream handling
        raise

if __name__ == "__main__":
    main()
'''

    return script

def generate_improved_general_script(requirement, selected_models, project_path, execution_id, feedback):
    """Generate improved general script based on feedback"""

    # Similar structure but for general use cases
    return generate_general_script(requirement, selected_models, project_path, execution_id)

def add_specialized_agents(script_content):
    """Add more specialized agents to the script"""
    # Implementation for adding agents
    return script_content

def improve_task_definitions(script_content, requirement):
    """Improve task definitions with more specific requirements"""
    # Implementation for improving tasks
    return script_content

def enhance_error_handling(script_content):
    """Add comprehensive error handling"""
    # Implementation for error handling
    return script_content

def improve_output_handling(script_content, project_path):
    """Improve output and file management"""
    # Implementation for output handling
    return script_content

def generate_resume_processing_script(requirement, selected_models, project_path, execution_id):
    """Generate specialized resume processing script"""

    script = f'''#!/usr/bin/env python3
# Enhanced Resume Processing CrewAI Script
# Generated: {execution_id}

import os
import sys
import json
from datetime import datetime
from pathlib import Path
from crewai import Agent, Task, Crew, Process

# Model configuration
MODELS = ''' + str(selected_models) + '''

# Specialized agents for resume processing
document_parser = Agent(
    role="Document Parsing Expert",
    goal="Parse various document formats to extract text content",
    backstory="Expert in document processing with 10+ years of experience.",
    verbose=True,
    llm=MODELS.get('document_parser', 'gemini-flash'),
    allow_delegation=False
)

information_extractor = Agent(
    role="Information Extraction Specialist",
    goal="Extract structured information from unstructured text",
    backstory="Expert in regex and NLP techniques for information extraction.",
    verbose=True,
    llm=MODELS.get('information_extractor', 'gpt-4'),
    allow_delegation=False
)

data_validator = Agent(
    role="Data Validation Expert",
    goal="Validate accuracy and completeness of extracted data",
    backstory="Data quality management expert specializing in validation.",
    verbose=True,
    llm=MODELS.get('data_validator', 'claude-3'),
    allow_delegation=False
)

output_formatter = Agent(
    role="Output Formatting Specialist",
    goal="Convert validated data to required output formats",
    backstory="Expert in various output formats and encoding handling.",
    verbose=True,
    llm=MODELS.get('output_formatter', 'gemini-pro'),
    allow_delegation=False
)

# Tasks for resume processing pipeline
task1 = Task(
    description="Implement document parsing system for PDF, DOCX, Excel files with encoding support",
    expected_output="Document parsing functions with error handling",
    agent=document_parser
)

task2 = Task(
    description="Extract personal info, education, experience, skills from parsed text using regex",
    expected_output="Information extraction system with validation logic",
    agent=information_extractor
)

task3 = Task(
    description="Structure extracted data into standardized JSON format with validation",
    expected_output="JSON data conversion system with validation rules",
    agent=data_validator
)

task4 = Task(
    description="Generate output files in JSON, Excel, CSV formats with proper encoding",
    expected_output="Multi-format file output system",
    agent=output_formatter
)

# Create crew
crew = Crew(
    agents=[document_parser, information_extractor, data_validator, output_formatter],
    tasks=[task1, task2, task3, task4],
    process=Process.sequential,
    verbose=True
)

def main():
    print("Enhanced Resume Processing CrewAI - Starting execution")
    print(f"Execution ID: ''' + execution_id + '''")
    print(f"Project Path: ''' + project_path + '''")

    try:
        output_dir = Path(""" + f'"{project_path}"' + """) / "output"
        output_dir.mkdir(parents=True, exist_ok=True)

        result = crew.kickoff()

        print("Execution completed!")
        print(result)

        result_file = output_dir / f"crew_result_{'{datetime.now().strftime(\\'%Y%m%d_%H%M%S\\')}'}.txt"
        with open(result_file, 'w', encoding='utf-8') as f:
            f.write(str(result))

        print(f"Result saved to: {'{result_file}'}")

    except Exception as e:
        print(f"Error occurred: {'{e}'}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
'''

    return script

def generate_enhanced_general_script(requirement, selected_models, project_path, execution_id):
    """Generate enhanced 4-agent general script for all project types"""

    script = '''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
High-Quality General Project CrewAI Script (4-Agent System)
Generated: ''' + execution_id + '''
Enhanced with Enterprise-Grade Features
Requirement: ''' + requirement + '''
"""

import os
import sys
import json
from datetime import datetime
from pathlib import Path
from crewai import Agent, Task, Crew, Process

# Model configuration
MODELS = ''' + str(selected_models) + '''

# Enhanced 4-Agent System for General Projects
requirements_analyst = Agent(
    role="Senior Requirements Analyst",
    goal="Analyze and structure project requirements with precision",
    backstory="""You are a senior business analyst with 15+ years of experience.
    You excel at understanding complex requirements, identifying hidden needs,
    and translating business goals into clear technical specifications.""",
    verbose=True,
    llm=MODELS.get('requirements_analyst', 'gpt-4'),
    allow_delegation=False
)

technology_researcher = Agent(
    role="Technology Research Specialist",
    goal="Research and recommend optimal technology stack and implementation approaches",
    backstory="""You are a technology research expert with deep knowledge of modern frameworks,
    tools, and best practices. You stay current with industry trends and can recommend
    the most suitable technologies for any project type.""",
    verbose=True,
    llm=MODELS.get('technology_researcher', 'gemini-pro'),
    allow_delegation=False
)

solution_architect = Agent(
    role="Senior Solution Architect",
    goal="Design comprehensive system architecture and implementation strategy",
    backstory="""You are a senior solution architect with expertise in designing scalable,
    maintainable systems. You excel at creating detailed technical designs that balance
    performance, security, and development efficiency.""",
    verbose=True,
    llm=MODELS.get('solution_architect', 'claude-3'),
    allow_delegation=False
)

implementation_engineer = Agent(
    role="Senior Implementation Engineer",
    goal="Create production-ready code and comprehensive project deliverables",
    backstory="""You are a senior software engineer with expertise in multiple programming
    languages and frameworks. You write clean, well-documented, production-ready code
    with comprehensive testing and deployment strategies.""",
    verbose=True,
    llm=MODELS.get('implementation_engineer', 'deepseek-coder'),
    allow_delegation=False
)

# Enhanced task definitions
task1_analyze_requirements = Task(
    description=f"""Perform comprehensive requirements analysis for: {requirement}

**Analysis Framework:**
1. **Functional Requirements**: Core features, user stories, business logic
2. **Non-Functional Requirements**: Performance, security, usability standards
3. **Technical Constraints**: Platform limitations, dependencies, resources
4. **Success Criteria**: Measurable outcomes, acceptance criteria, quality standards

**Deliverables:**
- Structured requirements document with priority matrix
- Risk assessment and mitigation strategies
- Success metrics and KPI definitions
""",
    expected_output="Comprehensive requirements analysis with structured specifications and success criteria",
    agent=requirements_analyst
)

task2_research_technology = Task(
    description="""Research optimal technology stack based on analyzed requirements:

**Research Areas:**
1. **Technology Stack**: Languages, frameworks, databases, cloud services
2. **Architecture Patterns**: Design patterns, integration approaches, security frameworks
3. **Development Ecosystem**: Libraries, testing frameworks, monitoring solutions
4. **Implementation Strategy**: Development methodology, quality assurance, DevOps

**Quality Standards:**
- Industry best practices compliance
- Security and privacy considerations
- Scalability and maintainability analysis
- Cost-effectiveness evaluation
""",
    expected_output="Technology research report with justified recommendations and implementation roadmap",
    agent=technology_researcher
)

task3_design_architecture = Task(
    description="""Design comprehensive system architecture:

**Architecture Design:**
1. **System Architecture**: High-level design, component interactions, data flow
2. **Technical Specifications**: API design, database schema, UI wireframes
3. **Implementation Plan**: Development phases, resource allocation, quality checkpoints
4. **Deployment Architecture**: Infrastructure, environment configuration, monitoring

**Quality Assurance:**
- Architecture review checklist and performance benchmarking plan
- Security audit framework and compliance verification strategy
""",
    expected_output="Detailed system architecture with implementation specifications and quality assurance plan",
    agent=solution_architect
)

task4_implement_solution = Task(
    description="""Create production-ready implementation:

**Implementation Deliverables:**
1. **Complete Source Code**: Production-ready app with error handling and security
2. **Configuration**: Environment configs, dependencies, deployment scripts
3. **Testing Suite**: Unit tests, integration tests, API validation, performance testing
4. **Documentation**: Technical docs, API docs, user guides, deployment guides
5. **Quality Assurance**: Code review, security audit, performance benchmarks

Save all deliverables to: ''' + project_path + '''/output/
""",
    expected_output="Complete production-ready implementation with comprehensive documentation and testing",
    agent=implementation_engineer
)

# Create enhanced crew with 4 specialized agents
crew = Crew(
    agents=[requirements_analyst, technology_researcher, solution_architect, implementation_engineer],
    tasks=[task1_analyze_requirements, task2_research_technology, task3_design_architecture, task4_implement_solution],
    process=Process.sequential,
    verbose=True
)

def main():
    """Enhanced main execution function with comprehensive project delivery"""
    print("=" * 80)
    print("HIGH-QUALITY 4-Agent CrewAI System - Starting Execution")
    print(f"Execution ID: ''' + execution_id + '''")
    print(f"Project Path: ''' + project_path + '''")
    print(f"Requirement: ''' + requirement + '''")
    print("=" * 80)

    try:
        # Create comprehensive output structure
        output_dir = Path("''' + project_path + '''") / "output"
        output_dir.mkdir(parents=True, exist_ok=True)

        logs_dir = output_dir / "logs"
        logs_dir.mkdir(exist_ok=True)

        deliverables_dir = output_dir / "deliverables"
        deliverables_dir.mkdir(exist_ok=True)

        # Execute CrewAI with enhanced monitoring
        print("\\nğŸš€ Starting 4-Agent CrewAI execution...")
        start_time = datetime.now()

        result = crew.kickoff()

        end_time = datetime.now()
        execution_time = (end_time - start_time).total_seconds()

        print("\\n" + "=" * 80)
        print("âœ… 4-AGENT EXECUTION COMPLETED SUCCESSFULLY!")
        print(f"â±ï¸  Total execution time: {execution_time:.2f} seconds")
        print(f"ğŸ‘¥ Agents used: 4 specialized agents")
        print(f"ğŸ“‹ Tasks completed: 4 comprehensive tasks")
        print("=" * 80)
        print(result)

        # Save comprehensive results
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

        # Main result file
        result_file = output_dir / f"crew_result_{timestamp}.txt"
        with open(result_file, 'w', encoding='utf-8') as f:
            f.write(f"4-Agent CrewAI Execution Results\\n")
            f.write(f"================================\\n")
            f.write(f"Execution ID: ''' + execution_id + '''\\n")
            f.write(f"Requirement: ''' + requirement + '''\\n")
            f.write(f"Start Time: {start_time}\\n")
            f.write(f"End Time: {end_time}\\n")
            f.write(f"Duration: {execution_time:.2f} seconds\\n")
            f.write(f"Agents: 4 specialized agents\\n\\n")
            f.write(f"Results:\\n")
            f.write(f"========\\n")
            f.write(str(result))

        # Execution metadata
        metadata_file = output_dir / f"execution_metadata_{timestamp}.json"
        metadata = {
            "execution_id": "''' + execution_id + '''",
            "requirement": "''' + requirement + '''",
            "start_time": start_time.isoformat(),
            "end_time": end_time.isoformat(),
            "duration_seconds": execution_time,
            "agent_count": 4,
            "agents_used": ["requirements_analyst", "technology_researcher", "solution_architect", "implementation_engineer"],
            "task_count": 4,
            "status": "completed",
            "output_files": [str(result_file), str(metadata_file)],
            "system_type": "enhanced_4_agent"
        }

        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)

        print(f"\\nğŸ“ Results saved:")
        print(f"   ğŸ“„ Main result: {result_file}")
        print(f"   ğŸ“Š Metadata: {metadata_file}")
        print(f"   ğŸ“ Output directory: {output_dir}")
        print(f"   ğŸ“ Deliverables: {deliverables_dir}")

    except Exception as e:
        error_time = datetime.now()
        print(f"\\nâŒ ERROR OCCURRED: {e}")

        # Comprehensive error logging
        error_file = output_dir / f"error_log_{error_time.strftime('%Y%m%d_%H%M%S')}.txt"
        with open(error_file, 'w', encoding='utf-8') as f:
            f.write(f"4-Agent System Error Report\\n")
            f.write(f"=========================\\n")
            f.write(f"Time: {error_time}\\n")
            f.write(f"Execution ID: ''' + execution_id + '''\\n")
            f.write(f"Error: {str(e)}\\n\\n")

            import traceback
            f.write("Full Traceback:\\n")
            f.write(traceback.format_exc())

        print(f"ğŸ“„ Error log saved: {error_file}")

        # Re-raise for upstream handling
        raise

if __name__ == "__main__":
    main()
'''

    return script

def generate_general_script(requirement, selected_models, project_path, execution_id):
    """Generate general CrewAI script (3-agent fallback)"""

    script = f'''#!/usr/bin/env python3
# General CrewAI Script (3-Agent System)
# Generated: {execution_id}

import os
import sys
from datetime import datetime
from pathlib import Path
from crewai import Agent, Task, Crew, Process

# Model configuration
MODELS = ''' + str(selected_models) + '''

# General-purpose agents
researcher = Agent(
    role="Researcher",
    goal="Analyze requirements and collect information",
    backstory="Professional research and analysis expert",
    verbose=True,
    llm=MODELS.get('researcher', 'gemini-2.5-flash'),
    allow_delegation=False
)

writer = Agent(
    role="Writer",
    goal="Create clear documentation",
    backstory="Expert in creating well-structured documents",
    verbose=True,
    llm=MODELS.get('writer', 'gpt-4'),
    allow_delegation=False
)

planner = Agent(
    role="Planner",
    goal="Develop execution plans",
    backstory="Expert in systematic planning and project management",
    verbose=True,
    llm=MODELS.get('planner', 'claude-3'),
    allow_delegation=False
)

# Tasks
task1 = Task(
    description=f"Analyze requirements and collect information: {requirement}",
    expected_output="Requirements analysis and collected information",
    agent=researcher
)

task2 = Task(
    description="Create systematic documentation based on analysis",
    expected_output="Well-organized documentation",
    agent=writer
)

task3 = Task(
    description="Develop specific execution plans",
    expected_output="Step-by-step execution plan",
    agent=planner
)

# Create crew
crew = Crew(
    agents=[researcher, writer, planner],
    tasks=[task1, task2, task3],
    process=Process.sequential,
    verbose=True
)

def main():
    print("General CrewAI (3-Agent System) - Starting execution")
    print(f"Execution ID: ''' + execution_id + '''")
    print(f"Project Path: ''' + project_path + '''")

    try:
        output_dir = Path(""" + f'"{project_path}"' + """) / "output"
        output_dir.mkdir(parents=True, exist_ok=True)

        result = crew.kickoff()

        print("Execution completed!")
        print(result)

        result_file = output_dir / f"crew_result_{'{datetime.now().strftime(\\'%Y%m%d_%H%M%S\\')}'}.txt"
        with open(result_file, 'w', encoding='utf-8') as f:
            f.write(str(result))

        print(f"Result saved to: {'{result_file}'}")

    except Exception as e:
        print(f"Error occurred: {'{e}'}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
'''

    return script