"""
Pre-analysis Chat API
ì‚¬ìš©ìì™€ LLM ê°„ì˜ ëŒ€í™”ë¥¼ í†µí•´ ìš”êµ¬ì‚¬í•­ì„ ëª…í™•íˆ í•˜ëŠ” API
"""
from flask import Blueprint, request, jsonify
import os
from typing import List, Dict
import re
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_openai import ChatOpenAI
try:
    from langchain_anthropic import ChatAnthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False
    ChatAnthropic = None
from langchain.schema import HumanMessage, AIMessage, SystemMessage

pre_analysis_bp = Blueprint('pre_analysis', __name__)

class PreAnalysisService:
    """ì‚¬ì „ë¶„ì„ ì„œë¹„ìŠ¤"""

    def __init__(self):
        self.system_prompt = """ë‹¹ì‹ ì€ ì†Œí”„íŠ¸ì›¨ì–´ í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ìš”êµ¬ì‚¬í•­ì„ ë“£ê³ , ë‹¤ìŒ í•­ëª©ë“¤ì„ ëª…í™•íˆ í•˜ê¸° ìœ„í•´ ì§ˆë¬¸í•˜ì„¸ìš”:

1. **í”„ë¡œì íŠ¸ ëª©ì **: ë¬´ì—‡ì„ ë§Œë“¤ê³  ì‹¶ì€ê°€?
2. **í•µì‹¬ ê¸°ëŠ¥**: ë°˜ë“œì‹œ í•„ìš”í•œ ê¸°ëŠ¥ì€ ë¬´ì—‡ì¸ê°€?
3. **ëŒ€ìƒ ì‚¬ìš©ì**: ëˆ„ê°€ ì‚¬ìš©í•  ê²ƒì¸ê°€?
4. **ê¸°ìˆ  ìŠ¤íƒ**: ì„ í˜¸í•˜ëŠ” ê¸°ìˆ ì´ ìˆëŠ”ê°€?
5. **ì œì•½ì‚¬í•­**: ì‹œê°„, ì˜ˆì‚°, ê¸°ìˆ ì  ì œì•½ì€?

ì‚¬ìš©ìì˜ ë‹µë³€ì„ ë“£ê³ , ëª¨í˜¸í•œ ë¶€ë¶„ì´ ìˆìœ¼ë©´ ì¶”ê°€ ì§ˆë¬¸ì„ í•˜ì„¸ìš”.
ìš”êµ¬ì‚¬í•­ì´ ì¶©ë¶„íˆ ëª…í™•í•´ì§€ë©´, ìµœì¢… ìš”êµ¬ì‚¬í•­ì„ ì •ë¦¬í•˜ì—¬ ì œì‹œí•˜ê³  í™•ì • ì—¬ë¶€ë¥¼ ë¬¼ì–´ë³´ì„¸ìš”.

**ì‘ë‹µ í˜•ì‹**:
- ì§ˆë¬¸ì´ í•„ìš”í•œ ê²½ìš°: ëª…í™•í•˜ê³  êµ¬ì²´ì ì¸ ì§ˆë¬¸
- ìš”êµ¬ì‚¬í•­ ì •ë¦¬ê°€ ê°€ëŠ¥í•œ ê²½ìš°: "ë‹¤ìŒê³¼ ê°™ì´ ìš”êµ¬ì‚¬í•­ì„ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤:" ë¡œ ì‹œì‘í•˜ëŠ” ìš”ì•½
"""

    def get_llm(self, model_name: str):
        """ëª¨ë¸ëª…ì— ë”°ë¼ LLM ë°˜í™˜"""
        if model_name.startswith('gpt'):
            return ChatOpenAI(
                model=model_name,
                temperature=0.7,
                api_key=os.getenv('OPENAI_API_KEY')
            )
        elif model_name.startswith('gemini'):
            return ChatGoogleGenerativeAI(
                model=model_name,
                temperature=0.7,
                google_api_key=os.getenv('GOOGLE_API_KEY')
            )
        elif model_name.startswith('claude'):
            if ANTHROPIC_AVAILABLE:
                return ChatAnthropic(
                    model=model_name,
                    temperature=0.7,
                    anthropic_api_key=os.getenv('ANTHROPIC_API_KEY')
                )
            else:
                # Claude ì‚¬ìš© ë¶ˆê°€ëŠ¥í•œ ê²½ìš° Geminië¡œ í´ë°±
                print(f"Warning: Claude model requested but langchain_anthropic not available. Falling back to Gemini.")
                return ChatGoogleGenerativeAI(
                    model='gemini-2.0-flash-exp',
                    temperature=0.7,
                    google_api_key=os.getenv('GOOGLE_API_KEY')
                )
        else:
            # ê¸°ë³¸ê°’
            return ChatGoogleGenerativeAI(
                model='gemini-2.0-flash-exp',
                temperature=0.7,
                google_api_key=os.getenv('GOOGLE_API_KEY')
            )

    def chat(
        self,
        user_message: str,
        conversation_history: List[Dict],
        model: str = 'gemini-2.0-flash-exp'
    ) -> Dict:
        """
        ì‚¬ì „ë¶„ì„ ëŒ€í™” ì²˜ë¦¬

        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            conversation_history: ì´ì „ ëŒ€í™” ì´ë ¥
            model: ì‚¬ìš©í•  LLM ëª¨ë¸

        Returns:
            {
                'analysis': AI ì‘ë‹µ,
                'canFinalize': ìš”êµ¬ì‚¬í•­ í™•ì • ê°€ëŠ¥ ì—¬ë¶€,
                'suggestedRequirement': ì œì•ˆëœ ìµœì¢… ìš”êµ¬ì‚¬í•­ (canFinalize=Trueì¸ ê²½ìš°)
            }
        """
        llm = self.get_llm(model)

        # ë©”ì‹œì§€ êµ¬ì„±
        messages = [SystemMessage(content=self.system_prompt)]

        # ëŒ€í™” ì´ë ¥ ì¶”ê°€
        for msg in conversation_history:
            if msg['role'] == 'user':
                messages.append(HumanMessage(content=msg['content']))
            elif msg['role'] == 'assistant':
                messages.append(AIMessage(content=msg['content']))

        # í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        messages.append(HumanMessage(content=user_message))

        # LLM í˜¸ì¶œ
        response = llm.invoke(messages)
        ai_message = response.content

        # ìš”êµ¬ì‚¬í•­ í™•ì • ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨
        can_finalize = self._can_finalize(ai_message)
        suggested_requirement = None

        if can_finalize:
            suggested_requirement = self._extract_requirement(ai_message)

        return {
            'analysis': ai_message,
            'canFinalize': can_finalize,
            'suggestedRequirement': suggested_requirement
        }


    @staticmethod
    def _ensure_statement(text: str) -> str:
        if not text:
            return ''
        normalized = re.sub(r'\*+', '', text).strip()
        if not normalized:
            return ''
        normalized = re.sub(r'\s+', ' ', normalized)
        if normalized[-1] in '.?!â€¦':
            return normalized
        return normalized + '.'

    @classmethod
    def _normalize_requirement_sentences(cls, lines: List[str]) -> List[str]:
        cleaned = []
        for raw in lines:
            if not raw:
                continue
            stripped = re.sub(r'^[-â€¢Â·\d\.\)\s]+', '', raw)
            stripped = re.sub(r'\*+', '', stripped).strip()
            stripped = stripped.lstrip('ğŸ“Œâœ…â“').strip()
            if not stripped:
                continue
            statement = cls._ensure_statement(stripped)
            if statement:
                cleaned.append(statement)
        return cleaned

    @staticmethod
    def _split_items(text: str) -> List[str]:
        if not text:
            return []
        normalized = (text.replace(' - ', '|')
                        .replace('- ', '|')
                        .replace('â€¢', '|')
                        .replace('Â·', '|'))
        parts = []
        for part in normalized.split('|'):
            cleaned = part.strip(' -â€¢Â·')
            if cleaned:
                parts.append(cleaned)
        return parts

    @classmethod
    def _structure_requirement_sections(cls, lines: List[str]) -> Dict[str, List[str]]:
        sections: Dict[str, List[str]] = {}
        current_header = None
        for raw in lines:
            plain = re.sub(r'\*+', '', raw).strip()
            header_match = re.match(r'([^:]+):(.*)', plain)
            if header_match:
                header = header_match.group(1).strip()
                body = header_match.group(2).strip()
                current_header = header
                if body:
                    sections.setdefault(header, []).extend(cls._split_items(body))
            else:
                if current_header:
                    sections.setdefault(current_header, []).extend(cls._split_items(plain))
                else:
                    sections.setdefault('ê¸°íƒ€', []).append(plain)
        return sections


    def _can_finalize(self, ai_message: str) -> bool:
        """AI ì‘ë‹µì—ì„œ ìš”êµ¬ì‚¬í•­ í™•ì • ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨"""
        finalize_keywords = [
            'ìµœì¢… ìš”êµ¬ì‚¬í•­ì„ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤',
            'ë‹¤ìŒê³¼ ê°™ì´ ìš”êµ¬ì‚¬í•­ì„ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤',
            'ìš”êµ¬ì‚¬í•­ ì •ë¦¬',
            'ìµœì¢… ìš”êµ¬ì‚¬í•­',
            'ì´ìƒìœ¼ë¡œ ì •ë¦¬',
            'í™•ì¸í•´ ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”',
            'ê²€í† í•´ ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”'
        ]
        return any(keyword in ai_message for keyword in finalize_keywords)


    def _extract_requirement(self, ai_message: str) -> str:
        """AI ì‘ë‹µì—ì„œ ìµœì¢… ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ"""
        lines = ai_message.splitlines()
        requirement_lines = []
        capture = False

        trigger_phrases = [
            'ìµœì¢… ìš”êµ¬ì‚¬í•­ì„ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤',
            'ìµœì¢… ìš”êµ¬ì‚¬í•­ì„ ì •ë¦¬í–ˆì–´ìš”',
            'ìµœì¢… ìš”êµ¬ì‚¬í•­ì„ ì •ë¦¬í•˜ê² ìŠµë‹ˆë‹¤',
            'ë‹¤ìŒê³¼ ê°™ì´ ìš”êµ¬ì‚¬í•­ì„ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤'
        ]

        for line in lines:
            if any(phrase in line for phrase in trigger_phrases):
                capture = True
                continue
            if capture:
                stripped = line.strip()
                if stripped and not stripped.startswith('í™•ì¸'):
                    requirement_lines.append(stripped)

        cleaned_lines = self._normalize_requirement_sentences(requirement_lines)
        sections = self._structure_requirement_sections(cleaned_lines) if cleaned_lines else {}

        summary_candidates = sections.get('í”„ë¡œì íŠ¸ ëª©ì ') or sections.get('ìš”ì•½') or []
        summary = summary_candidates[0] if summary_candidates else (cleaned_lines[0] if cleaned_lines else '')

        detail_headers = ['í•µì‹¬ ê¸°ëŠ¥', 'ëŒ€ìƒ ì‚¬ìš©ì', 'ê¸°ìˆ  ìŠ¤íƒ', 'ê¸°ìˆ ', 'ì œì•½ ì‚¬í•­', 'ë¹„ê³ ', 'ì¶”ê°€ ì •ë³´']
        detail_items = []
        for header in detail_headers:
            for item in sections.get(header, []):
                detail_items.append(f"{header}: {item}")

        miscellaneous = [
            item
            for key, values in sections.items()
            if key not in detail_headers + ['í”„ë¡œì íŠ¸ ëª©ì ', 'ìš”ì•½', 'í™•ì • ì—¬ë¶€']
            for item in (f"{key}: {value}" for value in values)
        ]
        detail_items.extend(miscellaneous)

        questions = sections.get('í™•ì • ì—¬ë¶€', [])

        result_lines: List[str] = []
        if summary:
            result_lines.append('ğŸ“Œ í”„ë¡œì íŠ¸ ìš”ì•½')
            result_lines.append(f"- {summary}")

        if detail_items:
            result_lines.append('')
            result_lines.append('âœ… ì£¼ìš” ìš”êµ¬ì‚¬í•­')
            result_lines.extend(f"- {item}" for item in detail_items)

        if questions:
            result_lines.append('')
            result_lines.append('â“ í™•ì¸ ìš”ì²­')
            result_lines.extend(f"- {question}" for question in questions)

        if result_lines:
            return '\n'.join(result_lines)

        fallback_lines = self._normalize_requirement_sentences([ai_message])
        if fallback_lines:
            return '\n'.join(fallback_lines)
        return ai_message





# Flask ë¼ìš°íŠ¸
@pre_analysis_bp.route('/api/pre-analysis/chat', methods=['POST'])
def pre_analysis_chat():
    """
    ì‚¬ì „ë¶„ì„ ëŒ€í™” API

    Request Body:
    {
        "userMessage": "ì „ììƒê±°ë˜ ì›¹ì‚¬ì´íŠ¸ë¥¼ ë§Œë“¤ê³  ì‹¶ì–´ìš”",
        "conversationHistory": [
            {"role": "assistant", "content": "ì–´ë–¤ í”„ë¡œì íŠ¸ë¥¼ ë§Œë“¤ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?"},
            {"role": "user", "content": "ì‡¼í•‘ëª°ì„ ë§Œë“¤ê³  ì‹¶ì–´ìš”"}
        ],
        "model": "gemini-2.0-flash-exp"
    }

    Response:
    {
        "analysis": "AIì˜ ì‘ë‹µ",
        "canFinalize": true/false,
        "suggestedRequirement": "ì •ë¦¬ëœ ìµœì¢… ìš”êµ¬ì‚¬í•­" (canFinalize=trueì¸ ê²½ìš°)
    }
    """
    try:
        data = request.get_json()

        user_message = data.get('userMessage')
        conversation_history = data.get('conversationHistory', [])
        model = data.get('model', 'gemini-2.0-flash-exp')

        if not user_message:
            return jsonify({'error': 'User message is required'}), 400

        # ì‚¬ì „ë¶„ì„ ì„œë¹„ìŠ¤ ì‹¤í–‰
        service = PreAnalysisService()
        result = service.chat(
            user_message=user_message,
            conversation_history=conversation_history,
            model=model
        )

        return jsonify(result), 200

    except Exception as e:
        return jsonify({'error': str(e)}), 500


@pre_analysis_bp.route('/api/pre-analysis/initial', methods=['POST'])
def get_initial_question():
    """
    ì‚¬ì „ë¶„ì„ ì´ˆê¸° ì§ˆë¬¸ ìƒì„±

    Request Body:
    {
        "framework": "crewai" | "metagpt",
        "model": "gemini-2.0-flash-exp"
    }

    Response:
    {
        "initialQuestion": "ì´ˆê¸° ì§ˆë¬¸"
    }
    """
    try:
        data = request.get_json()
        framework = data.get('framework', 'crewai')
        model = data.get('model', 'gemini-2.0-flash-exp')

        # í”„ë ˆì„ì›Œí¬ë³„ ì´ˆê¸° ì§ˆë¬¸
        if framework == 'crewai':
            initial_question = """ì•ˆë…•í•˜ì„¸ìš”! CrewAI í”„ë¡œì íŠ¸ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤.

CrewAIëŠ” ì—¬ëŸ¬ AI ì—ì´ì „íŠ¸ê°€ í˜‘ì—…í•˜ì—¬ ë³µì¡í•œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

ì–´ë–¤ í”„ë¡œì íŠ¸ë¥¼ ë§Œë“¤ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?
ì˜ˆë¥¼ ë“¤ì–´:
- ë°ì´í„° ë¶„ì„ ë° ë¦¬í¬íŠ¸ ìƒì„±
- ì½˜í…ì¸  ì œì‘ ë° í¸ì§‘
- ì—°êµ¬ ë° ì •ë³´ ìˆ˜ì§‘
- ê¸°íƒ€ ì°½ì˜ì ì¸ ì‘ì—…

êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""

        elif framework == 'metagpt':
            initial_question = """ì•ˆë…•í•˜ì„¸ìš”! MetaGPT í”„ë¡œì íŠ¸ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤.

MetaGPTëŠ” ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ì „ ê³¼ì •(ê¸°íš, ì„¤ê³„, êµ¬í˜„, í…ŒìŠ¤íŠ¸)ì„ ìë™í™”í•˜ëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

ì–´ë–¤ ì†Œí”„íŠ¸ì›¨ì–´ë¥¼ ê°œë°œí•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?
ì˜ˆë¥¼ ë“¤ì–´:
- ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜
- ëª¨ë°”ì¼ ì•±
- API ì„œë²„
- ë°ì´í„° ì²˜ë¦¬ ì‹œìŠ¤í…œ
- ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œì íŠ¸

êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”."""

        else:
            initial_question = "ì–´ë–¤ í”„ë¡œì íŠ¸ë¥¼ ë§Œë“¤ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?"

        return jsonify({'initialQuestion': initial_question}), 200

    except Exception as e:
        return jsonify({'error': str(e)}), 500
